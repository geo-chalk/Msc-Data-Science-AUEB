{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chalkiopoulos Georgios, Electrical and Computer Engineer NTUA <br />\n",
    "> Data Science postgraduate Student <br />\n",
    "> gchalkiopoulos@aueb.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "## Goal\n",
    "\n",
    "* Find a rating-based or matching-based (binary) dataset that can be used to inform a recsys based on collaborative filtering.\n",
    "\n",
    "* Email me your dataset of choice to confirm before working on your recsys.\n",
    "\n",
    "* Build a Python Notebook that:\n",
    "\n",
    "(1) Loads the dataset\n",
    "\n",
    "(2) Tries at least 2 different recommendation methods based on collaborative filtering (Tensorflow, Matrix factorization, Count-based)\n",
    "\n",
    "(3) Uses quantitative metrics to evaluate the recommendations of each of the two methods that you selected.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset was [downloaded from Kaggle](https://www.kaggle.com/datasets/thedevastator/1-5-million-beer-reviews-from-beer-advocate) and contains 1.5m beer reviews from beer advocate.\n",
    "\n",
    "## Useful info\n",
    "\n",
    "The notebook uses three recommendation methods:\n",
    "- Count-based: which is split in user based and movie based\n",
    "- LDA: from which topic modelling is performed, and movies from the most fitting group are recommended\n",
    "- SVD: in which the recommendation is made based on the predicted rating\n",
    "\n",
    "## Evalutation\n",
    "\n",
    "A group of users (test_users) was created, of whom the first five (random) will be used to evaluate the results. These users have between 500 and 600 ratings. For these users, we will get recommendations, and calculate the ratio of positively rated beers. This ratio represents the beers that are potential recommendation, but the user has already rated.\n",
    "\n",
    "Moreover, another user (user 5) will be used to print the actual recommendations, along with the previous metric.\n",
    "\n",
    "## Code setup\n",
    "\n",
    "This Notebook uses modules placed under the folder `utils` to help with readability. Moreover, a new environment can be created using the `requirements.txt` file. The logging level can be set from the coresponding cell. If the user whishes to see minimal info, it should be set to WARNING.\n",
    "\n",
    "## pkl files\n",
    "\n",
    "some parts of the code use saved `.pkl` files, to reduce computational time. If the files do not exist, the corresponding calculation will take place and the files will then be saved. You may contact the author, if you wish to receive the pre-calculated pkl files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import INFO, WARNING, DEBUG, ERROR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# utils\n",
    "from utils import helper_functions\n",
    "from utils import lda\n",
    "from utils import reader\n",
    "from utils.Loggers import BaseLogger\n",
    "from utils import svd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Set Logging level"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BaseLogger.level = INFO\n",
    "logger = BaseLogger().logger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-05 23:19:52,442] INFO [ReviewReader] - Loading beer_reviews.csv\n",
      "[2023-03-05 23:19:59,054] INFO [ReviewReader] - 300000 reviews loaded.\n",
      "[2023-03-05 23:20:05,179] INFO [ReviewReader] - 600000 reviews loaded.\n",
      "[2023-03-05 23:20:11,568] INFO [ReviewReader] - 900000 reviews loaded.\n",
      "[2023-03-05 23:20:17,746] INFO [ReviewReader] - 1200000 reviews loaded.\n",
      "[2023-03-05 23:20:24,025] INFO [ReviewReader] - 1500000 reviews loaded.\n",
      "[2023-03-05 23:20:25,702] INFO [ReviewReader] - All reviews loaded. Total reviews: 1586614\n",
      "[2023-03-05 23:20:53,312] INFO [ReviewReader] - Processing completed.\n"
     ]
    }
   ],
   "source": [
    "file_path: str = \"beer_reviews.csv\"\n",
    "reader = reader.ReviewReader(file_path=file_path)\n",
    "reviews: pd.DataFrame = reader.read_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1399623, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    user_id    user_name  beer_id      beer_name   beer_style  review_overall  \\\n10        7      fodeeoz      436   Amstel Light  Light Lager             3.0   \n18       15       jdhilt      436   Amstel Light  Light Lager             2.5   \n19       16  UCLABrewN84    58046  Rauch Ür Bock    Rauchbier             4.5   \n20       17   zaphodchak    58046  Rauch Ür Bock    Rauchbier             4.0   \n21       18      Tilley4    58046  Rauch Ür Bock    Rauchbier             4.0   \n\n    review_aroma  review_appearance review_taste review_palate brewery_id  \\\n10           2.0                3.0          2.5           2.5        163   \n18           3.0                3.0          2.0           2.0        163   \n19           4.5                3.0          4.5           4.0       1075   \n20           4.0                4.0          4.0           3.0       1075   \n21           4.5                4.0          4.0           3.5       1075   \n\n   rating  \n10      A  \n18      A  \n19      P  \n20      P  \n21      P  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>user_name</th>\n      <th>beer_id</th>\n      <th>beer_name</th>\n      <th>beer_style</th>\n      <th>review_overall</th>\n      <th>review_aroma</th>\n      <th>review_appearance</th>\n      <th>review_taste</th>\n      <th>review_palate</th>\n      <th>brewery_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>7</td>\n      <td>fodeeoz</td>\n      <td>436</td>\n      <td>Amstel Light</td>\n      <td>Light Lager</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>163</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>15</td>\n      <td>jdhilt</td>\n      <td>436</td>\n      <td>Amstel Light</td>\n      <td>Light Lager</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>163</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>16</td>\n      <td>UCLABrewN84</td>\n      <td>58046</td>\n      <td>Rauch Ür Bock</td>\n      <td>Rauchbier</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>3.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>1075</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>17</td>\n      <td>zaphodchak</td>\n      <td>58046</td>\n      <td>Rauch Ür Bock</td>\n      <td>Rauchbier</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1075</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>18</td>\n      <td>Tilley4</td>\n      <td>58046</td>\n      <td>Rauch Ür Bock</td>\n      <td>Rauchbier</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>1075</td>\n      <td>P</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Item-Based and User-Based Recommendations with Hashing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Index data & compute similarity scores\n",
    "\n",
    "* Due to the size of the data, we will use Hashing in order to be able to perform calculations\n",
    "* Two recommendation systems (User based and Movie based) will be created by calculating the corresponding similarity scores\n",
    "* For faster development, pkl files are available."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-05 21:18:30,817] INFO [BaseLogger] - Trying to load indexer_usr.pkl file.\n",
      "[2023-03-05 21:18:39,472] INFO [BaseLogger] - indexer_usr.pkl file loaded.\n",
      "[2023-03-05 21:18:39,473] INFO [BaseLogger] - Trying to load indexer_beer.pkl file.\n",
      "[2023-03-05 21:18:49,784] INFO [BaseLogger] - indexer_beer.pkl file loaded.\n"
     ]
    }
   ],
   "source": [
    "indexer_user = helper_functions.load_indexer(focus=\"usr\",\n",
    "                             reviews=reviews, beer_id_col='beer_id', user_id_col='user_id',\n",
    "                             beer_mapping=reader.beer_mapping, user_mapping=reader.user_mapping,\n",
    "                             indexer_path=\"indexer_usr.pkl\"\n",
    "                            )\n",
    "\n",
    "indexer_beer = helper_functions.load_indexer(focus=\"beer\",\n",
    "                             reviews=reviews, beer_id_col='beer_id', user_id_col='user_id',\n",
    "                             beer_mapping=reader.beer_mapping, user_mapping=reader.user_mapping,\n",
    "                             indexer_path=\"indexer_beer.pkl\"\n",
    "                            )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Test users evaluation\n",
    "\n",
    "* In this part we will check the recommendations for some users. The recommendations provided will be compared to the user's ratings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1.1 Test users evaluation - User Based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: 2\n",
      "Positive ratio: 100.00%\n",
      "Already Rated number of beers: 31\n",
      "\n",
      "User: 63\n",
      "Positive ratio: 97.55%\n",
      "Already Rated number of beers: 286\n",
      "\n",
      "User: 76\n",
      "Positive ratio: 84.00%\n",
      "Already Rated number of beers: 25\n",
      "\n",
      "User: 80\n",
      "No beers already rated\n",
      "\n",
      "User: 151\n",
      "Positive ratio: 94.44%\n",
      "Already Rated number of beers: 54\n"
     ]
    }
   ],
   "source": [
    "for user in reader.test_users[:5]:\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Get already rated beers\n",
    "        already_rated = helper_functions.recommend_ub(indexer_user, user=user, rec_num=10, verbose=0)\n",
    "\n",
    "        # print the ratio of positively rated beers vs recommendations\n",
    "        print(f\"\\nUser: {user}\")\n",
    "        if already_rated:\n",
    "            print(\"Positive ratio:\", f'{list(already_rated.values()).count(\"P\")/len(already_rated.values())*100:.2f}%')\n",
    "            print(\"Already Rated number of beers:\", f'{len(already_rated.values())}')\n",
    "        else:\n",
    "            print(\"No beers already rated\")\n",
    "\n",
    "    except KeyError:\n",
    "       print(f\"\\nUser {user} not found\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1.2 Test users evaluation - Movie Based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: 2\n",
      "Positive ratio: 94.74%\n",
      "Already Rated number of beers: 19\n",
      "\n",
      "User: 63\n",
      "Positive ratio: 98.01%\n",
      "Already Rated number of beers: 403\n",
      "\n",
      "User: 76\n",
      "Positive ratio: 73.91%\n",
      "Already Rated number of beers: 23\n",
      "\n",
      "User: 80\n",
      "No beers already rated\n",
      "\n",
      "User: 151\n",
      "Positive ratio: 93.22%\n",
      "Already Rated number of beers: 59\n"
     ]
    }
   ],
   "source": [
    "for user in reader.test_users[:5]:\n",
    "    try:\n",
    "        # Get already rated beers\n",
    "        already_rated = helper_functions.recommend_mb(indexer_beer, user=user, rec_num=10, verbose=0)\n",
    "\n",
    "        # print the ratio of positively rated beers vs recommendations\n",
    "        print(f\"\\nUser: {user}\")\n",
    "        if already_rated:\n",
    "            print(\"Positive ratio:\", f'{list(already_rated.values()).count(\"P\")/len(already_rated.values())*100:.2f}%')\n",
    "            print(\"Already Rated number of beers:\", f'{len(already_rated.values())}')\n",
    "        else:\n",
    "            print(\"No beers already rated\")\n",
    "\n",
    "    except KeyError:\n",
    "       print(f\"\\nUser {user} not found\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.21 User 5 recommendations - User Based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I suggest the following beers because they have received positive ratings\n",
      "from users who tend to like what you like:\n",
      "\n",
      "1904 Sierra Nevada Celebration Ale 89.48\n",
      "2751 Racer 5 India Pale Ale 82.04\n",
      "35738 Hop Stoopid 70.62\n",
      "6549 Northern Hemisphere Harvest Wet Hop Ale 65.05\n",
      "16403 Smuttynose IPA \"Finest Kind\" 61.27\n",
      "646 Westmalle Trappist Tripel 60.11\n",
      "33644 B.O.R.I.S. The Crusher Oatmeal-Imperial Stout 59.49\n",
      "7348 Founders Porter 59.41\n",
      "22505 Green Flash West Coast I.P.A. 56.96\n",
      "8919 G'Knight Imperial Red Ale 56.42\n",
      "\n",
      "\n",
      "Positive ratio: 93.06%\n",
      "Already Rated number of beers: 72\n"
     ]
    }
   ],
   "source": [
    "already_rated = helper_functions.recommend_ub(indexer_user, user=5, rec_num=10, verbose=1)\n",
    "\n",
    "print(\"\\n\\nPositive ratio:\", f'{list(already_rated.values()).count(\"P\")/len(already_rated.values())*100:.2f}%')\n",
    "print(\"Already Rated number of beers:\", f'{len(already_rated.values())}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2.1 User 5 recommendations - Movie Based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I suggest the following beers because they are similar to the beers you already like:\n",
      "\n",
      "3916 AleSmith IPA 30.02\n",
      "2751 Racer 5 India Pale Ale 29.00\n",
      "33644 B.O.R.I.S. The Crusher Oatmeal-Imperial Stout 29.00\n",
      "8919 G'Knight Imperial Red Ale 28.02\n",
      "6549 Northern Hemisphere Harvest Wet Hop Ale 27.75\n",
      "1658 Big Bear Black Stout 26.32\n",
      "35738 Hop Stoopid 26.24\n",
      "7348 Founders Porter 25.53\n",
      "22505 Green Flash West Coast I.P.A. 24.99\n",
      "1117 Bell's Kalamazoo Stout 24.07\n",
      "\n",
      "\n",
      "Positive ratio: 95.08%\n",
      "Already Rated number of beers: 61\n"
     ]
    }
   ],
   "source": [
    "already_rated = helper_functions.recommend_mb(indexer_beer, user=5, rec_num=10, verbose=1)\n",
    "\n",
    "print(\"\\n\\nPositive ratio:\", f'{list(already_rated.values()).count(\"P\")/len(already_rated.values())*100:.2f}%')\n",
    "print(\"Already Rated number of beers:\", f'{len(already_rated.values())}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. LDA\n",
    "\n",
    "We will use Latent Dirichlet Allocation (LDA) for topic modeling, to create groups of beers. In order to create the groups, we will create a \"doc\" for each user, containing a list of the beerid concatenated with the rating.\n",
    "* This will work as the corpus, from which groups (topics) will be generated)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 Create Corpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-05 21:29:06,264] INFO [BaseLogger] - Creating list of reviews per user.\n",
      "[2023-03-05 21:29:14,171] INFO [BaseLogger] - Creating User docs.\n",
      "[2023-03-05 21:29:14,175] INFO [BaseLogger] - Docs created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 10707\n"
     ]
    }
   ],
   "source": [
    "# list of reviews (beer_id+rating) per user\n",
    "logger.info(\"Creating list of reviews per user.\")\n",
    "reviews_user = reviews[[\"user_id\", \"beer_id\", \"rating\"]].groupby('user_id').apply(lambda x: list(x['beer_id'].astype(str).str.cat(x['rating'])))\n",
    "\n",
    "print(\"Number of users:\", reviews_user.shape[0])\n",
    "reviews_user.head()\n",
    "\n",
    "logger.info(\"Creating User docs.\")\n",
    "docs: dict = dict(zip(reviews_user.index, reviews_user.values))\n",
    "logger.info(\"Docs created.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 Create LDA topics (Groups)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To speed up computing time, we have pre-calculated the groups. If the pkl file doesn't exist, the LDA caluclation will take place, by finding the best combination of k and iterations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-05 21:30:03,021] INFO [BaseLogger] - Trying to load lda_groups.pkl file.\n",
      "[2023-03-05 21:30:03,033] INFO [BaseLogger] - lda_groups.pkl file loaded.\n"
     ]
    }
   ],
   "source": [
    "lda_groups_path: Path = Path(\"lda_groups.pkl\")\n",
    "\n",
    "try:\n",
    "\n",
    "    logger.info(f\"Trying to load {lda_groups_path} file.\")\n",
    "    with open(lda_groups_path, 'rb') as handle:\n",
    "        groups = pickle.load(handle)\n",
    "        logger.info(f\"{lda_groups_path} file loaded.\")\n",
    "\n",
    "except (FileNotFoundError, EOFError) as e:\n",
    "\n",
    "    logger.warning(f\"{lda_groups_path} file doesn't exist. Proceeding to calculate.\")\n",
    "    groups = lda.setup_LDA(docs=docs, k_range=(3, 7), k_step=2,\n",
    "                   iteration_range=(0, 500), iterations_step=20,\n",
    "                   top_n=100, reviews=reviews, verbose=0)\n",
    "\n",
    "    logger.info(f\"Saving {lda_groups_path} file.\")\n",
    "    with open(lda_groups_path, 'wb') as handle:\n",
    "        pickle.dump(groups, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    logger.info(f\"{lda_groups_path} file saved.\")\n",
    "\n",
    "handle.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3 LDA test users' recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: 2\n",
      "Group: 1\n",
      "Positive ratio: 75.00%\n",
      "Already Rated number of beers: 4\n",
      "\n",
      "Group: 2\n",
      "Positive ratio: 100.00%\n",
      "Already Rated number of beers: 24\n",
      "\n",
      "Group: 3\n",
      "Positive ratio: 100.00%\n",
      "Already Rated number of beers: 4\n",
      "\n",
      "\n",
      "User: 63\n",
      "Group: 1\n",
      "Positive ratio: 89.69%\n",
      "Already Rated number of beers: 97\n",
      "\n",
      "Group: 2\n",
      "Positive ratio: 99.00%\n",
      "Already Rated number of beers: 100\n",
      "\n",
      "Group: 3\n",
      "Positive ratio: 94.44%\n",
      "Already Rated number of beers: 36\n",
      "\n",
      "\n",
      "User: 76\n",
      "Group: 1\n",
      "Positive ratio: 71.43%\n",
      "Already Rated number of beers: 14\n",
      "\n",
      "Group: 2\n",
      "Positive ratio: 87.50%\n",
      "Already Rated number of beers: 16\n",
      "\n",
      "Group: 3\n",
      "Positive ratio: 87.50%\n",
      "Already Rated number of beers: 8\n",
      "\n",
      "\n",
      "User: 80\n",
      "Group: 1\n",
      "No beers already rated in the group\n",
      "Group: 2\n",
      "No beers already rated in the group\n",
      "Group: 3\n",
      "Positive ratio: 100.00%\n",
      "Already Rated number of beers: 1\n",
      "\n",
      "\n",
      "User: 151\n",
      "Group: 1\n",
      "Positive ratio: 78.12%\n",
      "Already Rated number of beers: 32\n",
      "\n",
      "Group: 2\n",
      "Positive ratio: 91.67%\n",
      "Already Rated number of beers: 48\n",
      "\n",
      "Group: 3\n",
      "Positive ratio: 85.71%\n",
      "Already Rated number of beers: 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user in reader.test_users[:5]:\n",
    "    print(f\"\\nUser: {user}\")\n",
    "    try:\n",
    "        best_recommendations = lda.recommend_lda(groups=groups, user=user, rec_num=10, _user_ratings=indexer_user.user_ratings, _beer_mapping=reader.beer_mapping)\n",
    "\n",
    "    except KeyError:\n",
    "       print(f\"\\nUser {user} not found\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3 LDA user 5 recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: 1\n",
      "Positive ratio: 82.22%\n",
      "Already Rated number of beers: 45\n",
      "\n",
      "Group: 2\n",
      "Positive ratio: 92.00%\n",
      "Already Rated number of beers: 50\n",
      "\n",
      "Group: 3\n",
      "Positive ratio: 100.00%\n",
      "Already Rated number of beers: 16\n",
      "\n",
      "Best Recommendations\n",
      "\n",
      "646   : Westmalle Trappist Tripel\n",
      "674   : Westmalle Trappist Dubbel\n",
      "221   : Fuller's London Porter\n",
      "1346  : Chimay Tripel (White)\n",
      "219   : Fuller's ESB\n",
      "222   : Fuller's London Pride\n",
      "1836  : La Chouffe\n",
      "672   : Chimay Première (Red)\n",
      "652   : Traquair Jacobite\n",
      "63    : Anchor Steam Beer\n"
     ]
    }
   ],
   "source": [
    "best_recommendations = lda.recommend_lda(groups=groups, user=5, rec_num=10, _user_ratings=indexer_user.user_ratings, _beer_mapping=reader.beer_mapping)\n",
    "\n",
    "\n",
    "print(\"Best Recommendations\\n\")\n",
    "for beer_id, beer in best_recommendations:\n",
    "    print(f\"{beer_id:<6}: {beer}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Model Based\n",
    "\n",
    "Using SVD we will try to build a recommended system that predicts the user's score for each beer.\n",
    "We will user the test users to find the optimal value of k, based on the MSE."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 Find optimal k value\n",
    "\n",
    "* In the step we will find the optimal value of k, by using the recall as the metric of evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ratings_np_centered, user_means, ratings_matrix = svd.initialize_svd(reviews=reviews)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This part was used to find the optimal value of k. Due to the long time of processing it's commented out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# for k in range(1, 302, 50):\n",
    "#     logger.info(f\"Started SVD calculation for k={k}\")\n",
    "#     #perform svd with k singular values (features)\n",
    "#     U, sigma, Vt = svds(ratings_np_centered, k = k)\n",
    "#     sigma = np.diag(sigma)\n",
    "#     logger.info(f\"Completed SVD calculation for k={k}\")\n",
    "#\n",
    "#     count = []\n",
    "#     acc = []\n",
    "#\n",
    "#     # calculate average score for test users\n",
    "#     for user in helper_functions.progressbar(reader.test_users,\n",
    "#                                              f\"Validating recall for k={k}: \",\n",
    "#                                              60,\n",
    "#                                              print_every=1):\n",
    "#         try:\n",
    "#             _acc, _count = svd.validate(user, reviews, U, sigma, Vt, user_means, ratings_matrix)\n",
    "#             acc.append(_acc)\n",
    "#             count.append(_count)\n",
    "#         except ValueError:\n",
    "#             print(f\"User {user} not found\")\n",
    "#\n",
    "#     print(f\"Weighted recall for k={k}: {np.dot(np.array(acc)/np.array(count), np.array(count)/np.array(count).sum(axis=0,keepdims=1))*100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 Evaluate results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "U, sigma, Vt = svds(ratings_np_centered, k = 1)\n",
    "sigma = np.diag(sigma)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.1 Test users evaluation - SVD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "User: 2\n",
      "Positive ratio: 93.75%\n",
      "Already Rated number of beers: 16\n",
      "\n",
      "\n",
      "User: 63\n",
      "Positive ratio: 98.67%\n",
      "Already Rated number of beers: 226\n",
      "\n",
      "\n",
      "User: 76\n",
      "Positive ratio: 81.82%\n",
      "Already Rated number of beers: 22\n",
      "\n",
      "\n",
      "User: 151\n",
      "Positive ratio: 95.00%\n",
      "Already Rated number of beers: 60\n"
     ]
    }
   ],
   "source": [
    "for user in reader.test_users[:5]:\n",
    "\n",
    "    rec_df, already_rated = svd.recommend(uid=user, reviews=reviews,U=U,sigma=sigma,Vt=Vt,user_means=user_means,rec_num=10, ratings_matrix=ratings_matrix, beer_mapping=reader.beer_mapping)\n",
    "\n",
    "    if already_rated:\n",
    "        print(f\"\\n\\nUser: {user}\")\n",
    "        print(\"Positive ratio:\", f'{list(already_rated.values()).count(\"P\")/len(already_rated.values())*100:.2f}%')\n",
    "        print(\"Already Rated number of beers:\", f'{len(already_rated.values())}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.2 User 5 evaluation - SVD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio: 93.33%\n",
      "Already Rated number of beers: 60\n"
     ]
    },
    {
     "data": {
      "text/plain": "         beer_id                                beer_name  predicted_rating  \\\n76393       1904            Sierra Nevada Celebration Ale          3.943417   \n154175      2751                   Racer 5 India Pale Ale          3.927446   \n155929      3916                             AleSmith IPA          3.904008   \n1131796      221                   Fuller's London Porter          3.902999   \n82961       6549  Northern Hemisphere Harvest Wet Hop Ale          3.902391   \n971432       646                Westmalle Trappist Tripel          3.900599   \n1362025    35738                              Hop Stoopid          3.892939   \n394065       228              Great Lakes Dortmunder Gold          3.890578   \n154433      1658                     Big Bear Black Stout          3.890358   \n45773      48434      Sierra Nevada Kellerweis Hefeweizen          3.890240   \n\n        pred_rating_discr  \n76393                   P  \n154175                  P  \n155929                  P  \n1131796                 P  \n82961                   P  \n971432                  P  \n1362025                 P  \n394065                  P  \n154433                  P  \n45773                   P  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_id</th>\n      <th>beer_name</th>\n      <th>predicted_rating</th>\n      <th>pred_rating_discr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>76393</th>\n      <td>1904</td>\n      <td>Sierra Nevada Celebration Ale</td>\n      <td>3.943417</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>154175</th>\n      <td>2751</td>\n      <td>Racer 5 India Pale Ale</td>\n      <td>3.927446</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>155929</th>\n      <td>3916</td>\n      <td>AleSmith IPA</td>\n      <td>3.904008</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>1131796</th>\n      <td>221</td>\n      <td>Fuller's London Porter</td>\n      <td>3.902999</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>82961</th>\n      <td>6549</td>\n      <td>Northern Hemisphere Harvest Wet Hop Ale</td>\n      <td>3.902391</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>971432</th>\n      <td>646</td>\n      <td>Westmalle Trappist Tripel</td>\n      <td>3.900599</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>1362025</th>\n      <td>35738</td>\n      <td>Hop Stoopid</td>\n      <td>3.892939</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>394065</th>\n      <td>228</td>\n      <td>Great Lakes Dortmunder Gold</td>\n      <td>3.890578</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>154433</th>\n      <td>1658</td>\n      <td>Big Bear Black Stout</td>\n      <td>3.890358</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>45773</th>\n      <td>48434</td>\n      <td>Sierra Nevada Kellerweis Hefeweizen</td>\n      <td>3.890240</td>\n      <td>P</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_df, already_rated = svd.recommend(uid=5, reviews=reviews,U=U,sigma=sigma,Vt=Vt,user_means=user_means,rec_num=10, ratings_matrix=ratings_matrix, beer_mapping=reader.beer_mapping)\n",
    "\n",
    "\n",
    "print(\"Positive ratio:\", f'{list(already_rated.values()).count(\"P\")/len(already_rated.values())*100:.2f}%')\n",
    "print(\"Already Rated number of beers:\", f'{len(already_rated.values())}')\n",
    "rec_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TensorFlow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "class MovieLensModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      movie_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.movie_model = movie_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    movie_embeddings = self.movie_model(features[\"beer_name\"])\n",
    "\n",
    "    return self.task(user_embeddings, movie_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jojoshulk\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\formats\\format.py:1429: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  for val, m in zip(values.ravel(), mask.ravel())\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "subset = 500000\n",
    "ds = tf.data.Dataset.from_tensor_slices(dict(pd.DataFrame(reviews.iloc[:subset]).astype('category')))\n",
    "ds_beers = tf.data.Dataset.from_tensor_slices(dict(pd.DataFrame(reviews[\"beer_name\"].drop_duplicates()).astype('category')))\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = ds.map(lambda x: {\n",
    "    \"beer_name\": x[\"beer_name\"],\n",
    "    \"user_id\": str(x[\"user_id\"])\n",
    "})\n",
    "\n",
    "movies = ds_beers.map(lambda x: x[\"beer_name\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\JOJOSH~1\\AppData\\Local\\Temp/ipykernel_22692/3606917409.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0muser_ids_vocabulary\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStringLookup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmask_token\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0muser_ids_vocabulary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madapt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mratings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"user_id\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m60\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py\u001B[0m in \u001B[0;36madapt\u001B[1;34m(self, data, batch_size, steps)\u001B[0m\n\u001B[0;32m    407\u001B[0m               \u001B[0margument\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msupported\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0marray\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    408\u001B[0m         \"\"\"\n\u001B[1;32m--> 409\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madapt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msteps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    410\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    411\u001B[0m     \u001B[1;31m# Overridden methods from IndexLookup.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\u001B[0m in \u001B[0;36madapt\u001B[1;34m(self, data, batch_size, steps)\u001B[0m\n\u001B[0;32m    255\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miterator\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menumerate_epochs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    256\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcatch_stop_iteration\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 257\u001B[1;33m                 \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    258\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_adapt_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    259\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36msteps\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1369\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Set by `catch_stop_iteration`.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1370\u001B[0m                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1371\u001B[1;33m             \u001B[0moriginal_spe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_steps_per_execution\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1372\u001B[0m             can_run_full_execution = (\n\u001B[0;32m   1373\u001B[0m                 \u001B[0moriginal_spe\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    637\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    638\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 639\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    640\u001B[0m     raise NotImplementedError(\n\u001B[0;32m    641\u001B[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001B[0m in \u001B[0;36mread_value\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    728\u001B[0m     \u001B[1;31m# Return an identity so it can get placed on whatever device the context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    729\u001B[0m     \u001B[1;31m# specifies instead of the device where the variable is.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 730\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    731\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    732\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mread_value_no_copy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mop_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m       \u001B[1;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1175\u001B[0m       \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1176\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1177\u001B[0m       \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1178\u001B[0m         \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36midentity\u001B[1;34m(input, name)\u001B[0m\n\u001B[0;32m    292\u001B[0m     \u001B[1;31m# variables. Variables have correct handle data when graph building.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m     \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m   \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m   \u001B[1;31m# Propagate handle data for happier shape inference for resource variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"_handle_data\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\resys_p1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001B[0m in \u001B[0;36midentity\u001B[1;34m(input, name)\u001B[0m\n\u001B[0;32m   4834\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4835\u001B[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[1;32m-> 4836\u001B[1;33m         _ctx, \"Identity\", name, input)\n\u001B[0m\u001B[0;32m   4837\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4838\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
    "\n",
    "print((time.time() - start)/60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies)\n",
    "\n",
    "print((time.time() - start)/60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# Define user and movie models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "movie_model = tf.keras.Sequential([\n",
    "    movie_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    movies.batch(128).map(movie_model)\n",
    "  )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25/25 [==============================] - 35s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0196 - factorized_top_k/top_10_categorical_accuracy: 0.0327 - factorized_top_k/top_50_categorical_accuracy: 0.1037 - factorized_top_k/top_100_categorical_accuracy: 0.1637 - loss: 35915.1734 - regularization_loss: 0.0000e+00 - total_loss: 35915.1734\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 39s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0353 - factorized_top_k/top_10_categorical_accuracy: 0.0519 - factorized_top_k/top_50_categorical_accuracy: 0.1134 - factorized_top_k/top_100_categorical_accuracy: 0.1642 - loss: 33772.2882 - regularization_loss: 0.0000e+00 - total_loss: 33772.2882\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 43s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 3.0000e-05 - factorized_top_k/top_10_categorical_accuracy: 3.0000e-05 - factorized_top_k/top_50_categorical_accuracy: 0.0027 - factorized_top_k/top_100_categorical_accuracy: 0.0196 - loss: 32460.5170 - regularization_loss: 0.0000e+00 - total_loss: 32460.5170\n",
      "Top 10 recommendations for user 42: [b'Riggwelter Yorkshire Ale' b'Sierra Nevada Pale Ale' b'Orchard White'\n",
      " b'Saison Rue' b'Saison De Lente' b'Doppel-Hirsch' b'Batemans XXXB'\n",
      " b'O.K. Beer' b'Castle Lager' b'Neuschwansteiner']\n",
      "Riggwelter Yorkshire Ale\n",
      "Sierra Nevada Pale Ale\n",
      "Orchard White\n",
      "Saison Rue\n",
      "Saison De Lente\n",
      "Doppel-Hirsch\n",
      "Batemans XXXB\n",
      "O.K. Beer\n",
      "Castle Lager\n",
      "Neuschwansteiner\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(user_model, movie_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ratings.batch(4096), epochs=3)\n",
    "\n",
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    movies.batch(100).map(lambda title: (title, model.movie_model(title))))\n",
    "\n",
    "# Get some recommendations.\n",
    "_, titles = index(np.array([\"5\"]))\n",
    "print(f\"Top 10 recommendations for user 42: {titles[0, :10]}\")\n",
    "for beer in titles[0, :10]:\n",
    "    print(beer.numpy().decode(\"utf-8\") )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
