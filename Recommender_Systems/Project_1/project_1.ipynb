{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chalkiopoulos Georgios, Electrical and Computer Engineer NTUA <br />\n",
    "> Data Science postgraduate Student <br />\n",
    "> gchalkiopoulos@aueb.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, fields\n",
    "from datetime import datetime\n",
    "\n",
    "from typing import List, Optional, Union, Set\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from logging import INFO, WARNING, DEBUG, ERROR\n",
    "\n",
    "# utils\n",
    "from utils.Loggers import BaseLogger\n",
    "from utils.esim import Esim\n",
    "from utils.helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Logging level"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BaseLogger.level = INFO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BeerReview(object):\n",
    "    index: int\n",
    "    brewery_id: str\n",
    "    brewery_name: str\n",
    "    review_time: datetime.timestamp\n",
    "    review_overall: float\n",
    "    review_aroma: float\n",
    "    review_appearance: float\n",
    "    review_profilename: str\n",
    "    beer_style: str\n",
    "    review_palate: float\n",
    "    review_taste: float\n",
    "    beer_name: str\n",
    "    beer_abv: float\n",
    "    beer_beerid: int\n",
    "    user_id: Optional[Union[int, None]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewReader(BaseLogger):\n",
    "    \"\"\"Read reviews based on an input file\"\"\"\n",
    "    reviews: List[BeerReview] = []\n",
    "\n",
    "    def __init__(self, file_path: str,\n",
    "                 user_reviews_threshold: int = 10,\n",
    "                 beer_reviews_threshold: int = 10,\n",
    "                 subset: float = 1.0,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.file_path = file_path\n",
    "        self.user_reviews_threshold = user_reviews_threshold\n",
    "        self.beer_reviews_threshold = beer_reviews_threshold\n",
    "        self.subset = subset\n",
    "\n",
    "        # initialize users and beers dict\n",
    "        self.users: defaultdict = defaultdict(int) # to keep track of user reviews counts\n",
    "        self.beers: defaultdict = defaultdict(int) # to keep track of beer reviews counts\n",
    "            \n",
    "        self.user_mapping: defaultdict = defaultdict(str)\n",
    "        self.beer_mapping: defaultdict = defaultdict(str)\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def input_file(self) -> Path:\n",
    "        \"\"\"\n",
    "        Creates a Path object containing the input file.\n",
    "        Raises an exception if the file doesn't exist\n",
    "\n",
    "        Returns:\n",
    "            Path object\n",
    "        \"\"\"\n",
    "        input_file: Path = Path(self.file_path)\n",
    "        if not input_file.is_file():\n",
    "            self.logger.error(f\"{input_file.name} file doesn't exist.\")\n",
    "\n",
    "        return input_file\n",
    "\n",
    "    @property\n",
    "    def valid_users(self) -> list:\n",
    "        \"\"\"Returns that have more than user_reviews_threshold reviews\"\"\"\n",
    "        return [user for user, total_ratings in self.users.items() if total_ratings >= self.user_reviews_threshold]\n",
    "\n",
    "    @property\n",
    "    def valid_beers(self) -> list:\n",
    "        \"\"\"Returns that have more than user_reviews_threshold reviews\"\"\"\n",
    "        return [beer for beer, total_ratings in self.beers.items() if total_ratings >= self.beer_reviews_threshold]\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_array(_review: BeerReview):\n",
    "        \"\"\"Select the necessary columns needed from the BeerReview object\n",
    "        user_id, review_profilename\n",
    "        beer_beerid, review_overall\n",
    "        review_aroma, review_appearance, review_taste, review_palate\"\"\"\n",
    "\n",
    "        return [_review.user_id, _review.review_profilename,\n",
    "                _review.beer_beerid,_review.beer_name, _review.beer_style,\n",
    "                _review.review_overall, _review.review_aroma, _review.review_appearance, _review.review_taste, _review.review_palate,\n",
    "                _review.brewery_id]\n",
    "\n",
    "\n",
    "    def filtered_reviews(self, reviews_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Filters the reviews dataframe to keep users based on defined thresholds\"\"\"\n",
    "\n",
    "        # filter users\n",
    "        return reviews_df.loc[(reviews_df.user_name.isin(self.valid_users))\n",
    "                              & (reviews_df.beer_id.isin(self.valid_beers))\n",
    "                            & (reviews_df.user_name != \"\")].iloc[:int((reviews_df.shape[0]*self.subset)), :]\n",
    "\n",
    "\n",
    "    def read_reviews(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Read the reviews based on the input file. Returns a list of reviews.        \"\"\"\n",
    "        with open(self.input_file, encoding=\"utf8\") as f:\n",
    "\n",
    "            self.logger.info(f\"Loading {self.input_file}\")\n",
    "\n",
    "            # initialize user_id\n",
    "            user_id: dict = {}\n",
    "            id: int = 0\n",
    "\n",
    "            for i, row in enumerate(csv.DictReader(f)):\n",
    "\n",
    "                # add user_id and user_mapping\n",
    "                if user_id.get(row[\"review_profilename\"].strip()) is None:\n",
    "                    user_id[row[\"review_profilename\"].strip()] = id                    \n",
    "                    self.user_mapping[id] = row[\"review_profilename\"].strip()\n",
    "                    id += 1\n",
    "                \n",
    "                # add beer_mapping\n",
    "                if not self.beer_mapping.get(row[\"beer_beerid\"]):\n",
    "                    self.beer_mapping[row[\"beer_beerid\"]] = row[\"beer_name\"]\n",
    "                \n",
    "                \n",
    "                # create a review object\n",
    "                review: BeerReview = BeerReview(\n",
    "                    int(row[\"index\"]) if row[\"index\"].isnumeric() else None,\n",
    "                    row[\"brewery_id\"],\n",
    "                    row[\"brewery_name\"].strip(),\n",
    "                    datetime.fromtimestamp(int(row[\"review_time\"])),\n",
    "                    float(row[\"review_overall\"]),\n",
    "                    float(row[\"review_aroma\"]),\n",
    "                    float(row[\"review_appearance\"]),\n",
    "                    row[\"review_profilename\"].strip(),\n",
    "                    row[\"beer_style\"].strip(),\n",
    "                    row[\"review_palate\"],\n",
    "                    row[\"review_taste\"],\n",
    "                    row[\"beer_name\"],\n",
    "                    row[\"beer_abv\"],\n",
    "                    int(row[\"beer_beerid\"]),\n",
    "                    user_id[row[\"review_profilename\"]])\n",
    "\n",
    "                # add the review object to the total reviews\n",
    "                self.reviews.append(self.make_array(review))\n",
    "\n",
    "                # Keep user count\n",
    "                self.users[review.review_profilename] += 1\n",
    "                self.beers[review.beer_beerid] += 1\n",
    "\n",
    "                if i % 300000 == 0 and i != 0:\n",
    "                    self.logger.info(f\"{i} reviews loaded.\")\n",
    "\n",
    "\n",
    "        self.logger.info(f\"All reviews loaded. Total reviews: {len(self.reviews)}\")\n",
    "        f.close()\n",
    "\n",
    "        # Convert to Pandas Dataframe\n",
    "        reviews_df = pd.DataFrame(self.reviews,\n",
    "                                  columns=[\"user_id\", \"user_name\",\n",
    "                                            \"beer_id\",\"beer_name\", \"beer_style\",\n",
    "                                           \"review_overall\", \"review_aroma\", \"review_appearance\", \"review_taste\", \"review_palate\",\n",
    "                                            \"brewery_id\"])\n",
    "        reviews_df.drop_duplicates(inplace=True)\n",
    "\n",
    "        return self.filtered_reviews(reviews_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-01 00:03:36,569] INFO [ReviewReader] - Loading beer_reviews.csv\n",
      "[2023-03-01 00:03:43,269] INFO [ReviewReader] - 300000 reviews loaded.\n",
      "[2023-03-01 00:03:50,532] INFO [ReviewReader] - 600000 reviews loaded.\n",
      "[2023-03-01 00:03:56,293] INFO [ReviewReader] - 900000 reviews loaded.\n",
      "[2023-03-01 00:04:02,039] INFO [ReviewReader] - 1200000 reviews loaded.\n",
      "[2023-03-01 00:04:07,727] INFO [ReviewReader] - 1500000 reviews loaded.\n",
      "[2023-03-01 00:04:11,273] INFO [ReviewReader] - All reviews loaded. Total reviews: 1586614\n"
     ]
    }
   ],
   "source": [
    "file_path: str = \"beer_reviews.csv\"\n",
    "reader = ReviewReader(file_path=file_path, subset=0.1)\n",
    "reviews: pd.DataFrame = reader.read_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (158584, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    user_id    user_name  beer_id      beer_name   beer_style  review_overall  \\\n10        7      fodeeoz      436   Amstel Light  Light Lager             3.0   \n18       15       jdhilt      436   Amstel Light  Light Lager             2.5   \n19       16  UCLABrewN84    58046  Rauch Ür Bock    Rauchbier             4.5   \n20       17   zaphodchak    58046  Rauch Ür Bock    Rauchbier             4.0   \n21       18      Tilley4    58046  Rauch Ür Bock    Rauchbier             4.0   \n\n    review_aroma  review_appearance review_taste review_palate brewery_id  \n10           2.0                3.0          2.5           2.5        163  \n18           3.0                3.0          2.0           2.0        163  \n19           4.5                3.0          4.5           4.0       1075  \n20           4.0                4.0          4.0           3.0       1075  \n21           4.5                4.0          4.0           3.5       1075  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>user_name</th>\n      <th>beer_id</th>\n      <th>beer_name</th>\n      <th>beer_style</th>\n      <th>review_overall</th>\n      <th>review_aroma</th>\n      <th>review_appearance</th>\n      <th>review_taste</th>\n      <th>review_palate</th>\n      <th>brewery_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>7</td>\n      <td>fodeeoz</td>\n      <td>436</td>\n      <td>Amstel Light</td>\n      <td>Light Lager</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>15</td>\n      <td>jdhilt</td>\n      <td>436</td>\n      <td>Amstel Light</td>\n      <td>Light Lager</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>16</td>\n      <td>UCLABrewN84</td>\n      <td>58046</td>\n      <td>Rauch Ür Bock</td>\n      <td>Rauchbier</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>3.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>1075</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>17</td>\n      <td>zaphodchak</td>\n      <td>58046</td>\n      <td>Rauch Ür Bock</td>\n      <td>Rauchbier</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1075</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>18</td>\n      <td>Tilley4</td>\n      <td>58046</td>\n      <td>Rauch Ür Bock</td>\n      <td>Rauchbier</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>1075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Item-Based and User-Based Recommendations with Hashing\n",
    "\n",
    "* Due to the size of the data, we will use Hashing in order to be able to perform calculations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-02-28 22:24:49,131] INFO [BaseLogger] - Trying to load indexer_beer_subset.pkl file.\n",
      "[2023-02-28 22:24:49,132] WARNING [BaseLogger] - indexer_beer_subset.pkl file doesn't exist. Proceeding to calculate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Loading ratings: [████████████████████████████████████████████████████████████] 1566/1566\r\n",
      "\n",
      "beer ratings processed\n",
      "beer-based index created\r indexed."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-02-28 22:25:41,447] INFO [BaseLogger] - Saving indexer_beer_subset.pkl file.\n",
      "[2023-02-28 22:25:42,691] INFO [BaseLogger] - indexer_beer_subset.pkl file saved.\n",
      "[2023-02-28 22:25:42,692] INFO [BaseLogger] - Trying to load indexer_usr_subset.pkl file.\n",
      "[2023-02-28 22:25:42,694] WARNING [BaseLogger] - indexer_usr_subset.pkl file doesn't exist. Proceeding to calculate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Loading ratings: [████████████████████████████████████████████████████████████] 9583/9583\r\n",
      "\n",
      "user ratings processed\n",
      "usr-based index created\rs indexed."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-02-28 22:28:01,343] INFO [BaseLogger] - Saving indexer_usr_subset.pkl file.\n",
      "[2023-02-28 22:28:04,632] INFO [BaseLogger] - indexer_usr_subset.pkl file saved.\n"
     ]
    }
   ],
   "source": [
    "indexer_beer = load_indexer(focus=\"beer\",\n",
    "                             reviews=reviews, beer_id_col='beer_id', user_id_col='user_id',\n",
    "                             beer_mapping=reader.beer_mapping, user_mapping=reader.user_mapping,\n",
    "                             indexer_path=\"indexer_beer_subset.pkl\")\n",
    "\n",
    "indexer_user = load_indexer(focus=\"usr\",\n",
    "                             reviews=reviews, beer_id_col='beer_id', user_id_col='user_id',\n",
    "                             beer_mapping=reader.beer_mapping, user_mapping=reader.user_mapping,\n",
    "                             indexer_path=\"indexer_usr_subset.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I suggest the following beers because they have received positive ratings\n",
      "from users who tend to like what you like:\n",
      "\n",
      "\n",
      " 1904 Sierra Nevada Celebration Ale 173.26021184610593\n",
      "\n",
      " 2751 Racer 5 India Pale Ale 159.4540317927605\n",
      "\n",
      " 6549 Northern Hemisphere Harvest Wet Hop Ale 125.42356879863041\n",
      "\n",
      " 7348 Founders Porter 120.33105725423805\n",
      "\n",
      " 33644 B.O.R.I.S. The Crusher Oatmeal-Imperial Stout 106.89627620980662\n",
      "\n",
      " 48434 Sierra Nevada Kellerweis Hefeweizen 101.81794420610073\n",
      "\n",
      " 7463 Founders Dirty Bastard 98.8171774678231\n",
      "\n",
      " 283 Sierra Nevada Stout 92.61508135562863\n",
      "\n",
      " 47658 Founders CBS Imperial Stout 88.0095267433147\n",
      "\n",
      " 1658 Big Bear Black Stout 87.52241823901221\n"
     ]
    }
   ],
   "source": [
    "already_rated = recommend_ub(indexer_user, user=5, rec_num=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I suggest the following beers because they are similar to the beers you already like:\n",
      "\n",
      "\n",
      " 33644 B.O.R.I.S. The Crusher Oatmeal-Imperial Stout 5.292497785676612\n",
      "\n",
      " 7348 Founders Porter 4.755895965254549\n",
      "\n",
      " 6549 Northern Hemisphere Harvest Wet Hop Ale 4.595827154944165\n",
      "\n",
      " 2751 Racer 5 India Pale Ale 4.2599818067698365\n",
      "\n",
      " 48434 Sierra Nevada Kellerweis Hefeweizen 3.6296267722769553\n",
      "\n",
      " 47658 Founders CBS Imperial Stout 3.6202756962742395\n",
      "\n",
      " 1658 Big Bear Black Stout 3.5124413421421354\n",
      "\n",
      " 49286 Mokah 3.4997675126927885\n",
      "\n",
      " 7463 Founders Dirty Bastard 3.355135886452315\n",
      "\n",
      " 1904 Sierra Nevada Celebration Ale 3.1824369219308495\n"
     ]
    }
   ],
   "source": [
    "already_rated = recommend_mb(indexer_beer, user=5, rec_num=10, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-02-28 22:30:19,893] INFO [BaseLogger] - Docs created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 9583\n"
     ]
    }
   ],
   "source": [
    "import tomotopy as tp\n",
    "\n",
    "# discretize ratings\n",
    "reviews[\"rating\"] = reviews.apply(lambda x: Esim.discretize_rating(x[\"review_overall\"]), axis=1)\n",
    "\n",
    "reivews_user = reviews[[\"user_id\", \"beer_id\", \"rating\"]].groupby('user_id').apply(lambda x: list(x['beer_id'].str.cat(x['rating'])))\n",
    "\n",
    "print(\"Number of users:\", reivews_user.shape[0])\n",
    "reivews_user.head()\n",
    "\n",
    "docs: dict = dict(zip(reivews_user.index, reivews_user.values))\n",
    "BaseLogger().logger.info(\"Docs created.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-02-28 22:39:02,879] INFO [BaseLogger] - Iteration: 0\tLog-likelihood: -7.269106293037566\tk: 3\n",
      "[2023-02-28 22:39:03,029] INFO [BaseLogger] - Iteration: 20\tLog-likelihood: -7.185922215075826\tk: 3\n",
      "[2023-02-28 22:39:03,218] INFO [BaseLogger] - Iteration: 40\tLog-likelihood: -7.151881912767065\tk: 3\n",
      "[2023-02-28 22:39:03,433] INFO [BaseLogger] - Iteration: 60\tLog-likelihood: -7.138551838631168\tk: 3\n",
      "[2023-02-28 22:39:03,613] INFO [BaseLogger] - Iteration: 80\tLog-likelihood: -7.134495909027678\tk: 3\n",
      "[2023-02-28 22:39:03,788] INFO [BaseLogger] - Iteration: 100\tLog-likelihood: -7.129393466905827\tk: 3\n",
      "[2023-02-28 22:39:03,965] INFO [BaseLogger] - Iteration: 120\tLog-likelihood: -7.1297267411696845\tk: 3\n",
      "[2023-02-28 22:39:04,124] INFO [BaseLogger] - Iteration: 140\tLog-likelihood: -7.125713644413285\tk: 3\n",
      "[2023-02-28 22:39:04,291] INFO [BaseLogger] - Iteration: 160\tLog-likelihood: -7.1243277112538745\tk: 3\n",
      "[2023-02-28 22:39:04,439] INFO [BaseLogger] - Iteration: 180\tLog-likelihood: -7.1234853921969945\tk: 3\n",
      "[2023-02-28 22:39:04,556] INFO [BaseLogger] - Iteration: 200\tLog-likelihood: -7.122160319106036\tk: 3\n",
      "[2023-02-28 22:39:04,683] INFO [BaseLogger] - Iteration: 220\tLog-likelihood: -7.12243259176719\tk: 3\n",
      "[2023-02-28 22:39:04,815] INFO [BaseLogger] - Iteration: 240\tLog-likelihood: -7.126303476632372\tk: 3\n",
      "[2023-02-28 22:39:04,961] INFO [BaseLogger] - Iteration: 260\tLog-likelihood: -7.1209790264685005\tk: 3\n",
      "[2023-02-28 22:39:05,116] INFO [BaseLogger] - Iteration: 280\tLog-likelihood: -7.120283033649372\tk: 3\n",
      "[2023-02-28 22:39:05,226] INFO [BaseLogger] - Iteration: 300\tLog-likelihood: -7.118582871877901\tk: 3\n",
      "[2023-02-28 22:39:05,354] INFO [BaseLogger] - Iteration: 320\tLog-likelihood: -7.114737069917087\tk: 3\n",
      "[2023-02-28 22:39:05,475] INFO [BaseLogger] - Iteration: 340\tLog-likelihood: -7.115908770554991\tk: 3\n",
      "[2023-02-28 22:39:05,589] INFO [BaseLogger] - Iteration: 360\tLog-likelihood: -7.117795839994629\tk: 3\n",
      "[2023-02-28 22:39:05,703] INFO [BaseLogger] - Iteration: 380\tLog-likelihood: -7.112950151528465\tk: 3\n",
      "[2023-02-28 22:39:05,810] INFO [BaseLogger] - Iteration: 400\tLog-likelihood: -7.114449463753311\tk: 3\n",
      "[2023-02-28 22:39:05,917] INFO [BaseLogger] - Iteration: 420\tLog-likelihood: -7.114110819278084\tk: 3\n",
      "[2023-02-28 22:39:06,031] INFO [BaseLogger] - Iteration: 440\tLog-likelihood: -7.114830383806835\tk: 3\n",
      "[2023-02-28 22:39:06,139] INFO [BaseLogger] - Iteration: 460\tLog-likelihood: -7.111633957041416\tk: 3\n",
      "[2023-02-28 22:39:06,260] INFO [BaseLogger] - Iteration: 480\tLog-likelihood: -7.1132881111652715\tk: 3\n",
      "[2023-02-28 22:39:06,493] INFO [BaseLogger] - Iteration: 0\tLog-likelihood: -7.453568861843718\tk: 5\n",
      "[2023-02-28 22:39:06,630] INFO [BaseLogger] - Iteration: 20\tLog-likelihood: -7.294628333859061\tk: 5\n",
      "[2023-02-28 22:39:06,750] INFO [BaseLogger] - Iteration: 40\tLog-likelihood: -7.211862314787322\tk: 5\n",
      "[2023-02-28 22:39:06,870] INFO [BaseLogger] - Iteration: 60\tLog-likelihood: -7.18129716572829\tk: 5\n",
      "[2023-02-28 22:39:06,991] INFO [BaseLogger] - Iteration: 80\tLog-likelihood: -7.1617098862066335\tk: 5\n",
      "[2023-02-28 22:39:07,128] INFO [BaseLogger] - Iteration: 100\tLog-likelihood: -7.152940302366908\tk: 5\n",
      "[2023-02-28 22:39:07,250] INFO [BaseLogger] - Iteration: 120\tLog-likelihood: -7.140652065576198\tk: 5\n",
      "[2023-02-28 22:39:07,374] INFO [BaseLogger] - Iteration: 140\tLog-likelihood: -7.13164626490974\tk: 5\n",
      "[2023-02-28 22:39:07,500] INFO [BaseLogger] - Iteration: 160\tLog-likelihood: -7.128918381721602\tk: 5\n",
      "[2023-02-28 22:39:07,616] INFO [BaseLogger] - Iteration: 180\tLog-likelihood: -7.121592995404772\tk: 5\n",
      "[2023-02-28 22:39:07,740] INFO [BaseLogger] - Iteration: 200\tLog-likelihood: -7.119794744675169\tk: 5\n",
      "[2023-02-28 22:39:07,861] INFO [BaseLogger] - Iteration: 220\tLog-likelihood: -7.119043832860656\tk: 5\n",
      "[2023-02-28 22:39:07,986] INFO [BaseLogger] - Iteration: 240\tLog-likelihood: -7.11474686062759\tk: 5\n",
      "[2023-02-28 22:39:08,111] INFO [BaseLogger] - Iteration: 260\tLog-likelihood: -7.111218619203343\tk: 5\n",
      "[2023-02-28 22:39:08,246] INFO [BaseLogger] - Iteration: 280\tLog-likelihood: -7.113716177612653\tk: 5\n",
      "[2023-02-28 22:39:08,367] INFO [BaseLogger] - Iteration: 300\tLog-likelihood: -7.112116836243312\tk: 5\n",
      "[2023-02-28 22:39:08,494] INFO [BaseLogger] - Iteration: 320\tLog-likelihood: -7.114844187546142\tk: 5\n",
      "[2023-02-28 22:39:08,614] INFO [BaseLogger] - Iteration: 340\tLog-likelihood: -7.111659642273996\tk: 5\n",
      "[2023-02-28 22:39:08,746] INFO [BaseLogger] - Iteration: 360\tLog-likelihood: -7.111631090512186\tk: 5\n",
      "[2023-02-28 22:39:08,868] INFO [BaseLogger] - Iteration: 380\tLog-likelihood: -7.1114601938614275\tk: 5\n",
      "[2023-02-28 22:39:08,991] INFO [BaseLogger] - Iteration: 400\tLog-likelihood: -7.11120232733695\tk: 5\n",
      "[2023-02-28 22:39:09,114] INFO [BaseLogger] - Iteration: 420\tLog-likelihood: -7.108692401258708\tk: 5\n",
      "[2023-02-28 22:39:09,246] INFO [BaseLogger] - Iteration: 440\tLog-likelihood: -7.1045615516585325\tk: 5\n",
      "[2023-02-28 22:39:09,374] INFO [BaseLogger] - Iteration: 460\tLog-likelihood: -7.106477229929576\tk: 5\n",
      "[2023-02-28 22:39:09,492] INFO [BaseLogger] - Iteration: 480\tLog-likelihood: -7.107436781366791\tk: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "(440, -7.1045615516585325, 5)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "min_likelihood = -100\n",
    "for k in range(3, 7, 2):\n",
    "    #new LDA model\n",
    "    lda = tp.LDAModel(k=k)\n",
    "\n",
    "    for doc in docs:\n",
    "        lda.add_doc(docs[doc])\n",
    "\n",
    "    #train LDA model\n",
    "    for i in range(0, 500, 20):\n",
    "        lda.train(20)\n",
    "        BaseLogger().logger.info('Iteration: {}\\tLog-likelihood: {}\\tk: {}'.format(i, lda.ll_per_word, k))\n",
    "        if lda.ll_per_word > min_likelihood:\n",
    "            min_data = (i, lda.ll_per_word, k)\n",
    "            min_likelihood = lda.ll_per_word\n",
    "            best_lda = lda\n",
    "min_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "('Sierra Nevada Pale Ale', 'American Pale Ale (APA)', 'P')\n",
      "('Sierra Nevada Celebration Ale', 'American IPA', 'P')\n",
      "('Sierra Nevada Porter', 'American Porter', 'P')\n",
      "('Sierra Nevada Summerfest Lager', 'Czech Pilsener', 'P')\n",
      "('Heineken Lager Beer', 'Euro Pale Lager', 'A')\n",
      "('Sierra Nevada Bigfoot Barleywine Style Ale', 'American Barleywine', 'P')\n",
      "('Sierra Nevada Stout', 'American Stout', 'P')\n",
      "('Pilsner Urquell', 'Czech Pilsener', 'P')\n",
      "('Hop Rod Rye', 'Rye Beer', 'P')\n",
      "('Red Stripe Jamaican Lager', 'American Adjunct Lager', 'A')\n",
      "--------------------------------------\n",
      "\n",
      "1\n",
      "('High Tide Fresh Hop IPA', 'American IPA', 'P')\n",
      "('Hop 15', 'American Double / Imperial IPA', 'P')\n",
      "('Old Viscosity', 'American Double / Imperial Stout', 'P')\n",
      "('Wipeout I.P.A.', 'American IPA', 'P')\n",
      "('Racer X', 'American Double / Imperial IPA', 'P')\n",
      "('Older Viscosity', 'American Double / Imperial Stout', 'P')\n",
      "(\"Santa's Little Helper\", 'Russian Imperial Stout', 'P')\n",
      "('Racer 5 India Pale Ale', 'American IPA', 'P')\n",
      "('Hop Rod Rye', 'Rye Beer', 'P')\n",
      "('Midnight Expression', 'Schwarzbier', 'P')\n",
      "--------------------------------------\n",
      "\n",
      "2\n",
      "('St-Ambroise Oatmeal Stout', 'Oatmeal Stout', 'P')\n",
      "('Heineken Lager Beer', 'Euro Pale Lager', 'A')\n",
      "('Hacker-Pschorr Hefe Weisse Natürtrub', 'Hefeweizen', 'P')\n",
      "('Pilsner Urquell', 'Czech Pilsener', 'P')\n",
      "('St-Ambroise Pale Ale', 'American Pale Ale (APA)', 'P')\n",
      "('Aecht Schlenkerla Rauchbier Märzen', 'Rauchbier', 'P')\n",
      "('Asahi Super Dry', 'Japanese Rice Lager', 'A')\n",
      "('Weltenburger Kloster Asam-Bock', 'Doppelbock', 'P')\n",
      "('Creemore Springs Premium Lager', 'American Amber / Red Lager', 'P')\n",
      "('Duchesse De Bourgogne', 'Flanders Red Ale', 'P')\n",
      "--------------------------------------\n",
      "\n",
      "3\n",
      "('Founders KBS (Kentucky Breakfast Stout)', 'American Double / Imperial Stout', 'P')\n",
      "('Founders CBS Imperial Stout', 'American Double / Imperial Stout', 'P')\n",
      "('Jai Alai IPA', 'American IPA', 'P')\n",
      "(\"Hunahpu's Imperial Stout\", 'American Double / Imperial Stout', 'P')\n",
      "('Founders Breakfast Stout', 'American Double / Imperial Stout', 'P')\n",
      "('Maduro Oatmeal Brown Ale', 'American Brown Ale', 'P')\n",
      "('Founders Backwoods Bastard', 'Scotch Ale / Wee Heavy', 'P')\n",
      "('Jai Alai IPA - Cedar Aged (Humidor Series)', 'American IPA', 'P')\n",
      "('Founders Imperial Stout', 'Russian Imperial Stout', 'P')\n",
      "('Guava Grove Saison', 'Saison / Farmhouse Ale', 'P')\n",
      "--------------------------------------\n",
      "\n",
      "4\n",
      "('Founders Breakfast Stout', 'American Double / Imperial Stout', 'P')\n",
      "('Sierra Nevada Torpedo Extra IPA', 'American IPA', 'P')\n",
      "('Sierra Nevada Celebration Ale', 'American IPA', 'P')\n",
      "('Racer 5 India Pale Ale', 'American IPA', 'P')\n",
      "('Sierra Nevada Bigfoot Barleywine Style Ale', 'American Barleywine', 'P')\n",
      "('Founders KBS (Kentucky Breakfast Stout)', 'American Double / Imperial Stout', 'P')\n",
      "(\"Founders Red's Rye PA\", 'Rye Beer', 'P')\n",
      "('Founders Centennial IPA', 'American IPA', 'P')\n",
      "('Hop Rod Rye', 'Rye Beer', 'P')\n",
      "('Sierra Nevada Southern Hemisphere Harvest Fresh Hop Ale', 'American IPA', 'P')\n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print topic info\n",
    "for k in range(best_lda.k):\n",
    "\n",
    "    topk_words=[pair[0] for pair in best_lda.get_topic_words(k, top_n=100)]\n",
    "\n",
    "    titles=[(reviews[reviews.beer_id==label[:-1]].beer_name.array[0],reviews[reviews.beer_id==label[:-1]].beer_style.array[0],label[-1]) for label in topk_words]\n",
    "    print(k)\n",
    "    for title in titles[:10]:\n",
    "        print(title)\n",
    "    print('--------------------------------------')\n",
    "\n",
    "\n",
    "    print()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "beer_id     4         11        12        13        80        81        82     \\\nuser_id                                                                         \n0        3.874045  3.874045  3.874045  3.874045  3.874045  3.874045  3.874045   \n1        3.874045  3.874045  3.874045  3.874045  3.874045  5.000000  3.874045   \n2        3.874045  3.874045  3.874045  3.874045  3.874045  3.874045  3.874045   \n3        3.874045  3.500000  4.500000  3.000000  4.000000  4.000000  3.000000   \n4        3.874045  3.874045  3.874045  3.874045  3.874045  3.874045  3.874045   \n\nbeer_id     175       176       178    ...     74898     75087     75160  \\\nuser_id                                ...                                 \n0        3.874045  3.874045  3.874045  ...  3.874045  3.874045  3.874045   \n1        3.874045  3.874045  3.874045  ...  3.874045  3.874045  3.874045   \n2        3.874045  3.874045  3.874045  ...  3.500000  2.500000  3.874045   \n3        3.874045  3.874045  3.874045  ...  3.874045  3.874045  3.874045   \n4        3.874045  3.874045  3.874045  ...  3.874045  3.874045  3.874045   \n\nbeer_id     75491     75559     75907     76028     76348     76440     76816  \nuser_id                                                                        \n0        3.874045  3.874045  3.874045  3.874045  3.874045  3.874045  3.874045  \n1        3.874045  3.874045  3.874045  4.000000  3.874045  3.874045  3.874045  \n2        3.874045  3.874045  3.500000  4.000000  3.874045  3.874045  3.874045  \n3        3.874045  3.874045  3.874045  3.874045  3.874045  3.874045  3.874045  \n4        3.874045  3.500000  3.874045  3.874045  3.874045  3.874045  3.874045  \n\n[5 rows x 1566 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>beer_id</th>\n      <th>4</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>80</th>\n      <th>81</th>\n      <th>82</th>\n      <th>175</th>\n      <th>176</th>\n      <th>178</th>\n      <th>...</th>\n      <th>74898</th>\n      <th>75087</th>\n      <th>75160</th>\n      <th>75491</th>\n      <th>75559</th>\n      <th>75907</th>\n      <th>76028</th>\n      <th>76348</th>\n      <th>76440</th>\n      <th>76816</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>...</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>5.000000</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>...</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>4.000000</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>...</td>\n      <td>3.500000</td>\n      <td>2.500000</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.500000</td>\n      <td>4.000000</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.874045</td>\n      <td>3.500000</td>\n      <td>4.500000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>...</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>...</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.500000</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n      <td>3.874045</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1566 columns</p>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ratings frame to a user X movies matrix\n",
    "ratings_matrix = reviews.sort_values(by=[\"user_id\", \"beer_id\"])[[\"user_id\", \"beer_id\", \"review_overall\"]].drop_duplicates().pivot_table(index = 'user_id', columns ='beer_id', values = 'review_overall').fillna(reviews.review_overall.mean())\n",
    "ratings_matrix.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3.87404467, 3.87404467, 3.87404467, ..., 3.87404467, 3.87404467,\n        3.87404467],\n       [3.87404467, 3.87404467, 3.87404467, ..., 3.87404467, 3.87404467,\n        3.87404467],\n       [3.87404467, 3.87404467, 3.87404467, ..., 3.87404467, 3.87404467,\n        3.87404467],\n       ...,\n       [3.87404467, 3.87404467, 3.87404467, ..., 3.87404467, 3.87404467,\n        3.87404467],\n       [3.87404467, 3.87404467, 3.87404467, ..., 3.87404467, 3.87404467,\n        3.87404467],\n       [3.87404467, 3.87404467, 3.87404467, ..., 3.87404467, 3.87404467,\n        3.87404467]])"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the matrix into an array\n",
    "ratings_np = ratings_matrix.values\n",
    "ratings_np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "(9583,)"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#compute the average rating per user\n",
    "user_means=np.mean(ratings_np, axis = 1)\n",
    "user_means.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "(9583, 1566)"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtract the mean from each rating\n",
    "ratings_np_centered = ratings_np - user_means.reshape(-1, 1)\n",
    "ratings_np_centered\n",
    "\n",
    "#unique user and movie num\n",
    "user_num = reviews.user_id.unique().shape[0]\n",
    "movie_num = reviews.beer_id.unique().shape[0]\n",
    "\n",
    "user_num,movie_num"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989\n"
     ]
    }
   ],
   "source": [
    "sparsity = round(1.0 - len(reviews) / float(user_num * movie_num), 3)\n",
    "print (sparsity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "#svd library\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#perform svd with k singular values (features)\n",
    "U, sigma, Vt = svds(ratings_np_centered, k = 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "(9583, 50)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "(50,)"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 1566)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "sigma = np.diag(sigma) # put the singular values in a diag matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 50)"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[16.56594438,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        , 16.61405619,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        , 16.70747356, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [ 0.        ,  0.        ,  0.        , ..., 34.4742787 ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n        40.71782598,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        , 60.95235791]])"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "def recommend(uid:int,\n",
    "              reviews:pd.DataFrame,\n",
    "              U:np.ndarray,\n",
    "              sigma:np.ndarray,\n",
    "              Vt:np.ndarray,\n",
    "              user_means:np.ndarray,\n",
    "              rec_num:int,\n",
    "              ratings_matrix:pd.DataFrame\n",
    "             ):\n",
    "\n",
    "    #get all the ratings by this user\n",
    "    my_ratings=reviews[[\"user_id\", \"beer_id\", \"review_overall\"]][reviews.user_id==uid]\n",
    "\n",
    "    # beers df\n",
    "    beers_df = reviews[[\"beer_id\", \"beer_name\", \"beer_style\"]].drop_duplicates()\n",
    "\n",
    "    #zip the ratings into a dict\n",
    "    already_rated=dict(zip(my_ratings.beer_id,my_ratings.review_overall))\n",
    "\n",
    "    #predict the rating of this user for all movies\n",
    "    predicted_ratings=np.dot(np.dot(U[uid-1], sigma),Vt)+user_means[uid-1]\n",
    "\n",
    "    # get the indexes of the ratings sorted in descending order\n",
    "    indexes_sorted=np.argsort(predicted_ratings)[::-1]\n",
    "\n",
    "    # get the scores for the sorted indexes\n",
    "\n",
    "    predicted_ratings_sorted=predicted_ratings[indexes_sorted]\n",
    "\n",
    "    # get the original movie indexes\n",
    "    original_indexes_sorted=[ratings_matrix.columns[i] for i in indexes_sorted]\n",
    "\n",
    "    pred_dict=dict(zip(original_indexes_sorted,predicted_ratings_sorted))\n",
    "\n",
    "    rec_set=set()# set of movie ids to be recommended\n",
    "\n",
    "    for mid in original_indexes_sorted: # for each movie id\n",
    "        if mid not in already_rated: # movie has not already been rated\n",
    "            rec_set.add(mid) # add to the set\n",
    "\n",
    "            if len(rec_set)==rec_num:break\n",
    "\n",
    "    # make a data frame with only the recommended movies\n",
    "    rec_df=pd.DataFrame(beers_df[beers_df.beer_id.isin(rec_set)])\n",
    "\n",
    "    #add the predicted rating as a new column\n",
    "    rec_df['predicted_rating']=rec_df['beer_id'].map(pred_dict)\n",
    "\n",
    "    #sort the df by the new col\n",
    "    rec_df=rec_df.sort_values(['predicted_rating'], ascending=False)\n",
    "\n",
    "    return rec_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "        beer_id                                   beer_name  \\\n140067    47022                    Hunahpu's Imperial Stout   \n124964    50081  Jai Alai IPA - Cedar Aged (Humidor Series)   \n58570     51257                               Black Tuesday   \n132191    47731                    Maduro Oatmeal Brown Ale   \n36969     16638                       Cherry Chocolate Beer   \n82961      6549     Northern Hemisphere Harvest Wet Hop Ale   \n115194    45973             Marshal Zhukov's Imperial Stout   \n68590      3981                                        Hite   \n154433     1658                        Big Bear Black Stout   \n56140     42434                                  Saison Rue   \n\n                              beer_style  predicted_rating  \n140067  American Double / Imperial Stout          4.161550  \n124964                      American IPA          4.075355  \n58570   American Double / Imperial Stout          4.074444  \n132191                American Brown Ale          4.063899  \n36969             Fruit / Vegetable Beer          4.033394  \n82961                       American IPA          4.003618  \n115194            Russian Imperial Stout          3.999396  \n68590                    Euro Pale Lager          3.986999  \n154433  American Double / Imperial Stout          3.978038  \n56140             Saison / Farmhouse Ale          3.972606  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_id</th>\n      <th>beer_name</th>\n      <th>beer_style</th>\n      <th>predicted_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>140067</th>\n      <td>47022</td>\n      <td>Hunahpu's Imperial Stout</td>\n      <td>American Double / Imperial Stout</td>\n      <td>4.161550</td>\n    </tr>\n    <tr>\n      <th>124964</th>\n      <td>50081</td>\n      <td>Jai Alai IPA - Cedar Aged (Humidor Series)</td>\n      <td>American IPA</td>\n      <td>4.075355</td>\n    </tr>\n    <tr>\n      <th>58570</th>\n      <td>51257</td>\n      <td>Black Tuesday</td>\n      <td>American Double / Imperial Stout</td>\n      <td>4.074444</td>\n    </tr>\n    <tr>\n      <th>132191</th>\n      <td>47731</td>\n      <td>Maduro Oatmeal Brown Ale</td>\n      <td>American Brown Ale</td>\n      <td>4.063899</td>\n    </tr>\n    <tr>\n      <th>36969</th>\n      <td>16638</td>\n      <td>Cherry Chocolate Beer</td>\n      <td>Fruit / Vegetable Beer</td>\n      <td>4.033394</td>\n    </tr>\n    <tr>\n      <th>82961</th>\n      <td>6549</td>\n      <td>Northern Hemisphere Harvest Wet Hop Ale</td>\n      <td>American IPA</td>\n      <td>4.003618</td>\n    </tr>\n    <tr>\n      <th>115194</th>\n      <td>45973</td>\n      <td>Marshal Zhukov's Imperial Stout</td>\n      <td>Russian Imperial Stout</td>\n      <td>3.999396</td>\n    </tr>\n    <tr>\n      <th>68590</th>\n      <td>3981</td>\n      <td>Hite</td>\n      <td>Euro Pale Lager</td>\n      <td>3.986999</td>\n    </tr>\n    <tr>\n      <th>154433</th>\n      <td>1658</td>\n      <td>Big Bear Black Stout</td>\n      <td>American Double / Imperial Stout</td>\n      <td>3.978038</td>\n    </tr>\n    <tr>\n      <th>56140</th>\n      <td>42434</td>\n      <td>Saison Rue</td>\n      <td>Saison / Farmhouse Ale</td>\n      <td>3.972606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(5, reviews,U,sigma,Vt,user_means,10, ratings_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def validate(uid:int,\n",
    "              reviews:pd.DataFrame,\n",
    "              U:np.ndarray,\n",
    "              sigma:np.ndarray,\n",
    "              Vt:np.ndarray,\n",
    "              user_means:np.ndarray,\n",
    "              ratings_matrix:pd.DataFrame\n",
    "             ):\n",
    "\n",
    "    #get all the ratings by this user\n",
    "    my_ratings=reviews[[\"user_id\", \"beer_id\", \"review_overall\"]][reviews.user_id==uid]\n",
    "\n",
    "    # beers df\n",
    "    beers_df = reviews[[\"beer_id\", \"beer_name\", \"beer_style\"]].drop_duplicates()\n",
    "\n",
    "    #zip the ratings into a dict\n",
    "    already_rated=dict(zip(my_ratings.beer_id,my_ratings.review_overall))\n",
    "\n",
    "    #predict the rating of this user for all movies\n",
    "    predicted_ratings=np.dot(np.dot(U[uid-1], sigma),Vt)+user_means[uid-1]\n",
    "\n",
    "    # get the indexes of the ratings sorted in descending order\n",
    "    indexes_sorted=np.argsort(predicted_ratings)[::-1]\n",
    "\n",
    "    # get the scores for the sorted indexes\n",
    "    predicted_ratings_sorted=predicted_ratings[indexes_sorted]\n",
    "\n",
    "    # get the original movie indexes\n",
    "    original_indexes=[ratings_matrix.columns[i] for i in indexes_sorted]\n",
    "\n",
    "    pred_dict=dict(zip(original_indexes,predicted_ratings_sorted))\n",
    "\n",
    "    actual,pred=[],[]\n",
    "    for mid in already_rated: # movie has not already been rated\n",
    "        actual.append(already_rated[mid])\n",
    "        pred.append(pred_dict[mid])\n",
    "\n",
    "    return mean_squared_error(actual,pred,squared=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "0.43703330428654824"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(5, reviews,U,sigma,Vt,user_means,ratings_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import libraries from Surprise package\n",
    "from surprise import Reader, Dataset, SVD\n",
    "\n",
    "# Load Reader library\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "# Load ratings dataset with Dataset library\n",
    "data = Dataset.load_from_df(reviews[['user_id', 'beer_id', 'review_overall']].drop_duplicates(), reader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.5819  0.5829  0.5763  0.5824  0.5883  0.5824  0.0038  \n",
      "Fit time          1.84    1.32    1.01    1.86    1.01    1.41    0.38    \n",
      "Test time         0.71    0.32    0.34    0.47    0.30    0.43    0.15    \n",
      "done\n",
      "25\n",
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.5791  0.5811  0.5853  0.5850  0.5848  0.5831  0.0025  \n",
      "Fit time          1.12    1.14    1.19    1.14    1.14    1.15    0.02    \n",
      "Test time         0.31    0.30    0.30    0.32    0.31    0.31    0.01    \n",
      "done\n",
      "50\n",
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.5866  0.5864  0.5883  0.5808  0.5840  0.5852  0.0026  \n",
      "Fit time          1.27    1.33    1.31    1.32    1.32    1.31    0.02    \n",
      "Test time         0.31    0.30    0.30    0.31    0.32    0.31    0.01    \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection.validation import cross_validate\n",
    "\n",
    "\n",
    "for factors in [10, 25, 50]:\n",
    "    print(factors)\n",
    "    # Use the SVD algorithm.\n",
    "    svd = SVD(n_factors=factors)\n",
    "\n",
    "    # Compute the RMSE of the SVD algorithm.\n",
    "    cross_validate(svd, data, measures=['RMSE'],cv=5,verbose=True)\n",
    "    print(\"done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x20caf9b7d08>"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a training set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "svd.fit(trainset)# fit the svd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "def recommend_surprise(uid:int,\n",
    "              reviews:pd.core.frame.DataFrame,\n",
    "              model,\n",
    "              rec_num:int\n",
    "             ):\n",
    "\n",
    "    #get all the ratings by this user\n",
    "    my_ratings=reviews[[\"user_id\", \"beer_id\", \"review_overall\"]][reviews.user_id==uid]\n",
    "\n",
    "    # beers df\n",
    "    beers_df = reviews[[\"beer_id\", \"beer_name\", \"beer_style\"]].drop_duplicates()\n",
    "\n",
    "    #zip the ratings into a dict\n",
    "    already_rated=dict(zip(my_ratings.beer_id,my_ratings.review_overall))\n",
    "\n",
    "    pred_dict={}# store predicted ratings\n",
    "\n",
    "    for index,row in beers_df.iterrows(): # for every movie\n",
    "\n",
    "        pred_dict[row.beer_id]=model.predict(uid=uid,iid= row.beer_id).est# get the pred for this user\n",
    "\n",
    "    # sort the movies by predicted ratings\n",
    "    srt=sorted(pred_dict.items(),key=lambda x:x[1],reverse=True)\n",
    "\n",
    "    rec_set=set()# set of movie ids to be recommended\n",
    "\n",
    "    for mid,pred in srt: # for each movie id\n",
    "        if mid not in already_rated: # movie has not already been rated\n",
    "\n",
    "            rec_set.add(mid) # add to the set\n",
    "\n",
    "            if len(rec_set)==rec_num:break\n",
    "\n",
    "    # make a data frame with only the recommended movies\n",
    "    rec_df=pd.DataFrame(beers_df[beers_df.beer_id.isin(rec_set)])\n",
    "\n",
    "    #add the predicted rating as a new column\n",
    "    rec_df['predicted_rating']=rec_df['beer_id'].map(pred_dict)\n",
    "\n",
    "    #sort the df by the new col\n",
    "    rec_df=rec_df.sort_values(['predicted_rating'], ascending=False)\n",
    "\n",
    "    return rec_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "        beer_id                                          beer_name  \\\n16137     47658                        Founders CBS Imperial Stout   \n62924     69569                    Cuir (100% Bourbon Barrel Aged)   \n132108    65472            Nickel Bag - O'Brien's 17th Anniversary   \n139796    56764  Hunahpu's Imperial Stout - Laird's Apple Brand...   \n135235    18201                                   Mo' Betta Bretta   \n64110     51557                                      Humulus Lager   \n16850     69894                     Founders Cashew Mountain Brown   \n135260     5933                                   Frank Double IPA   \n144570    54647     Hunahpu's Imperial Stout - Bourbon Barrel Aged   \n63926     50668                        Papier (Rye Whiskey Barrel)   \n134386    21383                                      Lou P Lin IPA   \n135322    52390                                         Pseudo IPA   \n61306     68676                                       The Wanderer   \n141012    67483                                       Nielsbohrium   \n59765     63149                                    Humulus Session   \n132310    60282                                          Cho-Saiko   \n145044    67124     Marshal Zhukov's Imperial Stout - 4 Roses Aged   \n59786     63724                       Oude Tart With Sour Cherries   \n13898     65528                               Mathias Imperial IPA   \n3359      72827                             Barrel Aged Naked Evil   \n\n                                beer_style  predicted_rating  \n16137     American Double / Imperial Stout          4.677580  \n62924                              Old Ale          4.595334  \n132108      American Double / Imperial IPA          4.581614  \n139796    American Double / Imperial Stout          4.534668  \n135235                   American Wild Ale          4.514267  \n64110   American Double / Imperial Pilsner          4.490672  \n16850                   American Brown Ale          4.473522  \n135260      American Double / Imperial IPA          4.452857  \n144570    American Double / Imperial Stout          4.446617  \n63926                              Old Ale          4.446371  \n134386      American Double / Imperial IPA          4.429394  \n135322                        American IPA          4.425322  \n61306                    American Wild Ale          4.425102  \n141012    American Double / Imperial Stout          4.419616  \n59765              American Pale Ale (APA)          4.405686  \n132310      American Double / Imperial IPA          4.405192  \n145044              Russian Imperial Stout          4.401505  \n59786                    American Wild Ale          4.394440  \n13898       American Double / Imperial IPA          4.390701  \n3359                    English Barleywine          4.387421  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_id</th>\n      <th>beer_name</th>\n      <th>beer_style</th>\n      <th>predicted_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16137</th>\n      <td>47658</td>\n      <td>Founders CBS Imperial Stout</td>\n      <td>American Double / Imperial Stout</td>\n      <td>4.677580</td>\n    </tr>\n    <tr>\n      <th>62924</th>\n      <td>69569</td>\n      <td>Cuir (100% Bourbon Barrel Aged)</td>\n      <td>Old Ale</td>\n      <td>4.595334</td>\n    </tr>\n    <tr>\n      <th>132108</th>\n      <td>65472</td>\n      <td>Nickel Bag - O'Brien's 17th Anniversary</td>\n      <td>American Double / Imperial IPA</td>\n      <td>4.581614</td>\n    </tr>\n    <tr>\n      <th>139796</th>\n      <td>56764</td>\n      <td>Hunahpu's Imperial Stout - Laird's Apple Brand...</td>\n      <td>American Double / Imperial Stout</td>\n      <td>4.534668</td>\n    </tr>\n    <tr>\n      <th>135235</th>\n      <td>18201</td>\n      <td>Mo' Betta Bretta</td>\n      <td>American Wild Ale</td>\n      <td>4.514267</td>\n    </tr>\n    <tr>\n      <th>64110</th>\n      <td>51557</td>\n      <td>Humulus Lager</td>\n      <td>American Double / Imperial Pilsner</td>\n      <td>4.490672</td>\n    </tr>\n    <tr>\n      <th>16850</th>\n      <td>69894</td>\n      <td>Founders Cashew Mountain Brown</td>\n      <td>American Brown Ale</td>\n      <td>4.473522</td>\n    </tr>\n    <tr>\n      <th>135260</th>\n      <td>5933</td>\n      <td>Frank Double IPA</td>\n      <td>American Double / Imperial IPA</td>\n      <td>4.452857</td>\n    </tr>\n    <tr>\n      <th>144570</th>\n      <td>54647</td>\n      <td>Hunahpu's Imperial Stout - Bourbon Barrel Aged</td>\n      <td>American Double / Imperial Stout</td>\n      <td>4.446617</td>\n    </tr>\n    <tr>\n      <th>63926</th>\n      <td>50668</td>\n      <td>Papier (Rye Whiskey Barrel)</td>\n      <td>Old Ale</td>\n      <td>4.446371</td>\n    </tr>\n    <tr>\n      <th>134386</th>\n      <td>21383</td>\n      <td>Lou P Lin IPA</td>\n      <td>American Double / Imperial IPA</td>\n      <td>4.429394</td>\n    </tr>\n    <tr>\n      <th>135322</th>\n      <td>52390</td>\n      <td>Pseudo IPA</td>\n      <td>American IPA</td>\n      <td>4.425322</td>\n    </tr>\n    <tr>\n      <th>61306</th>\n      <td>68676</td>\n      <td>The Wanderer</td>\n      <td>American Wild Ale</td>\n      <td>4.425102</td>\n    </tr>\n    <tr>\n      <th>141012</th>\n      <td>67483</td>\n      <td>Nielsbohrium</td>\n      <td>American Double / Imperial Stout</td>\n      <td>4.419616</td>\n    </tr>\n    <tr>\n      <th>59765</th>\n      <td>63149</td>\n      <td>Humulus Session</td>\n      <td>American Pale Ale (APA)</td>\n      <td>4.405686</td>\n    </tr>\n    <tr>\n      <th>132310</th>\n      <td>60282</td>\n      <td>Cho-Saiko</td>\n      <td>American Double / Imperial IPA</td>\n      <td>4.405192</td>\n    </tr>\n    <tr>\n      <th>145044</th>\n      <td>67124</td>\n      <td>Marshal Zhukov's Imperial Stout - 4 Roses Aged</td>\n      <td>Russian Imperial Stout</td>\n      <td>4.401505</td>\n    </tr>\n    <tr>\n      <th>59786</th>\n      <td>63724</td>\n      <td>Oude Tart With Sour Cherries</td>\n      <td>American Wild Ale</td>\n      <td>4.394440</td>\n    </tr>\n    <tr>\n      <th>13898</th>\n      <td>65528</td>\n      <td>Mathias Imperial IPA</td>\n      <td>American Double / Imperial IPA</td>\n      <td>4.390701</td>\n    </tr>\n    <tr>\n      <th>3359</th>\n      <td>72827</td>\n      <td>Barrel Aged Naked Evil</td>\n      <td>English Barleywine</td>\n      <td>4.387421</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_surprise(5,\n",
    "              reviews,\n",
    "              svd,\n",
    "              20\n",
    "             )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "def validate(uid:int,\n",
    "              reviews:pd.core.frame.DataFrame,\n",
    "              model\n",
    "             ):\n",
    "\n",
    "    #get all the ratings by this user\n",
    "    my_ratings=reviews[[\"user_id\", \"beer_id\", \"review_overall\"]][reviews.user_id==uid]\n",
    "\n",
    "    # beers df\n",
    "    beers_df = reviews[[\"beer_id\", \"beer_name\", \"beer_style\"]].drop_duplicates()\n",
    "\n",
    "    #zip the ratings into a dict\n",
    "    already_rated=dict(zip(my_ratings.beer_id,my_ratings.review_overall))\n",
    "\n",
    "    pred_dict={}# store predicted ratings\n",
    "\n",
    "    for index,row in beers_df.iterrows(): # for every movie\n",
    "\n",
    "        pred_dict[row.beer_id]=model.predict(uid=uid,iid= row.beer_id).est# get the pred for this user\n",
    "\n",
    "    actual,pred=[],[]\n",
    "    for mid in already_rated: # for each movie id\n",
    "        actual.append(already_rated[mid])\n",
    "        pred.append(pred_dict[mid])\n",
    "\n",
    "    return mean_squared_error(actual,pred,squared=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3461003991463652"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(5,\n",
    "          reviews,\n",
    "          svd\n",
    "         )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.knns.KNNBasic at 0x20c5a7d8608>"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNNBasic(k=40, sim_options={'user_based':False,'min_support':5})\n",
    "knn.fit(trainset)# fit the svd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.6715  0.6629  0.6670  0.6646  0.6566  0.6645  0.0049  \n",
      "Fit time          1.83    1.07    1.77    0.58    0.61    1.17    0.54    \n",
      "Test time         5.34    6.43    5.24    3.08    3.12    4.65    1.33    \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'test_rmse': array([0.67153682, 0.66287777, 0.66698089, 0.6646103 , 0.65656991]),\n 'fit_time': (1.8290042877197266,\n  1.0729997158050537,\n  1.770998239517212,\n  0.5776538848876953,\n  0.6099984645843506),\n 'test_time': (5.343993902206421,\n  6.433997869491577,\n  5.240999937057495,\n  3.0839972496032715,\n  3.122999906539917)}"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the RMSE of the KNN algorithm.\n",
    "cross_validate(knn, data, measures=['RMSE'],cv=5,verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.knns.KNNBasic at 0x20c59874e48>"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNNBasic(k=40, sim_options={'user_based':False,'min_support':5})\n",
    "knn.fit(trainset)# fit the svd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.6655  0.6619  0.6684  0.6662  0.6632  0.6650  0.0023  \n",
      "Fit time          0.56    0.59    0.59    0.60    0.66    0.60    0.03    \n",
      "Test time         3.09    3.11    3.11    3.12    3.06    3.10    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'test_rmse': array([0.66547246, 0.66191358, 0.66837954, 0.66616631, 0.66323764]),\n 'fit_time': (0.5570054054260254,\n  0.5889942646026611,\n  0.5880053043365479,\n  0.5989995002746582,\n  0.658001184463501),\n 'test_time': (3.092991590499878,\n  3.1120002269744873,\n  3.110999822616577,\n  3.121004343032837,\n  3.058999538421631)}"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the RMSE of the KNN algorithm.\n",
    "cross_validate(knn, data, measures=['RMSE'],cv=5,verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.knns.KNNBasic at 0x20c5e18cd08>"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2=KNNBasic(k=40, sim_options={'item_based':False,'min_support':5})\n",
    "knn2.fit(trainset)# fit the svd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.6111  0.6054  0.6044  0.6168  0.6086  0.6093  0.0045  \n",
      "Fit time          7.28    6.91    7.01    7.49    7.07    7.15    0.21    \n",
      "Test time         12.87   12.68   12.92   13.39   14.58   13.29   0.69    \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'test_rmse': array([0.61107363, 0.60540779, 0.60435604, 0.61682223, 0.60860252]),\n 'fit_time': (7.283001184463501,\n  6.912995100021362,\n  7.014000177383423,\n  7.4890007972717285,\n  7.071999788284302),\n 'test_time': (12.868999481201172,\n  12.677999258041382,\n  12.922994136810303,\n  13.389997243881226,\n  14.582995891571045)}"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the RMSE of the KNN algorithm.\n",
    "cross_validate(knn2, data, measures=['RMSE'],cv=5,verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
