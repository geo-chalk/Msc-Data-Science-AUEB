{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n!pip install nltk\\n!pip install pandas\\n!pip install reportlab\\n!pip install openai\\n!pip install matplotlib\\n'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install reportlab\n",
    "!pip install openai\n",
    "!pip install matplotlib\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import Paragraph\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.styles import ParagraphStyle\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# General\n",
    "from string import digits\n",
    "import re\n",
    "from typing import List\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.series import Series\n",
    "\n",
    "# Replace YOUR_API_KEY with your OpenAI API key\n",
    "import openai\n",
    "openai.api_key = \"YOUR_API_KEY\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jojoshulk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jojoshulk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate pdf function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def generate_pdf(product: str,\n",
    "                 review: str,\n",
    "                 review_positive: str,\n",
    "                 review_negative: str,\n",
    "                 product_image: str,\n",
    "                 output_path: str,\n",
    "                 average_rating: float,\n",
    "                 rating_frequencies: str,\n",
    "                 rating_history: str):\n",
    "    \"\"\"\n",
    "    Function that generates a product review pdf\n",
    "    Args:\n",
    "        product:\n",
    "        review:\n",
    "        product_image:\n",
    "        output_path:\n",
    "        average_rating:\n",
    "        rating_frequencies:\n",
    "        rating_history:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Register the font with reportlab\n",
    "    pdfmetrics.registerFont(TTFont('Arial', 'Arial.ttf'))\n",
    "    pdfmetrics.registerFont(TTFont('VeraBd', 'VeraBd.ttf'))\n",
    "\n",
    "    # Create a PDF canvas\n",
    "    c = canvas.Canvas(f\"{output_path}\", pagesize=A4)\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    # Draw the product image\n",
    "    if product_image:\n",
    "        c.drawImage(product_image, 50, 410, height=350, width=200, preserveAspectRatio=True)\n",
    "    else:\n",
    "        c.setFont(\"VeraBd\", 20)\n",
    "        c.drawCentredString(150, 600, f\"Product Image\")\n",
    "        c.drawCentredString(150, 570, f\"not provided.\")\n",
    "\n",
    "    # Set the font for the product name\n",
    "    c.setFont(\"VeraBd\", 30)\n",
    "    x = c._pagesize[0] / 2\n",
    "    c.drawCentredString(x, 790, f\"{product}\")\n",
    "\n",
    "\n",
    "    # --- Review text box --- #\n",
    "    # Set the font for the review\n",
    "    c.setFont(\"Arial\", 30)\n",
    "\n",
    "    # Draw a rectangle for the review text box\n",
    "    style = ParagraphStyle(name='Normal_1', fontSize=13)\n",
    "    c.rect(290, 590, 270, 160, stroke=0, fill=0)\n",
    "    p = Paragraph(review, style=style)\n",
    "    w, h = p.wrap(250, 0)\n",
    "    p.drawOn(c, 300, 750 - h)\n",
    "\n",
    "\n",
    "    # --- Average Rating --- #\n",
    "    # Set the font for the product name\n",
    "    c.setFont(\"VeraBd\", 20)\n",
    "    x = 300 + 250 /2\n",
    "    c.drawCentredString(x, 550, f\"Rating: {average_rating:.2f}/5\")\n",
    "\n",
    "    # Draw the average rating image\n",
    "    c.drawImage(rating_frequencies, 290, 360, width=260,preserveAspectRatio=True)\n",
    "\n",
    "    # Draw the rating history image\n",
    "    c.drawImage(rating_history, 100, 10, width=400, height=200, preserveAspectRatio=True)\n",
    "\n",
    "    # Draw a rectangle for the review text box\n",
    "    style = ParagraphStyle(name='Normal_1', fontSize=12)\n",
    "    # c.rect(20, 200, 250, 160, stroke=1, fill=0)\n",
    "    p = Paragraph(review_negative.replace(\"\\n\", \"<br/>\"), style=style)\n",
    "    w, h = p.wrap(230, 0)\n",
    "    p.drawOn(c, 30, 370 - h)\n",
    "\n",
    "    # Draw a rectangle for the review text box\n",
    "    style = ParagraphStyle(name='Normal_1', fontSize=12)\n",
    "    # c.rect(310, 200, 250, 160, stroke=1, fill=0)\n",
    "    p = Paragraph(review_positive.replace(\"\\n\", \"<br/>\"), style=style)\n",
    "    w, h = p.wrap(230, 0)\n",
    "    p.drawOn(c, 320, 370 - h)\n",
    "\n",
    "\n",
    "\n",
    "    # Set the font for the Negatives title\n",
    "    c.setFillColorRGB(0.91,0.15,0.16)\n",
    "    c.setFont(\"VeraBd\", 20)\n",
    "    c.drawCentredString(150, 370, f\"Negatives\")\n",
    "\n",
    "    # Set the font for the positives title\n",
    "    c.setFillColorRGB(0.05,0.56,0.06)\n",
    "    c.setFont(\"VeraBd\", 20)\n",
    "    c.drawCentredString(430, 370, f\"Positives\")\n",
    "\n",
    "\n",
    "\n",
    "    # Save the PDF\n",
    "    c.save()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class PlotGenerator:\n",
    "    \"\"\"class that generates and saves plots given a csv containing reviews\"\"\"\n",
    "\n",
    "    RATING_FREQUENCY: str = \"rating_frequencies.png\"\n",
    "    RATING_HISTORY: str= \"rating_history.png\"\n",
    "\n",
    "\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.df = self.read_csv(filename)\n",
    "        self.logger = self._setup_logger()\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        \"\"\"Setup up logger\"\"\"\n",
    "\n",
    "        # Create logger\n",
    "        logger = logging.getLogger(self.__class__.__name__)\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        if not logger.handlers:\n",
    "            # Create console handler and set level to debug\n",
    "            ch = logging.StreamHandler()\n",
    "            ch.setLevel(logging.INFO)\n",
    "\n",
    "            # Create formatter\n",
    "            formatter = logging.Formatter('[%(asctime)s] %(levelname)s [%(name)s] - %(message)s')\n",
    "\n",
    "            # Add formatter to ch\n",
    "            ch.setFormatter(formatter)\n",
    "\n",
    "            # Add ch to logger\n",
    "            logger.addHandler(ch)\n",
    "\n",
    "        return logger\n",
    "\n",
    "    @staticmethod\n",
    "    def read_csv(filename: str) -> pd.DataFrame:\n",
    "        \"\"\"Read a csv file and returns the output in a Dataframe\"\"\"\n",
    "\n",
    "        df = pd.read_csv(filename)\n",
    "        df.sort_values(by='date', inplace=True)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        return df\n",
    "\n",
    "    def generate_plots(self) -> None:\n",
    "        self._plot_rating_frequencies(output_path=self.RATING_FREQUENCY)\n",
    "        self._plot_mean_ratings(output_path=self.RATING_HISTORY)\n",
    "        self.logger.info(\"Plots generated.\")\n",
    "\n",
    "\n",
    "    def _plot_rating_frequencies(self, output_path: str) -> None:\n",
    "        \"\"\"Plot a bar chart of the frequencies of the ratings in a pandas DataFrame.\"\"\"\n",
    "\n",
    "        self.logger.info(\"Generating rating frequencies png file.\")\n",
    "        # Count the frequencies of the ratings\n",
    "        ratings = self.df['rating'].value_counts()\n",
    "\n",
    "        # Get the labels (ratings) and values (frequencies)\n",
    "        labels = ratings.index\n",
    "        values = ratings.values\n",
    "\n",
    "        # Convert the frequencies to percentages\n",
    "        total_ratings = sum(values)\n",
    "        values = [value / total_ratings * 100 for value in values]\n",
    "\n",
    "        # Create the bar plot\n",
    "        plt.barh(labels, values, height=0.6, color='#FF9900', edgecolor='none')\n",
    "\n",
    "        # Add labels to the bars\n",
    "        for index, value in enumerate(values):\n",
    "            plt.text(value+3, labels[index], f\"{value:.0f}\" + '%', va='center',  fontsize=20)\n",
    "\n",
    "        # Set the y-axis labels\n",
    "        plt.yticks(labels, [str(label) + ' stars'\n",
    "                            if str(label) != \"1\" else str(label) + ' star'\n",
    "                            for label in labels],  fontsize=20)\n",
    "        plt.box(False)\n",
    "        plt.xticks([])\n",
    "\n",
    "        # Save the plot as a PDF file\n",
    "        plt.savefig(output_path, format='png', bbox_inches = 'tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_mean_ratings(self, output_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Plot a line chart of the mean ratings over the years in a pandas DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.info(\"Generating rating history png file.\")\n",
    "        df = self.df.copy()\n",
    "        # Convert the date column to datetime\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        # Convert the date column to a period with the frequency \"Q\" (quarters)\n",
    "        df['period'] = df['date'].dt.to_period('Q')\n",
    "\n",
    "        # Group the ratings by year and quarter and calculate the mean rating for each year and quarter\n",
    "        mean_ratings = df.groupby('period')['rating'].mean()\n",
    "\n",
    "        # Group the reviews by year and quarter and count the number of reviews with ratings between 1 and 2\n",
    "        low_ratings = df[(df['rating'] >= 1) & (df['rating'] <= 2)].groupby('period')['rating'].count()/df.groupby('period')['rating'].count()\n",
    "\n",
    "        # Get the years and quarters and mean ratings and number of reviews with ratings between 1 and 2\n",
    "        periods = mean_ratings.index\n",
    "        mean_ratings = mean_ratings.values\n",
    "        low_ratings = low_ratings.values\n",
    "\n",
    "        # Convert the periods to strings in the format \"YYYY-QQ\"\n",
    "        labels = [period.strftime('%Y-%m') for period in periods]\n",
    "\n",
    "        # Create the figure and axis with twin y-axis\n",
    "        fig, ax = plt.subplots()\n",
    "        ax2 = ax.twinx()\n",
    "\n",
    "        # Create the line plots\n",
    "        ax.plot(labels, mean_ratings, color='#FF9900', linewidth=4)\n",
    "        ax2.bar(labels, low_ratings, color='#1f77b4', linewidth=2, alpha=0.8)\n",
    "\n",
    "        # Rotate the x-axis labels and start the y-axis from 0\n",
    "        ax.set_xticklabels(labels, rotation=45)\n",
    "        ax.set_ylim(0, 5,2)\n",
    "\n",
    "        # Add axis labels and title\n",
    "        ax.set_xlabel('Year and quarter',  fontsize=20)\n",
    "        ax.set_ylabel('Mean rating',  fontsize=20, color='#FF9900')\n",
    "        ax2.set_ylabel('Negative vs Total \\nRatings',  fontsize=20, color='#1f77b4')\n",
    "\n",
    "        # Save the plot as a PDF file\n",
    "        _ = plt.savefig(output_path, format='png', bbox_inches = 'tight')\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# pre-processing function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-processes the text, using nltk, in order to use in language models\n",
    "\"\"\"\n",
    "def preprocess(sentence):\n",
    "    \"\"\"\n",
    "    Function to process a given sentence.\n",
    "    INPUT: raw string (tweet)\n",
    "    OUTPUT: processed string\n",
    "    \"\"\"\n",
    "    # initialize lemmatizer\n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    # define trans for digits\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "    #convert the sentence to lower\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # Remove underscores\n",
    "    sentence = re.sub(r'[-_]', '', sentence)\n",
    "    sentence = re.sub(r'_[A-Za-z0-9]+', ' ', sentence)\n",
    "    sentence = re.sub(r'^ _\\s+', ' ', sentence)\n",
    "\n",
    "    # Remove websites\n",
    "    sentence = re.sub('https?://[A-Za-z0-9./]+', ' ', sentence)\n",
    "\n",
    "    #remove all non words\n",
    "    sentence = re.sub(r'\\W', ' ', sentence)\n",
    "\n",
    "    #remove all single characters\n",
    "    sentence = re.sub(r'\\b\\w\\b', ' ', sentence)\n",
    "\n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r'[0-9]', ' ', sentence)\n",
    "    sentence = sentence.translate(remove_digits)\n",
    "\n",
    "    #remove multiple whitespaces\n",
    "    sentence = re.sub(' +', ' ', sentence)\n",
    "\n",
    "    # Split the sentence based on whitespaces (--> List of words)\n",
    "    sentence = sentence.split()\n",
    "\n",
    "    # # Lemmatization\n",
    "    # sentence = [stemmer.lemmatize(word) for word in sentence]\n",
    "\n",
    "    # Reconstruct the sentence by joining the words on each whitespace\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OpenAI summary class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class OpenAISummary:\n",
    "    \"\"\"Class that uses openAI API to generate product summaries, using all, negative and positive reviews\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, all_reviews: Series,\n",
    "                 negative_reviews: Series,\n",
    "                 positive_reviews: Series):\n",
    "        self.all_reviews = all_reviews\n",
    "        self.negative_reviews = negative_reviews\n",
    "        self.positive_reviews = positive_reviews\n",
    "        self.logger = self._setup_logger()\n",
    "        self.max_length: int = 3400\n",
    "\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        \"\"\"Setup up logger\"\"\"\n",
    "\n",
    "        # Create logger\n",
    "        logger = logging.getLogger(self.__class__.__name__)\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        if not logger.handlers:\n",
    "            # Create console handler and set level to debug\n",
    "            ch = logging.StreamHandler()\n",
    "            ch.setLevel(logging.INFO)\n",
    "\n",
    "            # Create formatter\n",
    "            formatter = logging.Formatter('[%(asctime)s] %(levelname)s [%(name)s] - %(message)s')\n",
    "\n",
    "            # Add formatter to ch\n",
    "            ch.setFormatter(formatter)\n",
    "\n",
    "            # Add ch to logger\n",
    "            logger.addHandler(ch)\n",
    "\n",
    "        return logger\n",
    "\n",
    "\n",
    "    def make_tokens_list(self, reviews: Series,\n",
    "                         shuffling: bool = True) ->  List[str]:\n",
    "        \"\"\"Splits reviews (Series) into strings with number of tokens (words) equals max_length.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.info(\"Making token list.\")\n",
    "        token_list: List[str] = []\n",
    "        token = \"\"\n",
    "\n",
    "        # shuffle reviews\n",
    "        if shuffling:\n",
    "            self.logger.info(\"shuffling Reviews.\")\n",
    "            reviews = reviews.sample(frac=1)\n",
    "\n",
    "        # find review length\n",
    "        for review in reviews:\n",
    "            review_length: int = len(re.findall(r'\\w+', review))\n",
    "            token_length: int = len(re.findall(r'\\w+', token))\n",
    "\n",
    "\n",
    "            # add string\n",
    "            if review_length + token_length <= self.max_length and review_length >= 2:\n",
    "                token += review\n",
    "\n",
    "            # append review\n",
    "            elif review_length + token_length > self.max_length:\n",
    "                token_list.append(token)\n",
    "                token = review\n",
    "\n",
    "        if not token_list:\n",
    "            token_list.append(token)\n",
    "        self.logger.info(f\"Made token list. Number of elements in the list is: {len(token_list)+1}\")\n",
    "\n",
    "        return token_list\n",
    "\n",
    "\n",
    "    def summarize_text(self, text: str, what: str, max_length: int) -> str:\n",
    "        \"\"\"\n",
    "        Function that uses open AI completion API and returns the text response\n",
    "\n",
    "        Args:\n",
    "            text: text to feed the API\n",
    "            what: that to do with the text (eg. summarize these reviews)\n",
    "            max_length: maximum response length\n",
    "        \"\"\"\n",
    "        if openai.api_key == \"YOUR_API_KEY\":\n",
    "            self.logger.error(f\"Invalid API KEY!!!\")\n",
    "            raise ValueError(\"Please use your OpenAI API key found in the first cell. The current value is 'YOUR_API_KEY'.\")\n",
    "\n",
    "        # Use the OpenAI API to summarize the text\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=f\"{what} {text}\",\n",
    "            temperature=0.5,\n",
    "            max_tokens=100,\n",
    "            top_p=1,\n",
    "            frequency_penalty=1,\n",
    "            presence_penalty=1\n",
    "        )\n",
    "        api_response = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "        return api_response\n",
    "\n",
    "\n",
    "    def _generate_interim_summary(self, reviews: Series,\n",
    "                                  max_length: int = 100,\n",
    "                                  shuffling: bool = False) -> str:\n",
    "        \"\"\"Generate a max_length word, all reviews summary\"\"\"\n",
    "\n",
    "        summary_interim: str = \"\"\n",
    "\n",
    "        # only keep first 10 packs of tokens\n",
    "        for i, token in enumerate(self.make_tokens_list(reviews, shuffling=shuffling)[:40]):\n",
    "            self.logger.info(f\"Sending API request #{i}\")\n",
    "\n",
    "            summary_interim += self.summarize_text(what=f\"summarize these reviews in less than {max_length} words\", text=token, max_length=max_length)\n",
    "            time.sleep(1)\n",
    "\n",
    "        self.logger.info(f\"Generated Interim summary\")\n",
    "        return summary_interim\n",
    "\n",
    "    def generate_summary(self, max_length: int = 100):\n",
    "        \"\"\"Generates a summary of all reviews\"\"\"\n",
    "\n",
    "        self.logger.info(f\"Generating all reviews summary.\")\n",
    "        summary_interim: str = self._generate_interim_summary(self.all_reviews)\n",
    "\n",
    "        summary: str = self.summarize_text(what=f\"Make a product review in less than {max_length} words about this product:\", text=summary_interim, max_length=max_length)\n",
    "\n",
    "        self.logger.info(f\"Generated Summary\")\n",
    "        return summary\n",
    "\n",
    "\n",
    "    def generate_positive(self, max_length: int = 100):\n",
    "        \"\"\"Extracts positive information\"\"\"\n",
    "        self.logger.info(f\"Generating positive reviews bullets\")\n",
    "\n",
    "        summary_interim: str = self._generate_interim_summary(self.positive_reviews)\n",
    "        summary: str = self.summarize_text(what=f\"make 3 bullets of good things about this product:\", text=summary_interim, max_length=max_length)\n",
    "\n",
    "        self.logger.info(f\"Generated Positive Summary\")\n",
    "        return summary\n",
    "\n",
    "\n",
    "    def generate_negative(self, max_length: int = 100):\n",
    "        \"\"\"Extracts negative information\"\"\"\n",
    "        self.logger.info(f\"Generating negative reviews bullets.\")\n",
    "        summary_interim: str = self._generate_interim_summary(self.negative_reviews, shuffling=True)\n",
    "\n",
    "        summary: str = self.summarize_text(what=f\"make 3 bullets of bad things about this product:\", text=summary_interim, max_length=max_length)\n",
    "\n",
    "        self.logger.info(f\"Generated Negative Summary\")\n",
    "        return summary\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarize Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def summarize(csv_path: str,\n",
    "              png_path: str = None\n",
    "              ) -> None:\n",
    "    \"\"\"\n",
    "    Creates a one page pdf containing a summary review of the product\n",
    "\n",
    "    Args:\n",
    "        csv_path: path of the csv file. Should have the format: amazon_reviews_{product_name}.csv\n",
    "        png_path: path of the product image from amazon\n",
    "    \"\"\"\n",
    "\n",
    "    # save plots\n",
    "    plot_generator = PlotGenerator(csv_path)\n",
    "    plot_generator.generate_plots()\n",
    "\n",
    "    # pre-process text\n",
    "    plot_generator.df[\"text\"]: pd.DataFrame = plot_generator.df[\"text\"].apply(lambda row: preprocess(row) if isinstance(row, str) else '')\n",
    "\n",
    "    # split into all reviews, positive reviews, negative reviews\n",
    "    df = plot_generator.df\n",
    "    all_reviews: Series = df[\"text\"]\n",
    "    negative_reviews: Series = df.loc[df.rating.apply(lambda x: str(x)).isin([\"1\",\"2\"])][\"text\"]\n",
    "    positive_reviews: Series = df.loc[df.rating.apply(lambda x: str(x)).isin([\"4\",\"5\"])][\"text\"]\n",
    "\n",
    "\n",
    "    # Get openAI responses\n",
    "    summarizer = OpenAISummary(all_reviews=all_reviews,\n",
    "                               negative_reviews=negative_reviews,\n",
    "                               positive_reviews=positive_reviews)\n",
    "\n",
    "    review_text = summarizer.generate_summary()\n",
    "    review_positive = summarizer.generate_positive()\n",
    "    review_negative = summarizer.generate_negative()\n",
    "\n",
    "\n",
    "\n",
    "    product: str = csv_path.replace(\".csv\", \"\")\\\n",
    "        .split(\"amazon_reviews_\")[-1]\\\n",
    "        .replace(\"_\", \" \")\\\n",
    "        .capitalize()\n",
    "    output: str = f\"./{product.replace(' ', '_')}_summary.pdf\"\n",
    "\n",
    "    print(\"Generating pdf report.\")\n",
    "    generate_pdf(product=product,\n",
    "                review=review_text.strip().capitalize(),\n",
    "                 review_positive=review_positive,\n",
    "                 review_negative=review_negative,\n",
    "                 product_image=png_path,\n",
    "                 output_path=output,\n",
    "                 average_rating=df['rating'].mean(),\n",
    "                 rating_frequencies=r\"./rating_frequencies.png\",\n",
    "                 rating_history=r\"./rating_history.png\")\n",
    "\n",
    "\n",
    "    # delete plot files\n",
    "    print(\"Deleting png files.\")\n",
    "    os.remove(r\"./rating_frequencies.png\")\n",
    "    os.remove(r\"./rating_history.png\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execution cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-31 19:08:22,182] INFO [PlotGenerator] - Generating rating frequencies png file.\n",
      "[2022-12-31 19:08:22,298] INFO [PlotGenerator] - Generating rating history png file.\n",
      "C:\\Users\\jojoshulk\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:120: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "[2022-12-31 19:08:22,799] INFO [PlotGenerator] - Plots generated.\n",
      "[2022-12-31 19:08:22,835] INFO [OpenAISummary] - Generating all reviews summary.\n",
      "[2022-12-31 19:08:22,836] INFO [OpenAISummary] - Making token list.\n",
      "[2022-12-31 19:08:23,469] INFO [OpenAISummary] - Made token list. Number of elements in the list is: 4\n",
      "[2022-12-31 19:08:23,471] INFO [OpenAISummary] - Sending API request #0\n",
      "[2022-12-31 19:08:28,523] INFO [OpenAISummary] - Sending API request #1\n",
      "[2022-12-31 19:08:33,720] INFO [OpenAISummary] - Sending API request #2\n",
      "[2022-12-31 19:08:38,690] INFO [OpenAISummary] - Generated Interim summary\n",
      "[2022-12-31 19:08:40,267] INFO [OpenAISummary] - Generated Summary\n",
      "[2022-12-31 19:08:40,268] INFO [OpenAISummary] - Generating positive reviews bullets\n",
      "[2022-12-31 19:08:40,269] INFO [OpenAISummary] - Making token list.\n",
      "[2022-12-31 19:08:40,600] INFO [OpenAISummary] - Made token list. Number of elements in the list is: 3\n",
      "[2022-12-31 19:08:40,601] INFO [OpenAISummary] - Sending API request #0\n",
      "[2022-12-31 19:08:45,443] INFO [OpenAISummary] - Sending API request #1\n",
      "[2022-12-31 19:08:50,440] INFO [OpenAISummary] - Generated Interim summary\n",
      "[2022-12-31 19:08:51,210] INFO [OpenAISummary] - Generated Positive Summary\n",
      "[2022-12-31 19:08:51,211] INFO [OpenAISummary] - Generating negative reviews bullets.\n",
      "[2022-12-31 19:08:51,213] INFO [OpenAISummary] - Making token list.\n",
      "[2022-12-31 19:08:51,214] INFO [OpenAISummary] - shuffling Reviews.\n",
      "[2022-12-31 19:08:51,265] INFO [OpenAISummary] - Made token list. Number of elements in the list is: 2\n",
      "[2022-12-31 19:08:51,266] INFO [OpenAISummary] - Sending API request #0\n",
      "[2022-12-31 19:08:55,459] INFO [OpenAISummary] - Generated Interim summary\n",
      "[2022-12-31 19:08:56,788] INFO [OpenAISummary] - Generated Negative Summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pdf report.\n",
      "Deleting png files.\n"
     ]
    }
   ],
   "source": [
    "csv_path: str = r\"./backup/amazon_reviews_Vans_Ward_Sneaker.csv\"\n",
    "png_path : str = r\"./Vans_Ward_Sneaker.png\"\n",
    "\n",
    "summarize(csv_path=csv_path,\n",
    "          png_path=png_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
