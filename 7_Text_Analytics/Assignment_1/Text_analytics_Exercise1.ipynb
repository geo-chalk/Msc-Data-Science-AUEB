{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ea1d812-8e93-44a2-9807-bf564e6689ed"
      },
      "source": [
        "# Imports"
      ],
      "id": "9ea1d812-8e93-44a2-9807-bf564e6689ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c26137ed-9534-4d53-b63c-d57bf3a0ce71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eeda815-3d38-4f1b-dc92-78ec0251e6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ],
      "source": [
        "# numpy stack\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# general\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import unicodedata \n",
        "import string\n",
        "from collections import Counter\n",
        "from pprint import pprint\n",
        "import sys\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.corpus import webtext\n",
        "\n",
        "# others\n",
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "from scipy.special import softmax\n",
        "\n",
        "# inline to include plots\n",
        "%matplotlib inline"
      ],
      "id": "c26137ed-9534-4d53-b63c-d57bf3a0ce71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WYumQ4of9Y_"
      },
      "source": [
        "# (i) Biagram & Trigram language model"
      ],
      "id": "7WYumQ4of9Y_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsosU-Tl-FRP"
      },
      "source": [
        "* In this senction we will implement a Biagram and a Trigram model, using the `gutenberg` corpus."
      ],
      "id": "RsosU-Tl-FRP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ha5Fzq3iGCr"
      },
      "source": [
        "## Corpus Download\n",
        "\n",
        "* In order to train the model we need to download a corpus from the ones included in NLTK."
      ],
      "id": "2Ha5Fzq3iGCr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeVmHOkOTBui",
        "outputId": "3e532b64-24fc-4b0d-d717-992a15a759cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "### Download if not imported\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# nltk.download('brown')\n",
        "# nltk.download('europarl_raw')\n",
        "# nltk.download('reuters')"
      ],
      "id": "GeVmHOkOTBui"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e5f758c-8ef7-4a45-9330-bb05e9e51494"
      },
      "source": [
        "* NLTK includes a small selection of texts from the Project Gutenberg electronic text archive, which contains some 25,000 free electronic books, hosted at http://www.gutenberg.org/. We begin by getting the Python interpreter to load the NLTK package, then ask to see nltk.corpus.gutenberg.fileids(), the file identifiers in this corpus:"
      ],
      "id": "0e5f758c-8ef7-4a45-9330-bb05e9e51494"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60419eb9-4287-468e-acaf-bb771fb8a79b",
        "outputId": "05bf955a-b8da-4b84-8e51-c05046b2c7e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# load the package\n",
        "gutenberg_corpus = nltk.corpus.gutenberg.fileids()\n",
        "del gutenberg_corpus[3]\n",
        "\n",
        "# print files\n",
        "gutenberg_corpus"
      ],
      "id": "60419eb9-4287-468e-acaf-bb771fb8a79b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0IKaEYEXijfW",
        "outputId": "32485460-dd0a-402c-dda1-0a131c39154c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# print first sentence\n",
        "gutenberg.raw(gutenberg_corpus[0]).split('.')[0]"
      ],
      "id": "0IKaEYEXijfW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKTVimGWh1-i"
      },
      "source": [
        "* Before proceeding we will combine the text from all files into one variable named `final_corpus`, lowering Capital letters in the process.\n",
        "* Moreover we will count the total number of words."
      ],
      "id": "lKTVimGWh1-i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a1a3150-f57d-44c0-86b6-515af81119d5"
      },
      "outputs": [],
      "source": [
        "final_corpus = ''\n",
        "for corpus in gutenberg_corpus:\n",
        "    text = gutenberg.raw(fileids=corpus)    \n",
        "    lower_text = text.lower()\n",
        "    final_corpus += lower_text"
      ],
      "id": "3a1a3150-f57d-44c0-86b6-515af81119d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b60e67a-0189-4d30-acf0-fe637ab8bda0",
        "outputId": "e4b7f076-48db-446d-e245-0d44b784563f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1314109"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(final_corpus.split())"
      ],
      "id": "4b60e67a-0189-4d30-acf0-fe637ab8bda0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7f80759-2357-4771-876d-b5f9d27c363f"
      },
      "source": [
        "## Cleaning the Text\n",
        "\n",
        "In order to clean the text we will create two regexes as described below: \n",
        "1. We will only keep words (letters from a-z and sentence ending characters) removing punctuation and other characters.\n",
        "2. We will remove multiple white spaces and linebreaks."
      ],
      "id": "b7f80759-2357-4771-876d-b5f9d27c363f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "233a9837-67a5-45ad-aa9e-7db82b963cf4"
      },
      "outputs": [],
      "source": [
        "def text_cleaning(text: str) -> str: \n",
        "    \"\"\" Function to only keep words and sentence ending characters, remove punctuation and other characters and remove multiple white spaces.\"\"\"\n",
        "\n",
        "    corpus = re.sub(r'[^a-zA-Z.?!\\']', ' ', text)\n",
        "    corpus = corpus.replace('[', '')\n",
        "    corpus = corpus.replace(']', '.')\n",
        "    corpus = re.sub(r'[[]/$@^&*()€:΄]', ' ', corpus)\n",
        "    corpus = re.sub(' +', ' ', corpus)\n",
        "    corpus = corpus.replace('\\n', ' ')\n",
        "    return corpus"
      ],
      "id": "233a9837-67a5-45ad-aa9e-7db82b963cf4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e0da2ba-67b1-4ddf-a5cb-7c2110b51e8f",
        "outputId": "6b40a7df-693d-45e5-9853-153de48fc740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Cleaning: [emma by jane austen 1816]\n",
            "\n",
            "volume i\n",
            "\n",
            "chapter i\n",
            "\n",
            "\n",
            "emma woodhouse, handsome, clever, and rich, with a comfortable home\n",
            "and happy disposition, seemed to\n",
            "\n",
            "After Cleaning:  emma by jane austen volume i chapter i emma woodhouse handsome clever and rich with a comfortable home and happy disposition seemed to unite some of \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Possible nested set at position 1\n",
            "  import sys\n"
          ]
        }
      ],
      "source": [
        "print(f'Before Cleaning: {final_corpus[:150]}', end='\\n\\n')\n",
        "final_corpus = text_cleaning(final_corpus)\n",
        "\n",
        "# Print the first sentence of the corpus\n",
        "print(f'After Cleaning: {final_corpus[:150]}')"
      ],
      "id": "8e0da2ba-67b1-4ddf-a5cb-7c2110b51e8f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTXZei0r6Lu5"
      },
      "source": [
        "## Tokenize str input\n",
        "\n",
        "* We now will transform the string input into a list, with each item containing one sentence of the corpus input, using the [`sent_tokenize`](https://www.nltk.org/api/nltk.tokenize.html) function."
      ],
      "id": "XTXZei0r6Lu5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b50eed8-ec14-4c9b-8e98-c9e399a31f1a"
      },
      "outputs": [],
      "source": [
        "def sentence_tokenization(text: str) -> list:\n",
        "    \"\"\" Function that uses ntlk's sent_tokenize function. 'Tokenizers divide strings into lists of substrings.' \"\"\"\n",
        "    sentence_list = nltk.sent_tokenize(''.join(text))\n",
        "    return sentence_list"
      ],
      "id": "1b50eed8-ec14-4c9b-8e98-c9e399a31f1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "913f5309-4fec-4154-a7e6-5918fe4bc69c",
        "outputId": "fe0986d8-2a06-4a30-f206-cd1b18c4df77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she was the youngest of the two daughters of a most affectionate indulgent father and had in consequence of her sister's marriage been mistress of his house from a very early period.\n"
          ]
        }
      ],
      "source": [
        "sentence_list = sentence_tokenization(final_corpus)\n",
        "\n",
        "# Print the first two sentences of the corpus\n",
        "print(sentence_list[1])"
      ],
      "id": "913f5309-4fec-4154-a7e6-5918fe4bc69c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Yixvro6Rdd"
      },
      "source": [
        "## Word tokenize\n",
        "\n",
        "* For every sentence in the tokenized list, we will run the [`word_tokenize`](https://www.nltk.org/api/nltk.tokenize.html) function, which will split each list into words. We will iterate through all the sentences, as shown below:"
      ],
      "id": "A8Yixvro6Rdd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74a274bb-f81a-4a13-ba7b-2e90619afb6c",
        "outputId": "6b7cab19-1e9a-460c-9fd8-015edb5bb93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.']\n"
          ]
        }
      ],
      "source": [
        "def word_tokenization(text: str) -> list:\n",
        "    \"\"\" Function that applies word_tokenize if a given sentence.\"\"\"\n",
        "    words = nltk.word_tokenize(text)\n",
        "    return words\n",
        "\n",
        "# Run it for every entry in the sentence_list\n",
        "corpus_in_list_of_words = [word_tokenization(f) for f in sentence_list]\n",
        "\n",
        "# Print the first sentence of the corpus\n",
        "print([i for i in corpus_in_list_of_words[1]])"
      ],
      "id": "74a274bb-f81a-4a13-ba7b-2e90619afb6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haCHhkGc-Zty"
      },
      "source": [
        "## Train-Test Split\n",
        "\n",
        "* Having pre-processed the Corpus we will split the sentences into Three parts. One for training, one for validation and one for testing."
      ],
      "id": "haCHhkGc-Zty"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdbeef71-3097-494c-ab61-8b4e8066650a"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility \n",
        "random.seed(1)\n",
        "\n",
        "# Shuffle and calculate split length\n",
        "random.shuffle(corpus_in_list_of_words)\n",
        "train_length = math.floor(0.6 * len(corpus_in_list_of_words))\n",
        "dev_length   = test_length = math.floor(0.2 * len(corpus_in_list_of_words))"
      ],
      "id": "bdbeef71-3097-494c-ab61-8b4e8066650a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "258e7a69-a856-45a7-b2db-a7759f44c00a"
      },
      "outputs": [],
      "source": [
        "train_corpus = [f for f in corpus_in_list_of_words[0 : train_length]]\n",
        "dev_corpus   = [f for f in corpus_in_list_of_words[train_length : train_length + dev_length]]\n",
        "test_corpus  = [f for f in corpus_in_list_of_words[train_length + dev_length:]]"
      ],
      "id": "258e7a69-a856-45a7-b2db-a7759f44c00a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s3ua0lCFDxw"
      },
      "source": [
        "## Create and count n-grams frequency (NLTK), Vocabulary, OOV Words\n",
        "\n",
        "* In the next part of the code we will create and count n-grams frequencym for unigrams, biagrams and triagrams using [`nltk.util`](https://www.nltk.org/_modules/nltk/util.html).\n",
        "* Moreover, using the unigram count, we will build the Vocabulary, which will consist words that appear at least 10 times in the *training* subset.\n",
        "* All the out-of-vocabulary (OOV) words, will be replaced by a special token *UNK*."
      ],
      "id": "5s3ua0lCFDxw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91cf9951-3670-4b51-bf67-826811052dce"
      },
      "outputs": [],
      "source": [
        "def calc_unigrams(corpus: list) -> Counter:\n",
        "    \"\"\" Function that returns a Unigram Counter of a given corpus.\"\"\"\n",
        "    unigram_counter = Counter()\n",
        "    for sentence in corpus:\n",
        "        unigram_counter.update([gram for gram in ngrams(sentence, 1, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='<e>')])\n",
        "    return unigram_counter\n",
        "\n",
        "def calc_bigrams(corpus: list) -> Counter:\n",
        "    \"\"\" Function that returns a Biagram Counter of a given corpus.\"\"\"\n",
        "    bigram_counter = Counter()\n",
        "    for sentence in corpus:\n",
        "        bigram_counter.update([gram for gram in ngrams(sentence, 2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='<e>')])\n",
        "    return bigram_counter\n",
        "\n",
        "\n",
        "def calc_trigrams(corpus: list) -> Counter:\n",
        "    \"\"\" Function that returns a Trigram Counter of a given corpus.\"\"\"\n",
        "    trigram_counter = Counter()\n",
        "    for sentence in corpus:\n",
        "        trigram_counter.update([gram for gram in ngrams(sentence, 3, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='<e>')])\n",
        "    return trigram_counter"
      ],
      "id": "91cf9951-3670-4b51-bf67-826811052dce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ee8264a-d738-42e9-8305-a02f518f1d68"
      },
      "outputs": [],
      "source": [
        "def replace_oov_words_train(corpus):\n",
        "    \"\"\" Function that calculates and replaces OOV words.\n",
        "    INPUT: Train corpus (list)\n",
        "    OUTPUT: \n",
        "      OOV_word: dict with key containing OOC words and value the str 'UNK' -> dict\n",
        "      clean_corpus: the original corpus having the OOV words replaced by 'UNK' -> list\n",
        "      vocabulary: the words contained in the vocabulary -> set\n",
        "    \"\"\"\n",
        "\n",
        "    unigram_counter = calc_unigrams(corpus)\n",
        "    OOV_words = {k[0]:\"UNK\" for k, v in unigram_counter.items() if v < 10}\n",
        "    clean_corpus = []\n",
        "    for sentence in corpus:\n",
        "        clean_corpus.append([OOV_words.get(n,n) for n in sentence])\n",
        "    vocabulary = [f[0] for f in unigram_counter.keys() if f[0] not in OOV_words]\n",
        "    vocabulary = set(vocabulary) # set for unique words\n",
        "    return OOV_words, clean_corpus, vocabulary"
      ],
      "id": "7ee8264a-d738-42e9-8305-a02f518f1d68"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5067fad-ca1b-4cd3-aa5c-1d803561c243"
      },
      "outputs": [],
      "source": [
        "oov_words, clean_corpus, vocabulary = replace_oov_words_train(train_corpus)"
      ],
      "id": "b5067fad-ca1b-4cd3-aa5c-1d803561c243"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj5gpUeFIgtP",
        "outputId": "35db2eb7-e1cd-4f69-af6d-22e959ab5097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['seafaring',\n",
              " 'noxious',\n",
              " 'agh',\n",
              " 'millar',\n",
              " 'halcyon',\n",
              " 'marbles',\n",
              " 'tricycle',\n",
              " 'godlike',\n",
              " 'reticulations',\n",
              " 'groanes']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# print some random OOV words\n",
        "random.sample(list(oov_words.keys()), 10)"
      ],
      "id": "lj5gpUeFIgtP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJE4JvYsNgbc"
      },
      "source": [
        "* Having found the OOV words and build the vocabulary, we can replace the OOV words in the remaining sets (dev, test)"
      ],
      "id": "WJE4JvYsNgbc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1b16bd8-154c-4f11-a0b7-b7939e4c6c6a"
      },
      "outputs": [],
      "source": [
        "def replace_oov_words_dev_test(corpus, vocabulary, oov_words):\n",
        "    clean_corpus = []\n",
        "    for sentence in corpus:\n",
        "        updated_sentence = ['UNK' if ((word not in vocabulary) or (word in oov_words)) else word for word in sentence]\n",
        "        clean_corpus.append(updated_sentence)\n",
        "    return clean_corpus"
      ],
      "id": "e1b16bd8-154c-4f11-a0b7-b7939e4c6c6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b9eaa81-b130-43e1-8dd4-ef2249a92312"
      },
      "outputs": [],
      "source": [
        "dev_corpus = replace_oov_words_dev_test(dev_corpus, vocabulary, oov_words)\n",
        "test_corpus = replace_oov_words_dev_test(test_corpus, vocabulary, oov_words)"
      ],
      "id": "9b9eaa81-b130-43e1-8dd4-ef2249a92312"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LnszPsdNw8y"
      },
      "source": [
        "* Finally we can calculate the various n-grams, in the training set, as well as the Vocabulary length."
      ],
      "id": "3LnszPsdNw8y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf7e067b-6d14-4ea0-a069-1fef29fabd7c"
      },
      "outputs": [],
      "source": [
        "vocabulary_length = len(vocabulary)\n",
        "unigram_counter = calc_unigrams(train_corpus)\n",
        "bigram_counter = calc_bigrams(train_corpus)\n",
        "trigram_counter = calc_trigrams(train_corpus)"
      ],
      "id": "bf7e067b-6d14-4ea0-a069-1fef29fabd7c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f195717-fe98-44c6-a1fb-e8cdfa526675",
        "outputId": "bf651c1b-be2c-4507-f7fb-92fb04f6d646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Length: 5932\n",
            "========================= \n",
            "Unigram 10 most common:\n",
            "[(('the',), 41885),\n",
            " (('.',), 30625),\n",
            " (('and',), 26114),\n",
            " (('of',), 22028),\n",
            " (('to',), 20517),\n",
            " (('a',), 15413),\n",
            " (('i',), 12804),\n",
            " (('in',), 12476),\n",
            " (('that',), 9546),\n",
            " (('it',), 9529)]\n",
            "========================= \n",
            "Bigram 10 most common:\n",
            "[(('.', '<e>'), 30392),\n",
            " (('!', '<e>'), 4846),\n",
            " (('of', 'the'), 4571),\n",
            " (('?', '<e>'), 4105),\n",
            " (('in', 'the'), 3138),\n",
            " (('<s>', 'i'), 3075),\n",
            " (('<s>', 'the'), 2366),\n",
            " (('to', 'the'), 1966),\n",
            " (('<s>', 'he'), 1726),\n",
            " (('to', 'be'), 1661)]\n",
            "========================= \n",
            "Trigram 10 most common:\n",
            "[(('.', '<e>', '<e>'), 30392),\n",
            " (('!', '<e>', '<e>'), 4846),\n",
            " (('?', '<e>', '<e>'), 4105),\n",
            " (('<s>', '<s>', 'i'), 3075),\n",
            " (('<s>', '<s>', 'the'), 2366),\n",
            " (('<s>', '<s>', 'he'), 1726),\n",
            " (('<s>', '<s>', 'but'), 1644),\n",
            " (('<s>', '<s>', 'and'), 1280),\n",
            " (('<s>', '<s>', 'it'), 1255),\n",
            " (('<s>', '<s>', 'she'), 938)]\n"
          ]
        }
      ],
      "source": [
        "print(f'Vocabulary Length: {vocabulary_length}')\n",
        "print('='*25, '\\nUnigram 10 most common:')\n",
        "pprint(unigram_counter.most_common(10))\n",
        "print('='*25, '\\nBigram 10 most common:')\n",
        "pprint(bigram_counter.most_common(10))\n",
        "print('='*25, '\\nTrigram 10 most common:')\n",
        "pprint(trigram_counter.most_common(10))"
      ],
      "id": "9f195717-fe98-44c6-a1fb-e8cdfa526675"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe here that the bigram (('the', 'lord'), 4269) is one of the 10 most common."
      ],
      "metadata": {
        "id": "W1dBATRylal2"
      },
      "id": "W1dBATRylal2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e53f62be-8c30-4a26-9ca2-17075d9af6b7"
      },
      "source": [
        "# (ii) Language cross-entropy and perplexity of Bigram and Trigram model\n"
      ],
      "id": "e53f62be-8c30-4a26-9ca2-17075d9af6b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgcgtcNhX3MI"
      },
      "source": [
        "* Using Laplace smoothing and the dev set as a single sequece of sentences, we will calculate the n-gram probabilities, by summing the logs. Logs are used as they are more convinient, compared to the product, since the product of many probabilities might result in underfloat events.\n",
        "* We  will add *start* (or *start1*, *start2*) at the beginning of each sentence, and *end* at the end of each sentence.\n",
        "* Probabilities of the form P(*start*$\\vert$…) or P(*start1*$\\vert$…), P(*start2*$\\vert$…) will be excluded in the computation of cross-entropy and perplexity.\n",
        "* Finally, in order to achieve the best results possible we will tune the parameter $\\alpha$ of a-smoothing."
      ],
      "id": "NgcgtcNhX3MI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bbc149d-4e03-4644-a698-06d2245ab04b"
      },
      "outputs": [],
      "source": [
        "def calc_bi_prob(word1: str, word2: str, alpha: float, bigram_counter: Counter, unigram_counter: Counter, vocabulary_length: int) -> float:\n",
        "    \"\"\" Function that calculates the Bigram model's probabilities using Laplace & a-smoothing.\"\"\"\n",
        "    #Bigram prob + laplace smoothing\n",
        "    bigram_prob = (bigram_counter[(word1, word2)] + alpha) / (unigram_counter[(word1,)] + alpha * vocabulary_length)\n",
        "    return bigram_prob"
      ],
      "id": "4bbc149d-4e03-4644-a698-06d2245ab04b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac58297c-0dc7-4b73-a145-f85c2b978757"
      },
      "outputs": [],
      "source": [
        "def calc_tri_prob(word1: str, word2: str, word3:str, alpha: float, trigram_counter:Counter, bigram_counter:Counter, vocabulary_length: int) -> float:\n",
        "    \"\"\" Function that calculates the Trigram model's probabilities using Laplace & a-smoothing.\"\"\"\n",
        "    #Bigram prob + laplace smoothing\n",
        "    trigram_prob = (trigram_counter[(word1, word2, word3)] +alpha) / (bigram_counter[(word1, word2)] + alpha * vocabulary_length)\n",
        "    return trigram_prob"
      ],
      "id": "ac58297c-0dc7-4b73-a145-f85c2b978757"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Bigram model perplexity/entropy in dev set."
      ],
      "metadata": {
        "id": "QYQ6TCIpas6K"
      },
      "id": "QYQ6TCIpas6K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35fcb4fd-d810-4769-8051-177214de66b7",
        "outputId": "fcaedc3e-b415-43d4-d9fe-2f0c417c6636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lowest perplexity/entropy regarding bigram model is : 336.397 / 8.394 at alpha= 0.017\n"
          ]
        }
      ],
      "source": [
        "# initialize variables\n",
        "perpl = []\n",
        "HC_list = []\n",
        "min, pos = 1, 0\n",
        "min_range_bi = []\n",
        "alpha_list = np.linspace(0.001,0.1,100)\n",
        "\n",
        "for i, alpha in enumerate(alpha_list):\n",
        "\n",
        "    sum_prob = 0\n",
        "    bigram_cnt = 0\n",
        "    for sent in dev_corpus:\n",
        "        sent = ['<s>']  + sent + ['<e>']\n",
        "        for idx in range(1,len(sent)):\n",
        "            bigram_prob = calc_bi_prob(word1=sent[idx-1], word2=sent[idx], alpha=alpha, bigram_counter=bigram_counter, unigram_counter=unigram_counter, vocabulary_length=vocabulary_length)\n",
        "            sum_prob += math.log2(bigram_prob)\n",
        "            bigram_cnt+=1\n",
        "\n",
        "    HC_list.append(-sum_prob / bigram_cnt)\n",
        "    perpl.append(math.pow(2,(-sum_prob / bigram_cnt)))\n",
        "\n",
        "    if i == 0:\n",
        "        min_entrp = -sum_prob / bigram_cnt\n",
        "    elif (-sum_prob / bigram_cnt) <= min_entrp:\n",
        "        min_range_bi.append(i)\n",
        "\n",
        "perpl_bi = np.array(perpl)\n",
        "entropy_bi = np.array(HC_list)\n",
        "best_alpha_bi = alpha_list[np.argmin(perpl)]\n",
        "\n",
        "print(f\"The lowest perplexity/entropy regarding bigram model is : {round(np.min(perpl_bi),3)} / {round(np.min(entropy_bi),3)} at alpha= {np.round(best_alpha_bi, 3)}\")"
      ],
      "id": "35fcb4fd-d810-4769-8051-177214de66b7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Trigram model perplexity/entropy in dev set."
      ],
      "metadata": {
        "id": "YDjNwa15ay-Q"
      },
      "id": "YDjNwa15ay-Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af6c4901-858b-4e7a-a2da-49ca25a71ab2",
        "outputId": "19cd8d78-babb-4cf9-f55a-b4532e31374c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lowest perplexity / entropy regarding trigram model is : 694.189 / 9.439 at alpha= 0.004\n"
          ]
        }
      ],
      "source": [
        "# initialize variables\n",
        "perpl = []\n",
        "HC_list = []\n",
        "min_range_tri = []\n",
        "alpha_list = np.linspace(0.001,0.1,100)\n",
        "\n",
        "\n",
        "for i, alpha in enumerate(alpha_list):\n",
        "\n",
        "    sum_prob = 0\n",
        "    trigram_cnt = 0\n",
        "    for sent in dev_corpus:\n",
        "        sent = ['<s>'] + ['<s>'] + sent + ['<e>'] + ['<e>']\n",
        "        for idx in range(2,len(sent)):\n",
        "            trigram_prob = calc_tri_prob(word1=sent[idx-2], word2=sent[idx-1], word3=sent[idx], alpha=alpha, trigram_counter=trigram_counter, bigram_counter=bigram_counter, vocabulary_length=vocabulary_length)\n",
        "            sum_prob += math.log2(trigram_prob)\n",
        "            trigram_cnt+=1\n",
        "\n",
        "    # append Cross-entropy and perplexity\n",
        "    HC_list.append(-sum_prob / trigram_cnt)\n",
        "    perpl.append(math.pow(2,(-sum_prob / trigram_cnt)))\n",
        "\n",
        "    if i == 0:\n",
        "        min_entrp = -sum_prob / trigram_cnt\n",
        "    elif (-sum_prob / trigram_cnt) <= min_entrp:\n",
        "        min_range_tri.append(i)\n",
        "\n",
        "perpl_tri = np.array(perpl)\n",
        "entropy_tri = np.array(HC_list)\n",
        "best_alpha_tri = alpha_list[np.argmin(perpl_tri)]\n",
        "\n",
        "print(f\"The lowest perplexity / entropy regarding trigram model is : {round(np.min(perpl_tri),3)} / {round(np.min(entropy_tri),3)} at alpha= {np.round(best_alpha_tri, 3)}\")"
      ],
      "id": "af6c4901-858b-4e7a-a2da-49ca25a71ab2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Find plot range\n",
        "plot_range = max(int(min_range_tri[-1]),int(min_range_bi[-1]))\n",
        "\n",
        "# define plot parameters for bigrama dn trigram\n",
        "pos_bi = np.argmin(perpl_bi)\n",
        "alpha_range_zoom_bi, perpl_zoom_bi = alpha_list[:plot_range], perpl_bi[:plot_range]\n",
        "pos_tri = np.argmin(perpl_tri)\n",
        "alpha_range_zoom_tri, perpl_zoom_tri = alpha_list[:plot_range], perpl_tri[:plot_range]\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# Bigram plot\n",
        "ax.plot(alpha_range_zoom_bi, perpl_zoom_bi, label='Perplexity (bigram)', color='#1f77b4')   \n",
        "ax.scatter(alpha_range_zoom_bi[pos_bi], perpl_zoom_bi[pos_bi], c='r', label='Lowest Perplexity point (bigram)', marker='x', s=150)\n",
        "ax.annotate(f\"Min Perplexity = {perpl_zoom_bi[pos_bi]:.3f}\", xy=(alpha_range_zoom_bi[pos_bi]-0.007, perpl_zoom_bi[pos_bi]+15), fontsize=12)\n",
        "ax.set_xlabel('α', fontsize=15)\n",
        "ax.set_ylabel('Perplexity', fontsize=15)\n",
        "\n",
        "\n",
        "# Trigram plot and twin axes\n",
        "# ax2 = ax.twinx()\n",
        "ax.plot(alpha_range_zoom_tri, perpl_zoom_tri, label='Perplexity (trigram)', color='orange')   \n",
        "ax.scatter(alpha_range_zoom_tri[pos_tri], perpl_zoom_tri[pos_tri], c='g', label='Lowest Perplexity point (trigram)', marker='x', s=150)\n",
        "ax.annotate(f\"Min Perplexity = {perpl_zoom_tri[pos_tri]:.3f}\", xy=(alpha_range_zoom_tri[pos_tri]-0.0009, perpl_zoom_tri[pos_tri]-30), fontsize=12)\n",
        "\n",
        "# set title and legend\n",
        "ax.set_title('Perplexity vs Alpha for bigram and trigram models.', fontsize=18)\n",
        "_ = ax.legend(loc='upper left')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dBVjOlnDdSaH",
        "outputId": "6e46408c-192f-4389-de25-c44369db715b"
      },
      "id": "dBVjOlnDdSaH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a133de00-64a5-4dd2-9c8c-de08c8fdf28d"
      },
      "source": [
        "## Testing the language models"
      ],
      "id": "a133de00-64a5-4dd2-9c8c-de08c8fdf28d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Having found the optimal value of $\\alpha$ for our models, we will proceed with evaluating the models, using previously unseen sentences.\n",
        "* We will not include probabilities in the form of P(*start*$\\vert$…) and P(*\\start1*$\\vert$…), P(*start2*$\\vert$…) but will cound *end* tokens in the total length N of the test corpus."
      ],
      "metadata": {
        "id": "JzvIkmnysSGv"
      },
      "id": "JzvIkmnysSGv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2c360a2-7d50-42e1-8622-d0d2d40e106a"
      },
      "outputs": [],
      "source": [
        "sum_prob = 0\n",
        "log_prob_bigram_correct=[]\n",
        "for sent in test_corpus:\n",
        "    sent = ['<s>']  + sent + ['<e>']\n",
        "    for idx in range(1,len(sent)):\n",
        "        bigram_prob = calc_bi_prob(word1=sent[idx-1], word2=sent[idx], alpha=best_alpha_bi, bigram_counter=bigram_counter, unigram_counter=unigram_counter, vocabulary_length=vocabulary_length)\n",
        "        sum_prob += math.log2(bigram_prob)\n",
        "        bigram_cnt+=1  \n",
        "    log_prob_bigram_correct.append(sum_prob)\n",
        "    sum_prob = 0"
      ],
      "id": "e2c360a2-7d50-42e1-8622-d0d2d40e106a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fdd6675-64d0-4243-9852-5d572b3c519d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "5df844d4-c724-43a1-efb8-fb83724c1f1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                         Correct Sentence  \\\n",
              "0  [how, came, they, acquainted, ?]                                                                                                                         \n",
              "1  [for, himself, .]                                                                                                                                        \n",
              "2  [talbot, for, ever, !]                                                                                                                                   \n",
              "3  [UNK, UNK, why, do, you, shew, me, this, ?]                                                                                                              \n",
              "4  [the, horse, kept, his, good, pace, and, by, noon, the, towers, of, the, castle, stood, out, against, the, sky, much, nearer, and, more, beautiful, .]   \n",
              "\n",
              "   Log Probability Correct  \n",
              "0 -38.119949                \n",
              "1 -9.034187                 \n",
              "2 -20.831215                \n",
              "3 -82.643206                \n",
              "4 -203.721381               "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cc75072-688f-43f1-80c2-4cf6d6ceac3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Correct Sentence</th>\n",
              "      <th>Log Probability Correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[how, came, they, acquainted, ?]</td>\n",
              "      <td>-38.119949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[for, himself, .]</td>\n",
              "      <td>-9.034187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[talbot, for, ever, !]</td>\n",
              "      <td>-20.831215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[UNK, UNK, why, do, you, shew, me, this, ?]</td>\n",
              "      <td>-82.643206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[the, horse, kept, his, good, pace, and, by, noon, the, towers, of, the, castle, stood, out, against, the, sky, much, nearer, and, more, beautiful, .]</td>\n",
              "      <td>-203.721381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cc75072-688f-43f1-80c2-4cf6d6ceac3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cc75072-688f-43f1-80c2-4cf6d6ceac3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cc75072-688f-43f1-80c2-4cf6d6ceac3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth',1)\n",
        "df_bigram = pd.DataFrame({\"Correct Sentence\":test_corpus, \"Log Probability Correct\":log_prob_bigram_correct})\n",
        "df_bigram.head()"
      ],
      "id": "6fdd6675-64d0-4243-9852-5d572b3c519d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60d7ab5e-2158-45b3-8107-9b2fdc1315b1"
      },
      "outputs": [],
      "source": [
        "sum_prob = 0\n",
        "log_prob_trigram_correct=[]\n",
        "for sent in test_corpus:\n",
        "    # This was wrong in trigram we need 2 starts not 1\n",
        "    sent = ['<s>'] + ['<s>']  + sent + ['<e>'] + ['<e>']\n",
        "    for idx in range(2,len(sent)):\n",
        "        trigram_prob = calc_tri_prob(word1=sent[idx-2], word2=sent[idx-1], word3=sent[idx], alpha=best_alpha_tri, trigram_counter=trigram_counter, bigram_counter=bigram_counter, vocabulary_length=vocabulary_length)\n",
        "        sum_prob += math.log2(trigram_prob)  \n",
        "    log_prob_trigram_correct.append(sum_prob)\n",
        "    sum_prob = 0"
      ],
      "id": "60d7ab5e-2158-45b3-8107-9b2fdc1315b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55c439b2-2d02-4157-a4eb-1e328c03eb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "3494b07f-1b28-4d47-d9b5-b5a125356fe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                         Correct Sentence  \\\n",
              "0  [how, came, they, acquainted, ?]                                                                                                                         \n",
              "1  [for, himself, .]                                                                                                                                        \n",
              "2  [talbot, for, ever, !]                                                                                                                                   \n",
              "3  [UNK, UNK, why, do, you, shew, me, this, ?]                                                                                                              \n",
              "4  [the, horse, kept, his, good, pace, and, by, noon, the, towers, of, the, castle, stood, out, against, the, sky, much, nearer, and, more, beautiful, .]   \n",
              "\n",
              "   Log Probability Correct  \n",
              "0 -45.045827                \n",
              "1 -15.487781                \n",
              "2 -13.115277                \n",
              "3 -99.544735                \n",
              "4 -281.578390               "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1eb9f022-18d3-4d6a-84ad-402543a1bf57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Correct Sentence</th>\n",
              "      <th>Log Probability Correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[how, came, they, acquainted, ?]</td>\n",
              "      <td>-45.045827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[for, himself, .]</td>\n",
              "      <td>-15.487781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[talbot, for, ever, !]</td>\n",
              "      <td>-13.115277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[UNK, UNK, why, do, you, shew, me, this, ?]</td>\n",
              "      <td>-99.544735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[the, horse, kept, his, good, pace, and, by, noon, the, towers, of, the, castle, stood, out, against, the, sky, much, nearer, and, more, beautiful, .]</td>\n",
              "      <td>-281.578390</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1eb9f022-18d3-4d6a-84ad-402543a1bf57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1eb9f022-18d3-4d6a-84ad-402543a1bf57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1eb9f022-18d3-4d6a-84ad-402543a1bf57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth',1)\n",
        "df_trigram = pd.DataFrame({\"Correct Sentence\":test_corpus, \"Log Probability Correct\":log_prob_trigram_correct})\n",
        "df_trigram.head()"
      ],
      "id": "55c439b2-2d02-4157-a4eb-1e328c03eb35"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigram model"
      ],
      "metadata": {
        "id": "sdWRux-FtjXM"
      },
      "id": "sdWRux-FtjXM"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in bigram_counter.items():\n",
        "  if i[1]==0:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "oJXaWJ2NNKhk"
      },
      "id": "oJXaWJ2NNKhk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30b31bf0-d074-4151-84c0-3e78698f93a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2744f15b-27b1-4c93-a727-e7244f423a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Cross Entropy: 8.415\n",
            "Language Perplexity: 341.395\n"
          ]
        }
      ],
      "source": [
        "test_sequence = []\n",
        "for sent in test_corpus:\n",
        "    test_sequence += ['<s>']  + sent + ['<e>']\n",
        "\n",
        "sum_prob = 0\n",
        "bigram_cnt = 0\n",
        "for idx in range(1,len(test_sequence)):\n",
        "    if test_sequence[idx] != '<s>':\n",
        "        bigram_prob = calc_bi_prob(word1=test_sequence[idx-1], word2=test_sequence[idx], alpha=best_alpha_bi, bigram_counter=bigram_counter, unigram_counter=unigram_counter, vocabulary_length=vocabulary_length)\n",
        "        sum_prob += math.log2(bigram_prob)\n",
        "        bigram_cnt+=1\n",
        "        \n",
        "HC = -sum_prob / bigram_cnt\n",
        "perpl = math.pow(2,HC)\n",
        "#print(sum_prob)\n",
        "#print(bigram_cnt)\n",
        "print(\"Language Cross Entropy: {0:.3f}\".format(HC))\n",
        "print(\"Language Perplexity: {0:.3f}\".format(perpl))"
      ],
      "id": "30b31bf0-d074-4151-84c0-3e78698f93a4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trigram model"
      ],
      "metadata": {
        "id": "mFknys57tl3p"
      },
      "id": "mFknys57tl3p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "836ece14-9072-4ab6-86f9-30c82da65af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0eb37dd-255f-49ab-9ae6-90b245a0f0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Cross Entropy: 9.431\n",
            "Language Perplexity: 690.201\n"
          ]
        }
      ],
      "source": [
        "test_sequence = []\n",
        "for sent in test_corpus:\n",
        "    test_sequence += ['<s>'] + ['<s>'] + sent + ['<e>'] + ['<e>']\n",
        "\n",
        "sum_prob = 0\n",
        "trigram_cnt = 0\n",
        "for idx in range(2,len(test_sequence)):\n",
        "    if test_sequence[idx] != '<s>':\n",
        "        trigram_prob = calc_tri_prob(word1=test_sequence[idx-2], word2=test_sequence[idx-1], word3=test_sequence[idx], alpha=best_alpha_tri, trigram_counter=trigram_counter, bigram_counter=bigram_counter, vocabulary_length=vocabulary_length)\n",
        "        sum_prob += math.log2(trigram_prob)\n",
        "        trigram_cnt+=1\n",
        "        \n",
        "HC = -sum_prob / trigram_cnt\n",
        "perpl = math.pow(2,HC)\n",
        "#print(sum_prob)\n",
        "#print(trigram_cnt)\n",
        "print(\"Language Cross Entropy: {0:.3f}\".format(HC))\n",
        "print(\"Language Perplexity: {0:.3f}\".format(perpl))"
      ],
      "id": "836ece14-9072-4ab6-86f9-30c82da65af4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa289903-0a5e-4e60-89f5-2a0bf5807271"
      },
      "source": [
        "# (iii) Spelling Corrector"
      ],
      "id": "aa289903-0a5e-4e60-89f5-2a0bf5807271"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In this section we will develop a  context-aware spelling corrector for both spelling and grammatical errors using our bigram language model, a beam search decoder,\n",
        "and the formulae of slide 19"
      ],
      "metadata": {
        "id": "ZA8zm3x22X20"
      },
      "id": "ZA8zm3x22X20"
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are updating the unigram counter for the start symbol < s > in order for the bigram probs to be calculated correctly."
      ],
      "metadata": {
        "id": "Lv6uK2XM3KqF"
      },
      "id": "Lv6uK2XM3KqF"
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_counter[('<s>',)] = len(train_corpus)\n",
        "bigram_counter[('<s>','<s>')] = len(train_corpus)"
      ],
      "metadata": {
        "id": "tz7KIa2X29Yo"
      },
      "id": "tz7KIa2X29Yo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam search decoder"
      ],
      "metadata": {
        "id": "mC_v9RMga8kR"
      },
      "id": "mC_v9RMga8kR"
    },
    {
      "cell_type": "code",
      "source": [
        "# beam search decoder function\n",
        "def beam_search(sent, l1, l2, k_init, topk_init, printing=True):\n",
        "    predicted_sent = list()\n",
        "    cumulative_ED_norm = [1] * k_init\n",
        "    cumulative_bigram_prob_norm = [1] * k_init\n",
        "    output_seq = [[] for x in range(k_init)]\n",
        "    output_seq_temp = [[] for x in range(k_init)]\n",
        "    choice = [['<s>'] for x in range(k_init)]\n",
        "    \n",
        "    # loop through each word in input sentence\n",
        "    for idx in range(1,len(sent)):\n",
        "        word_ED = list()\n",
        "        word_ED_norm = list()\n",
        "        bigram_prob = list()\n",
        "        criteria = list()\n",
        "        cumulative_ED_norm_temp = list()\n",
        "        cumulative_bigram_prob_norm_temp = list()\n",
        "      \n",
        "        if idx==len(sent)-1:\n",
        "            k=1\n",
        "            topk=1\n",
        "        elif idx==1:\n",
        "            k=1\n",
        "            topk=topk_init\n",
        "        else:\n",
        "            k=k_init\n",
        "            topk=topk_init\n",
        "      \n",
        "        # loop k times to find top probabilities from k previous selections\n",
        "        for i in range(k):\n",
        "          \n",
        "            # loop through each word in vocabulary\n",
        "            for word in vocabulary:\n",
        "                # edit distance for P(w|t)\n",
        "                word_ED.append(1/(nltk.edit_distance(sent[idx], word)+1))\n",
        "                # for the first iteration begin with the <s> symbol\n",
        "                if idx==1:\n",
        "                    bigram_prob.append(calc_bi_prob(word1=sent[0],\n",
        "                                                    word2=word, \n",
        "                                                    alpha=best_alpha_bi, \n",
        "                                                    bigram_counter=bigram_counter, \n",
        "                                                    unigram_counter=unigram_counter, \n",
        "                                                    vocabulary_length=vocabulary_length))\n",
        "                # else use the previously selected k choices\n",
        "                else:\n",
        "                    bigram_prob.append(calc_bi_prob(word1=choice[i][0], \n",
        "                                                    word2=word, \n",
        "                                                    alpha=best_alpha_bi, \n",
        "                                                    bigram_counter=bigram_counter, \n",
        "                                                    unigram_counter=unigram_counter, \n",
        "                                                    vocabulary_length=vocabulary_length))\n",
        "            # normalize to sum to 1\n",
        "            word_ED_norm = softmax(word_ED)\n",
        "            bigram_prob_norm = softmax(bigram_prob)\n",
        "            \n",
        "            cumulative_ED_norm_temp = np.multiply(np.array(word_ED_norm),cumulative_ED_norm[i])\n",
        "            cumulative_bigram_prob_norm_temp = np.multiply(np.array(bigram_prob_norm),cumulative_bigram_prob_norm[i])\n",
        "            \n",
        "            # zip the argmax criterion for each vocabulary word, the vocabulary word and the k iteration from which it originates \n",
        "            criteria += list(zip((l1 * np.log10(np.array(cumulative_bigram_prob_norm_temp)) + l2 * np.log10(np.array(cumulative_ED_norm_temp))),\n",
        "                                (np.array(cumulative_bigram_prob_norm_temp)),\n",
        "                                (np.array(cumulative_ED_norm_temp)),\n",
        "                                vocabulary,\n",
        "                                [i for x in vocabulary]))\n",
        "        # sort to find the top k\n",
        "        criteria_sorted = sorted(criteria,key=lambda k: k[0], reverse=True)[:topk]\n",
        "      \n",
        "        # save the k choices [word, from which k it originates, the previous word]\n",
        "        choice = [[x[3],x[4],choice[x[4]][0],x[1],x[2]] for x in criteria_sorted]\n",
        "      \n",
        "        # append in output sequence\n",
        "        if idx==1:\n",
        "            for i in range(topk):\n",
        "                output_seq[i].append(choice[i][0])\n",
        "        else:\n",
        "            for i in range(topk):\n",
        "                output_seq_temp[i] = output_seq[choice[i][1]] + [choice[i][0]]\n",
        "            for i in range(topk):\n",
        "                output_seq[i] = output_seq_temp[i]\n",
        "        \n",
        "        # cumulative probs\n",
        "        for i in range(topk):\n",
        "            cumulative_ED_norm[i] = choice[i][4]\n",
        "            cumulative_bigram_prob_norm[i] = choice[i][3]\n",
        "        \n",
        "        \n",
        "        if printing:\n",
        "          print('============================================================')        \n",
        "          print(f'step = {idx}')\n",
        "          print(f'w = {sent[idx]}')\n",
        "          print(f'top {topk_init} selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)')\n",
        "          print(criteria_sorted)\n",
        "          print('choice: (selected word, previous sequence, previous word)')\n",
        "          print(choice)\n",
        "          print('output seq:')\n",
        "          print(output_seq)\n",
        "          print('\\n')\n",
        "\n",
        "    return output_seq\n",
        "\n",
        "\n",
        "# find and print the longest sequence since the last choice is only one    \n",
        "def FindMaxLength(lst):\n",
        "    maxList = max(lst, key = lambda i: len(i))\n",
        "    maxLength = len(maxList)\n",
        "      \n",
        "    return maxList, maxLength\n"
      ],
      "metadata": {
        "id": "pd1cXmv0anQY"
      },
      "id": "pd1cXmv0anQY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $λ_1$ $λ_2$ hyperparameter tuning"
      ],
      "metadata": {
        "id": "Z_ASji9FbRmC"
      },
      "id": "Z_ASji9FbRmC"
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize variables\n",
        "k_init = 3\n",
        "topk_init = 3\n",
        "l1_list = np.linspace(0.01,1,50)\n",
        "fuzz_ratio = [[] for x in range(2)]\n",
        "\n",
        "actual_phrase = \"in consequence of her sister's marriage, been mistress of his house from a very early period\"\n",
        "test_phrase = \"in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\"\n",
        "phrase_tokenized = nltk.word_tokenize(test_phrase)\n",
        "sent = ['<s>']  + phrase_tokenized\n",
        "\n",
        "for i, l1 in enumerate(l1_list):\n",
        "    output_seq = beam_search(sent=sent, l1=l1, l2=1-l1, k_init=k_init, topk_init=topk_init, printing=False)\n",
        "    fuzz_ratio[0].append(fuzz.ratio(\" \".join(FindMaxLength(output_seq)[0]), actual_phrase))\n",
        "\n",
        "best_l1a = l1_list[np.argmax(fuzz_ratio[0])]\n",
        "\n",
        "print(f\"The best fuzz ratio is : {round(np.max(fuzz_ratio[0]),3)} at l1= {np.round(best_l1a, 3)}, l2= {1-np.round(best_l1a, 3)}\")\n",
        "\n",
        "\n",
        "actual_phrase = \"Tomorrow will bring something new, so leave today as a memory\"\n",
        "test_phrase = \"Tomorrrow well bring somethiing new, so leav today as a memoory.\"\n",
        "phrase_tokenized = nltk.word_tokenize(test_phrase)\n",
        "sent = ['<s>']  + phrase_tokenized\n",
        "\n",
        "for i, l1 in enumerate(l1_list):\n",
        "    output_seq = beam_search(sent=sent, l1=l1, l2=1-l1, k_init=k_init, topk_init=topk_init, printing=False)\n",
        "    fuzz_ratio[1].append(fuzz.ratio(\" \".join(FindMaxLength(output_seq)[0]), actual_phrase))\n",
        "\n",
        "best_l1b = l1_list[np.argmax(fuzz_ratio[1])]\n",
        "\n",
        "print(f\"The best fuzz ratio is : {round(np.max(fuzz_ratio[1]),3)} at l1= {np.round(best_l1b, 3)}, l2= {1-np.round(best_l1b, 3)}\")"
      ],
      "metadata": {
        "id": "sClcI6GD1Yvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a5adee-6c7a-436d-e798-f6238e88ec3a"
      },
      "id": "sClcI6GD1Yvn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best fuzz ratio is : 98 at l1= 0.01, l2= 0.99\n",
            "The best fuzz ratio is : 93 at l1= 0.01, l2= 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define plot parameters for bigram and trigram\n",
        "pos_best_l1a = np.argmax(fuzz_ratio[0])\n",
        "pos_best_l1b = np.argmax(fuzz_ratio[1])\n",
        "\n",
        "# Plot the results\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# plot\n",
        "ax.plot(l1_list, fuzz_ratio[0], label='test_sentence_1', color='blue')   \n",
        "#ax.scatter(l1_list[pos_best_l1a], fuzz_ratio[0][pos_best_l1a], c='r', label='best fuzz ratio point', marker='x', s=150)\n",
        "ax.set_xlabel('$λ_1$', fontsize=15)\n",
        "ax.set_ylabel('fuzz ratio', fontsize=15)\n",
        "\n",
        "ax.plot(l1_list, fuzz_ratio[1], label='test_sentence_2', color='orange')   \n",
        "#ax.scatter(l1_list[pos_best_l1b], fuzz_ratio[1][pos_best_l1b], c='r', label='best fuzz ratio point', marker='x', s=150)\n",
        "\n",
        "# set title and legend\n",
        "ax.set_title('fuzz ratio vs $λ_1$.', fontsize=18)\n",
        "_ = ax.legend(loc='upper right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "rvTQtntHQTMX",
        "outputId": "8821e161-0d3e-4c23-e1b2-2bfb024ed1c0"
      },
      "id": "rvTQtntHQTMX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will choose $λ_1$=0.3 and $λ_2$=0.7 since the fuzz ratio remains maximum with this choice and also we have both factors influencing the result."
      ],
      "metadata": {
        "id": "OuGRQoX2bx2R"
      },
      "id": "OuGRQoX2bx2R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test cases"
      ],
      "metadata": {
        "id": "7-N5o027bf_5"
      },
      "id": "7-N5o027bf_5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "843740fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd3a1bd-1d0a-4df8-eb48-cc9538d0f583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "step = 1\n",
            "w = in\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-3.5181720994824053, 0.00017057579865039082, 0.0003880899487875159, 'in', 0), (-3.66171637585779, 0.00018201760167653328, 0.00023538845266593415, 'i', 0), (-3.6676443704550836, 0.00017392155338484563, 0.00023538845266593415, 'it', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['in', 0, '<s>', 0.00017057579865039082, 0.0003880899487875159], ['i', 0, '<s>', 0.00018201760167653328, 0.00023538845266593415], ['it', 0, '<s>', 0.00017392155338484563, 0.00023538845266593415]]\n",
            "output seq:\n",
            "[['in'], ['i'], ['it']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 2\n",
            "w = consequencaae\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-7.215214438782736, 2.878019057461972e-08, 8.401712230042743e-08, 'consequence', 0), (-7.240682955540091, 2.875045742545241e-08, 7.729948410573697e-08, 'consequences', 0), (-7.255883262406705, 2.875045742545241e-08, 7.352954378010221e-08, 'consequently', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['consequence', 0, 'in', 2.878019057461972e-08, 8.401712230042743e-08], ['consequences', 0, 'in', 2.875045742545241e-08, 7.729948410573697e-08], ['consequently', 0, 'in', 2.875045742545241e-08, 7.352954378010221e-08]]\n",
            "output seq:\n",
            "[['in', 'consequence'], ['in', 'consequences'], ['in', 'consequently']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 3\n",
            "w = of\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-10.721758047565391, 5.263740832922411e-12, 3.288014458311205e-11, 'of', 0), (-10.883682771678505, 4.8777811748195e-12, 1.994281578544172e-11, 'if', 0), (-10.883682771678505, 4.8777811748195e-12, 1.994281578544172e-11, 'or', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['of', 0, 'consequence', 5.263740832922411e-12, 3.288014458311205e-11], ['if', 0, 'consequence', 4.8777811748195e-12, 1.994281578544172e-11], ['or', 0, 'consequence', 4.8777811748195e-12, 1.994281578544172e-11]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of'], ['in', 'consequence', 'if'], ['in', 'consequence', 'or']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 4\n",
            "w = her\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-14.239317667122886, 9.097816254539747e-16, 1.2714152211395988e-14, 'her', 0), (-14.394535428618699, 8.876086349095715e-16, 7.711523128464845e-15, 'hers', 0), (-14.39458253034514, 8.872878054218679e-16, 7.711523128464845e-15, 'here', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['her', 0, 'of', 9.097816254539747e-16, 1.2714152211395988e-14], ['hers', 0, 'of', 8.876086349095715e-16, 7.711523128464845e-15], ['here', 0, 'of', 8.872878054218679e-16, 7.711523128464845e-15]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her'], ['in', 'consequence', 'of', 'hers'], ['in', 'consequence', 'of', 'here']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 5\n",
            "w = sistero\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-17.900028223784243, 1.5616712025089774e-19, 3.079082174421648e-18, 'sister', 0), (-17.902268782345935, 1.5350448656150845e-19, 3.079082174421648e-18, 'sisters', 0), (-17.97836084429766, 1.5339786482951664e-19, 2.3979916085807835e-18, 'master', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['sister', 0, 'her', 1.5616712025089774e-19, 3.079082174421648e-18], ['sisters', 0, 'her', 1.5350448656150845e-19, 3.079082174421648e-18], ['master', 0, 'her', 1.5339786482951664e-19, 2.3979916085807835e-18]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister'], ['in', 'consequence', 'of', 'her', 'sisters'], ['in', 'consequence', 'of', 'her', 'master']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 6\n",
            "w = 's\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-21.40343256510878, 2.913936682868073e-23, 1.2071124151894072e-21, \"'s\", 0), (-21.56693646131486, 2.667743183703177e-23, 7.321506895321415e-22, 'as', 0), (-21.567633481165764, 2.653509332618524e-23, 7.321506895321415e-22, 'is', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[[\"'s\", 0, 'sister', 2.913936682868073e-23, 1.2071124151894072e-21], ['as', 0, 'sister', 2.667743183703177e-23, 7.321506895321415e-22], ['is', 0, 'sister', 2.653509332618524e-23, 7.321506895321415e-22]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\"], ['in', 'consequence', 'of', 'her', 'sister', 'as'], ['in', 'consequence', 'of', 'her', 'sister', 'is']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 7\n",
            "w = marriange\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-25.060221701103725, 4.919526166746159e-27, 2.9824509450059216e-25, 'marriage', 0), (-25.110676928388276, 4.927555022949144e-27, 2.524590220330256e-25, 'carriage', 0), (-25.111101852929934, 4.911510392595344e-27, 2.524590220330256e-25, 'marianne', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['marriage', 0, \"'s\", 4.919526166746159e-27, 2.9824509450059216e-25], ['carriage', 0, \"'s\", 4.927555022949144e-27, 2.524590220330256e-25], ['marianne', 0, \"'s\", 4.911510392595344e-27, 2.524590220330256e-25]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'carriage'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marianne']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 8\n",
            "w = ,\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-28.72136022735007, 8.63537152730492e-31, 7.143916631926662e-29, '.', 0), (-28.725882976577267, 8.340751775466016e-31, 7.143916631926662e-29, 'i', 0), (-28.725882976577267, 8.340751775466016e-31, 7.143916631926662e-29, '?', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['.', 0, 'marriage', 8.63537152730492e-31, 7.143916631926662e-29], ['i', 0, 'marriage', 8.340751775466016e-31, 7.143916631926662e-29], ['?', 0, 'marriage', 8.340751775466016e-31, 7.143916631926662e-29]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', 'i'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '?']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 9\n",
            "w = been\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-32.24123252860315, 1.455724957591027e-34, 2.770982727302242e-32, 'been', 0), (-32.39323559726929, 1.455724957591027e-34, 1.6806859816429412e-32, 'keen', 0), (-32.39323559726929, 1.455724957591027e-34, 1.6806859816429412e-32, 'bee', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['been', 0, '.', 1.455724957591027e-34, 2.770982727302242e-32], ['keen', 0, '.', 1.455724957591027e-34, 1.6806859816429412e-32], ['bee', 0, '.', 1.455724957591027e-34, 1.6806859816429412e-32]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'keen'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'bee']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 10\n",
            "w = moistress\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-35.89814471444766, 2.457463416303349e-38, 6.84382365016117e-36, 'mistress', 0), (-35.94901389702707, 2.453665846794464e-38, 5.7931716482356087e-36, 'distress', 0), (-35.97434774180476, 2.453665846794464e-38, 5.3299752179481186e-36, 'noiseless', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['mistress', 0, 'been', 2.457463416303349e-38, 6.84382365016117e-36], ['distress', 0, 'been', 2.453665846794464e-38, 5.7931716482356087e-36], ['noiseless', 0, 'been', 2.453665846794464e-38, 5.3299752179481186e-36]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'distress'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'noiseless']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 11\n",
            "w = of\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-39.40325758588967, 4.544195617029556e-42, 2.6783339509531868e-39, 'of', 0), (-39.56581373608594, 4.190637355958413e-42, 1.6244916582023803e-39, 'if', 0), (-39.56732131916167, 4.142426421233547e-42, 1.6244916582023803e-39, 'o', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['of', 0, 'mistress', 4.544195617029556e-42, 2.6783339509531868e-39], ['if', 0, 'mistress', 4.190637355958413e-42, 1.6244916582023803e-39], ['o', 0, 'mistress', 4.142426421233547e-42, 1.6244916582023803e-39]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'if'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'o']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 12\n",
            "w = hois\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-43.06931779438594, 7.995975716988178e-46, 6.305854575900609e-43, 'his', 0), (-43.12381249921474, 7.76452243152317e-46, 5.337790658317722e-43, 'this', 0), (-43.12431295505819, 7.734755016576853e-46, 5.337790658317722e-43, 'him', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['his', 0, 'of', 7.995975716988178e-46, 6.305854575900609e-43], ['this', 0, 'of', 7.76452243152317e-46, 5.337790658317722e-43], ['him', 0, 'of', 7.734755016576853e-46, 5.337790658317722e-43]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'this'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'him']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 13\n",
            "w = house\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-46.58690407034317, 1.3513188022475829e-49, 2.461732356545409e-46, 'house', 0), (-46.73903861318521, 1.3499558720763534e-49, 1.4931161502514226e-46, 'horse', 0), (-46.739235824449054, 1.3479140538386473e-49, 1.4931161502514226e-46, 'rouse', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['house', 0, 'his', 1.3513188022475829e-49, 2.461732356545409e-46], ['horse', 0, 'his', 1.3499558720763534e-49, 1.4931161502514226e-46], ['rouse', 0, 'his', 1.3479140538386473e-49, 1.4931161502514226e-46]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'horse'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'rouse']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 14\n",
            "w = from\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-50.10325037222218, 2.292372377300321e-53, 9.63398188593634e-50, 'from', 0), (-50.25609017268357, 2.2776975815198967e-53, 5.843305388936529e-50, 'fro', 0), (-50.25609017268357, 2.2776975815198967e-53, 5.843305388936529e-50, 'frog', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['from', 0, 'house', 2.292372377300321e-53, 9.63398188593634e-50], ['fro', 0, 'house', 2.2776975815198967e-53, 5.843305388936529e-50], ['frog', 0, 'house', 2.2776975815198967e-53, 5.843305388936529e-50]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'fro'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'frog']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 15\n",
            "w = a\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-53.61677212482737, 3.995988038239549e-57, 3.761349979185438e-53, 'a', 0), (-53.77261536770598, 3.879927395762656e-57, 2.2813740842854436e-53, 'an', 0), (-53.77296447445257, 3.8695450721890515e-57, 2.2813740842854436e-53, '.', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['a', 0, 'from', 3.995988038239549e-57, 3.761349979185438e-53], ['an', 0, 'from', 3.879927395762656e-57, 2.2813740842854436e-53], ['.', 0, 'from', 3.8695450721890515e-57, 2.2813740842854436e-53]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'an'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', '.']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 16\n",
            "w = vry\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-57.283119553739034, 6.894820262450425e-61, 8.922000242108783e-57, 'very', 0), (-57.286058923285346, 6.741011232023875e-61, 8.922000242108783e-57, 'cry', 0), (-57.28613450707368, 6.737101723419908e-61, 8.922000242108783e-57, 'dry', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['very', 0, 'a', 6.894820262450425e-61, 8.922000242108783e-57], ['cry', 0, 'a', 6.741011232023875e-61, 8.922000242108783e-57], ['dry', 0, 'a', 6.737101723419908e-61, 8.922000242108783e-57]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'cry'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'dry']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 17\n",
            "w = early\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-60.799871910563695, 1.1700498844754471e-64, 3.486431273731441e-60, 'early', 0), (-60.95237229588909, 1.1655922626392252e-64, 2.1146274604990877e-60, 'nearly', 0), (-60.95275909773518, 1.1621369677501403e-64, 2.1146274604990877e-60, 'dearly', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['early', 0, 'very', 1.1700498844754471e-64, 3.486431273731441e-60], ['nearly', 0, 'very', 1.1655922626392252e-64, 2.1146274604990877e-60], ['dearly', 0, 'very', 1.1621369677501403e-64, 2.1146274604990877e-60]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'nearly'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'dearly']]\n",
            "\n",
            "\n",
            "============================================================\n",
            "step = 18\n",
            "w = period\n",
            "top 3 selections: (l1*logbigramprob+l2*logEDprob , bigramprob, EDprob, selectedword, sequence)\n",
            "[(-64.31359680393102, 1.9900521396543572e-68, 1.3746923428261785e-63, 'period', 0)]\n",
            "choice: (selected word, previous sequence, previous word)\n",
            "[['period', 0, 'early', 1.9900521396543572e-68, 1.3746923428261785e-63]]\n",
            "output seq:\n",
            "[['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'nearly'], ['in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', '.', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'dearly']]\n",
            "\n",
            "\n",
            "===== RESULTS ========================================\n",
            "test phrase:\n",
            "in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\n",
            "     --------\n",
            "selected sequence:\n",
            "in consequence of her sister 's marriage . been mistress of his house from a very early period\n"
          ]
        }
      ],
      "source": [
        "#input\n",
        "#test_phrase = 'and the philistnine sayd to david cme to me'\n",
        "#test_phrase = \"and the philistnine sayid to david cme to me\"\n",
        "test_phrase = \"in consequencaae of her sistero's marriange, been moistress of hois house from a vry early period\"\n",
        "#test_phrase = \"as this sirence continued ivery dayy made it appear more stange and more UNK with the dissposition of both.\"\n",
        "phrase_tokenized = nltk.word_tokenize(test_phrase)\n",
        "sent = ['<s>']  + phrase_tokenized\n",
        "\n",
        "#initialize params/vars\n",
        "k_init = 3\n",
        "topk_init = 3\n",
        "l1 = 0.3\n",
        "l2 = 0.7\n",
        "\n",
        "output_seq = beam_search(sent=sent, l1=l1, l2=l2, k_init=k_init, topk_init=topk_init, printing=True)\n",
        "#print(FindMaxLength(output_seq))\n",
        "\n",
        "print('===== RESULTS ========================================')\n",
        "print('test phrase:')\n",
        "print(test_phrase)\n",
        "print('     --------')\n",
        "print('selected sequence:')\n",
        "print(\" \".join(FindMaxLength(output_seq)[0]))"
      ],
      "id": "843740fc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the spelling corrector"
      ],
      "metadata": {
        "id": "bUfNSHKe-zKB"
      },
      "id": "bUfNSHKe-zKB"
    },
    {
      "cell_type": "code",
      "source": [
        "correct = [\"He strives to keep the best lawn in the neighborhood.\",\n",
        "\"He walked into the basement with the horror movie from the night before playing in his head.\",\n",
        "\"She was the type of girl who wanted to live in a pink house.\",\n",
        "\"As the rental car rolled to a stop on the dark road, her fear increased by the moment.\",\n",
        "\"There are few things better in life than a slice of pie.\",\n",
        "\"The stench from the feedlot permeated the car despite having the air conditioning on recycled air.\",\n",
        "\"He told us a very exciting adventure story.\",\n",
        "\"All you need to do is pick up the pen and begin.\",\n",
        "\"Peanut butter and jelly caused the elderly lady to think about her past.\",\n",
        "\"Green should have smelled more tranquil, but somehow it just tasted rotten.\",\n",
        "\"She opened up her third bottle of wine of the night.\",\n",
        "\"As the years pass by, we all know owners look more and more like their dogs.\",\n",
        "\"There's no reason a hula hoop can't also be a circus ring.\",\n",
        "\"Your girlfriend bought your favorite cookie crisp cereal but forgot to get milk.\",\n",
        "\"Greetings from the galaxy MACS0647-JD, or what we call home.\",\n",
        "\"The minute she landed she understood the reason this was a fly-over state.\",\n",
        "\"I liked their first two albums but changed my mind after that charity gig.\",\n",
        "\"The sunblock was handed to the girl before practice, but the burned skin was proof she did not apply it.\",\n",
        "\"It took me too long to realize that the ceiling hadn't been painted to look like the sky.\",\n",
        "\"He waited for the stop sign to turn to a go sign.\",\n",
        "\"He never understood why what, when, and where left out who.\",\n",
        "\"The stranger officiates the meal.\",\n",
        "\"Instead of a bachelorette party\",\n",
        "\"8% of 25 is the same as 25% of 8 and one of them is much easier to do in your head.\",\n",
        "\"She wrote him a long letter, but he didn't read it.\",\n",
        "\"Jeanne wished she has chosen the red button.\",\n",
        "\"Their argument could be heard across the parking lot.\",\n",
        "\"The near-death experience brought new ideas to light.\",\n",
        "\"It was getting dark, and we weren’t there yet.\",\n",
        "\"Yeah, I think it's a good environment for learning English.\"]\n",
        "\n",
        "wrong = [\"He strivess to keep then best lawn in the neighborhood.\",\n",
        "\"He walked into the basement with the horrror movie from the night before play in his head.\",\n",
        "\"She was thhe type of girl who want to live in a pink house.\",\n",
        "\"As the rentall car rolled to a stop on the dark road, her fear increased by the moment.\",\n",
        "\"There are few things better in life than a slice of pie.\",\n",
        "\"The stench from the feedlot permeated the car despite having the air conditioning on recycled air.\",\n",
        "\"He told us a verry exciting adventure story.\",\n",
        "\"All you need to do is pick up the pen and begin.\",\n",
        "\"Peanut butter and jelly caused the elderly lady to think about her past.\",\n",
        "\"Green should have smelled more tranquil, but somehow it just tasted rotten.\",\n",
        "\"She opened up her third bottle of wine of the night.\",\n",
        "\"As the years pass by, we all knnow owners look more and more like their dogs.\",\n",
        "\"There's no reason a hula hoop can't also be a circus ring.\",\n",
        "\"Your girlfriend boughht your favorite cookie crisp cereal but forgot to get milk.\",\n",
        "\"Greetings from the galaxy MACS0647-JD, or whhat we call home.\",\n",
        "\"Then minutes she landed she understoods the reasson this was a fly-over state.\",\n",
        "\"I liked their first two albums but changed my mind after that charity gig.\",\n",
        "\"The sunblock was handed to the girl beffore practice, but the burned skin was proof she dad not apply it.\",\n",
        "\"It took me too long to realize that the ceiling hadn't been painted to look like the sky.\",\n",
        "\"He waiter for the sttop sign to turn to a go sign.\",\n",
        "\"He never understood why what, when, annd whore left out who.\",\n",
        "\"The strangler officciates the meal.\",\n",
        "\"Instead of a bacheloreztte party\",\n",
        "\"8% of 25 is tqhe same as 25% of 8 and one of them is much easier to do in your head.\",\n",
        "\"She wrote him a long letter, but he didn't read it.\",\n",
        "\"Jeanne washed she has cheosen the red button.\",\n",
        "\"Their argument cloud be heard achross the parking lot.\",\n",
        "\"The near-death experience brought new ideals to light.\",\n",
        "\"It was getting dark, ankd we weren’t there yet.\",\n",
        "\"Yeah, I think it's an good enviranment for learnting English.\"]\n",
        "\n",
        "\n",
        "for actual_phrase, test_phrase in dict(zip(correct, wrong)).items():\n",
        "  phrase_tokenized = nltk.word_tokenize(test_phrase)\n",
        "  sent = ['<s>']  + phrase_tokenized\n",
        "  output_seq = beam_search(sent=sent, l1=0.01, l2=1-0.01, k_init=3, topk_init=3, printing=False)\n",
        "  print(\"Original Phrase:\\t\",actual_phrase)\n",
        "  print(\"Error induced Phrase:\\t\",test_phrase)\n",
        "  print(\"Corrected Phrase:\\t\",\" \".join(FindMaxLength(output_seq)[0]))\n",
        "  print('\\n')\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AkQHjl_CWoC",
        "outputId": "47745377-e355-4f78-da5d-6dd9b22ea182"
      },
      "id": "-AkQHjl_CWoC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Phrase:\t He strives to keep the best lawn in the neighborhood.\n",
            "Error induced Phrase:\t He strivess to keep then best lawn in the neighborhood.\n",
            "Corrected Phrase:\t he strikes to keep then best lawn in the neighbourhood .\n",
            "\n",
            "\n",
            "Original Phrase:\t He walked into the basement with the horror movie from the night before playing in his head.\n",
            "Error induced Phrase:\t He walked into the basement with the horrror movie from the night before play in his head.\n",
            "Corrected Phrase:\t he walked into the pavement with the horror move from the night before play in his head .\n",
            "\n",
            "\n",
            "Original Phrase:\t She was the type of girl who wanted to live in a pink house.\n",
            "Error induced Phrase:\t She was thhe type of girl who want to live in a pink house.\n",
            "Corrected Phrase:\t the was the type of girl who want to live in a pink house .\n",
            "\n",
            "\n",
            "Original Phrase:\t As the rental car rolled to a stop on the dark road, her fear increased by the moment.\n",
            "Error induced Phrase:\t As the rentall car rolled to a stop on the dark road, her fear increased by the moment.\n",
            "Corrected Phrase:\t as the mental car rolled to a stop on the dark road . her fear increased by the moment .\n",
            "\n",
            "\n",
            "Original Phrase:\t There are few things better in life than a slice of pie.\n",
            "Error induced Phrase:\t There are few things better in life than a slice of pie.\n",
            "Corrected Phrase:\t there are few things better in life than a alice of pie .\n",
            "\n",
            "\n",
            "Original Phrase:\t The stench from the feedlot permeated the car despite having the air conditioning on recycled air.\n",
            "Error induced Phrase:\t The stench from the feedlot permeated the car despite having the air conditioning on recycled air.\n",
            "Corrected Phrase:\t the french from the feet permitted the car despite having the air condition on recalled air .\n",
            "\n",
            "\n",
            "Original Phrase:\t He told us a very exciting adventure story.\n",
            "Error induced Phrase:\t He told us a verry exciting adventure story.\n",
            "Corrected Phrase:\t he told us a very exciting adventure story .\n",
            "\n",
            "\n",
            "Original Phrase:\t All you need to do is pick up the pen and begin.\n",
            "Error induced Phrase:\t All you need to do is pick up the pen and begin.\n",
            "Corrected Phrase:\t all you need to do is pick up the pen and begin .\n",
            "\n",
            "\n",
            "Original Phrase:\t Peanut butter and jelly caused the elderly lady to think about her past.\n",
            "Error induced Phrase:\t Peanut butter and jelly caused the elderly lady to think about her past.\n",
            "Corrected Phrase:\t meant butter and jolly caused the elderly lady to think about her past .\n",
            "\n",
            "\n",
            "Original Phrase:\t Green should have smelled more tranquil, but somehow it just tasted rotten.\n",
            "Error induced Phrase:\t Green should have smelled more tranquil, but somehow it just tasted rotten.\n",
            "Corrected Phrase:\t green should have melted more tranquil . but somehow it just tasted often .\n",
            "\n",
            "\n",
            "Original Phrase:\t She opened up her third bottle of wine of the night.\n",
            "Error induced Phrase:\t She opened up her third bottle of wine of the night.\n",
            "Corrected Phrase:\t the opened up her third bottle of wine of the night .\n",
            "\n",
            "\n",
            "Original Phrase:\t As the years pass by, we all know owners look more and more like their dogs.\n",
            "Error induced Phrase:\t As the years pass by, we all knnow owners look more and more like their dogs.\n",
            "Corrected Phrase:\t as the years pass by a we all know owners look more and more like their dogs .\n",
            "\n",
            "\n",
            "Original Phrase:\t There's no reason a hula hoop can't also be a circus ring.\n",
            "Error induced Phrase:\t There's no reason a hula hoop can't also be a circus ring.\n",
            "Corrected Phrase:\t there 's no reason a hull hoops ca n't also be a circle ring .\n",
            "\n",
            "\n",
            "Original Phrase:\t Your girlfriend bought your favorite cookie crisp cereal but forgot to get milk.\n",
            "Error induced Phrase:\t Your girlfriend boughht your favorite cookie crisp cereal but forgot to get milk.\n",
            "Corrected Phrase:\t your friend bought your favourite looke grasp real but forgot to get milk .\n",
            "\n",
            "\n",
            "Original Phrase:\t Greetings from the galaxy MACS0647-JD, or what we call home.\n",
            "Error induced Phrase:\t Greetings from the galaxy MACS0647-JD, or whhat we call home.\n",
            "Corrected Phrase:\t meetings from the lady russell . or what we call home .\n",
            "\n",
            "\n",
            "Original Phrase:\t The minute she landed she understood the reason this was a fly-over state.\n",
            "Error induced Phrase:\t Then minutes she landed she understoods the reasson this was a fly-over state.\n",
            "Corrected Phrase:\t then minutes she landed she understood the reason this was a lover state .\n",
            "\n",
            "\n",
            "Original Phrase:\t I liked their first two albums but changed my mind after that charity gig.\n",
            "Error induced Phrase:\t I liked their first two albums but changed my mind after that charity gig.\n",
            "Corrected Phrase:\t i liked their first two plums but changed my mind after that charity wig .\n",
            "\n",
            "\n",
            "Original Phrase:\t The sunblock was handed to the girl before practice, but the burned skin was proof she did not apply it.\n",
            "Error induced Phrase:\t The sunblock was handed to the girl beffore practice, but the burned skin was proof she dad not apply it.\n",
            "Corrected Phrase:\t the block was handed to the girl before practice i but the burned skin was proof she had not apple it .\n",
            "\n",
            "\n",
            "Original Phrase:\t It took me too long to realize that the ceiling hadn't been painted to look like the sky.\n",
            "Error induced Phrase:\t It took me too long to realize that the ceiling hadn't been painted to look like the sky.\n",
            "Corrected Phrase:\t it took me too long to realized that the ceiling had n't been painted to look like the sky .\n",
            "\n",
            "\n",
            "Original Phrase:\t He waited for the stop sign to turn to a go sign.\n",
            "Error induced Phrase:\t He waiter for the sttop sign to turn to a go sign.\n",
            "Corrected Phrase:\t he waiter for the stop sign to turn to a go sign .\n",
            "\n",
            "\n",
            "Original Phrase:\t He never understood why what, when, and where left out who.\n",
            "Error induced Phrase:\t He never understood why what, when, annd whore left out who.\n",
            "Corrected Phrase:\t he never understood why what i when i and where left out who .\n",
            "\n",
            "\n",
            "Original Phrase:\t The stranger officiates the meal.\n",
            "Error induced Phrase:\t The strangler officciates the meal.\n",
            "Corrected Phrase:\t the stranger offices the real .\n",
            "\n",
            "\n",
            "Original Phrase:\t Instead of a bachelorette party\n",
            "Error induced Phrase:\t Instead of a bacheloreztte party\n",
            "Corrected Phrase:\t instead of a bracelet party\n",
            "\n",
            "\n",
            "Original Phrase:\t 8% of 25 is the same as 25% of 8 and one of them is much easier to do in your head.\n",
            "Error induced Phrase:\t 8% of 25 is tqhe same as 25% of 8 and one of them is much easier to do in your head.\n",
            "Corrected Phrase:\t i ? of a is the same as he . of a and one of them is much easier to do in your head .\n",
            "\n",
            "\n",
            "Original Phrase:\t She wrote him a long letter, but he didn't read it.\n",
            "Error induced Phrase:\t She wrote him a long letter, but he didn't read it.\n",
            "Corrected Phrase:\t the wrote him a long letter . but he did n't read it .\n",
            "\n",
            "\n",
            "Original Phrase:\t Jeanne wished she has chosen the red button.\n",
            "Error induced Phrase:\t Jeanne washed she has cheosen the red button.\n",
            "Corrected Phrase:\t anne washed she has chosen the red button .\n",
            "\n",
            "\n",
            "Original Phrase:\t Their argument could be heard across the parking lot.\n",
            "Error induced Phrase:\t Their argument cloud be heard achross the parking lot.\n",
            "Corrected Phrase:\t their argument cloud be heard across the parting lot .\n",
            "\n",
            "\n",
            "Original Phrase:\t The near-death experience brought new ideas to light.\n",
            "Error induced Phrase:\t The near-death experience brought new ideals to light.\n",
            "Corrected Phrase:\t the nearest experience brought new ideal to light .\n",
            "\n",
            "\n",
            "Original Phrase:\t It was getting dark, and we weren’t there yet.\n",
            "Error induced Phrase:\t It was getting dark, ankd we weren’t there yet.\n",
            "Corrected Phrase:\t it was getting dark . and we were a ' there yet .\n",
            "\n",
            "\n",
            "Original Phrase:\t Yeah, I think it's a good environment for learning English.\n",
            "Error induced Phrase:\t Yeah, I think it's an good enviranment for learnting English.\n",
            "Corrected Phrase:\t ah ! ' think it 's an good government for learning english .\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g_4y7O-gI0cS"
      },
      "id": "g_4y7O-gI0cS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Text_analytics_Exercise1_v3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}