{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Mining – Assignment 1\n",
    "---\n",
    "> Chalkiopoulos Georgios, Electrical and Computer Engineer NTUA <br />\n",
    "> Data Science postgraduate Student <br />\n",
    "> gchalkiopoulos@aueb.gr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas import DataFrame\n",
    "from typing import TextIO\n",
    "\n",
    "from helper_functions import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"files\")\n",
    "except FileExistsError:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Import and pre-process the dataset with users\n",
    "\n",
    "There are 3 files for the dataset,\n",
    "* the users.txt file contains id, age, gender, occupation and postcode separated by |,\n",
    "* the movies.txt file contains id, title (with release year) and some other information not related with the assignment separated by |,\n",
    "* the ratings.txt file (tab separated) which contains userid, movieid, rating (1-5) and timestamp.\n",
    "\n",
    "For this assignment only the set of movies that a user has rated, and not the ratings, will be used. In your report you should describe in detail any processing and conversion you made to the original data and the reasons it was necessary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define path\n",
    "path = Path.cwd() / \"MovieLensDataset\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  age gender  occupation postcode\n0   1   24      M  technician    85711\n1   2   53      F       other    94043\n2   3   23      M      writer    32067\n3   4   24      M  technician    43537\n4   5   33      F       other    15213",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>occupation</th>\n      <th>postcode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>other</td>\n      <td>94043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>writer</td>\n      <td>32067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>43537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>F</td>\n      <td>other</td>\n      <td>15213</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users\n",
    "users_col: list = [\"id\", \"age\", \"gender\", \"occupation\", \"postcode\"]\n",
    "users_df: DataFrame = pd.read_csv(path / \"users.txt\", delimiter=\"|\",names=users_col, header=None)\n",
    "users_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   id         title_year\n0   1   Toy Story (1995)\n1   2   GoldenEye (1995)\n2   3  Four Rooms (1995)\n3   4  Get Shorty (1995)\n4   5     Copycat (1995)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movies df\n",
    "movies_col: list = [\"id\", \"title_year\"]\n",
    "movies_df: DataFrame = pd.read_csv(path / \"movies.txt\", delimiter=\"|\", encoding='latin-1', header=None, names=movies_col, usecols=movies_col)\n",
    "movies_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct users: 943\n",
      "Distinct Movies: 1682\n",
      "\n",
      "Ratings of userid #1:\n"
     ]
    },
    {
     "data": {
      "text/plain": "       userid  movieid  rating  timestamp\n202         1       61       4  878542420\n305         1      189       3  888732928\n333         1       33       4  878542699\n334         1      160       4  875072547\n478         1       20       4  887431883\n...       ...      ...     ...        ...\n92049       1       28       4  875072173\n92487       1      172       5  874965478\n94019       1      122       3  875241498\n96699       1      152       5  878542589\n99073       1       94       2  875072956\n\n[272 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userid</th>\n      <th>movieid</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>202</th>\n      <td>1</td>\n      <td>61</td>\n      <td>4</td>\n      <td>878542420</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>1</td>\n      <td>189</td>\n      <td>3</td>\n      <td>888732928</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>1</td>\n      <td>33</td>\n      <td>4</td>\n      <td>878542699</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>1</td>\n      <td>160</td>\n      <td>4</td>\n      <td>875072547</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>1</td>\n      <td>20</td>\n      <td>4</td>\n      <td>887431883</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92049</th>\n      <td>1</td>\n      <td>28</td>\n      <td>4</td>\n      <td>875072173</td>\n    </tr>\n    <tr>\n      <th>92487</th>\n      <td>1</td>\n      <td>172</td>\n      <td>5</td>\n      <td>874965478</td>\n    </tr>\n    <tr>\n      <th>94019</th>\n      <td>1</td>\n      <td>122</td>\n      <td>3</td>\n      <td>875241498</td>\n    </tr>\n    <tr>\n      <th>96699</th>\n      <td>1</td>\n      <td>152</td>\n      <td>5</td>\n      <td>878542589</td>\n    </tr>\n    <tr>\n      <th>99073</th>\n      <td>1</td>\n      <td>94</td>\n      <td>2</td>\n      <td>875072956</td>\n    </tr>\n  </tbody>\n</table>\n<p>272 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings df\n",
    "ratings_col: list = [\"userid\", \"movieid\", \"rating\", \"timestamp\"]\n",
    "ratings_df: DataFrame = pd.read_csv(path / \"ratings.txt\", delimiter=\"\\t\", header=None, names=ratings_col)\n",
    "\n",
    "print(f\"Distinct users: {ratings_df['userid'].unique().shape[0]}\")\n",
    "print(f\"Distinct Movies: {ratings_df['movieid'].unique().shape[0]}\")\n",
    "print(\"\\nRatings of userid #1:\")\n",
    "ratings_df.loc[ratings_df.userid == 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) Compute exact Jaccard similarity of users\n",
    "\n",
    "* As a first step we will create a set, for each user, containing the movies he has rated. We will combine all the users in a DataGrame called user_movies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "userid\n1    {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n2    {257, 258, 1, 10, 13, 14, 269, 272, 273, 274, ...\n3    {258, 260, 264, 268, 271, 272, 288, 294, 299, ...\n4    {258, 260, 264, 11, 271, 288, 294, 300, 301, 3...\n5    {1, 2, 17, 21, 24, 25, 29, 40, 42, 50, 62, 63,...\ndtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of movies per user\n",
    "user_movies: DataFrame =  ratings_df[[\"userid\", \"movieid\"]].groupby('userid').apply(lambda x: set([i for i in x['movieid']]))\n",
    "user_movies.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using this DataFrame, we will compute the jaccard scores between all possible pairs of users, and keep those whose similarity is above 50%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# compute jaccard scores\n",
    "jaccard_scores = compute_jaccard(data=user_movies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Pairs: \n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "Pair: (600, 826) - Jaccard Score: 54.55%\n",
      "Pair: (451, 489) - Jaccard Score: 53.33%\n",
      "Pair: (674, 879) - Jaccard Score: 52.17%\n",
      "Pair: (554, 764) - Jaccard Score: 51.70%\n",
      "Pair: (197, 826) - Jaccard Score: 51.30%\n",
      "Pair: (197, 600) - Jaccard Score: 50.00%\n",
      "Pair: (800, 879) - Jaccard Score: 50.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Similar Pairs: \")\n",
    "similar_users = print_similar_pairs(jaccard_scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Output the movie titles that the most similar pair of users has seen.\n",
    "The most similar pair of users are 408 and 898 with a Jaccard score of 83.87%. The movies that these users have seen is presented below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies seen by users 408 and/or 898: \n",
      "\n",
      "id        Movie\n",
      "[408 898] Air Force One (1997)\n",
      "[898]     Alien: Resurrection (1997)\n",
      "[408 898] Apt Pupil (1998)\n",
      "[898]     As Good As It Gets (1997)\n",
      "[408 898] Conspiracy Theory (1997)\n",
      "[408 898] Contact (1997)\n",
      "[408 898] Cop Land (1997)\n",
      "[898]     Deceiver (1997)\n",
      "[408 898] English Patient, The (1996)\n",
      "[408 898] Everyone Says I Love You (1996)\n",
      "[408 898] Gattaca (1997)\n",
      "[408 898] Good Will Hunting (1997)\n",
      "[408 898] Indian Summer (1996)\n",
      "[408 898] Jackal, The (1997)\n",
      "[898]     Jungle2Jungle (1997)\n",
      "[898 408] Kolya (1996)\n",
      "[408 898] L.A. Confidential (1997)\n",
      "[408]     Liar Liar (1997)\n",
      "[408 898] Lost Highway (1997)\n",
      "[408 898] Midnight in the Garden of Good and Evil (1997)\n",
      "[408 898] Mouse Hunt (1997)\n",
      "[408 898] Rainmaker, The (1997)\n",
      "[408 898] Rocket Man (1997)\n",
      "[408 898] Saint, The (1997)\n",
      "[408 898] Scream (1996)\n",
      "[408 898] Spawn (1997)\n",
      "[408 898] Starship Troopers (1997)\n",
      "[408 898] Titanic (1997)\n",
      "[898 408] Tomorrow Never Dies (1997)\n",
      "[408 898] U Turn (1997)\n",
      "[408 898] Wag the Dog (1997)\n"
     ]
    }
   ],
   "source": [
    "# join the ratings df with the movies to get the movie names per user id\n",
    "joined: DataFrame = ratings_df.loc[ratings_df.userid.isin([408, 898])].merge(movies_df, left_on=\"movieid\", right_on=\"id\")\n",
    "\n",
    "print(\"Movies seen by users 408 and/or 898: \\n\")\n",
    "print(f\"{'id':10}Movie\")\n",
    "for movie in sorted(joined[\"title_year\"].unique()):\n",
    "    print(f\"{str(joined.loc[joined.title_year == movie].userid.values):10}\", end=\"\")\n",
    "    print(movie)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "    userid  age gender occupation postcode\n0      408   23      M    student    61755\n27     898   23      M  homemaker    61755",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userid</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>occupation</th>\n      <th>postcode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>408</td>\n      <td>23</td>\n      <td>M</td>\n      <td>student</td>\n      <td>61755</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>898</td>\n      <td>23</td>\n      <td>M</td>\n      <td>homemaker</td>\n      <td>61755</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the ratings df with the movies to get the movie names per user id\n",
    "demographic: DataFrame = ratings_df.loc[ratings_df.userid.isin([408, 898])].merge(users_df, left_on=\"userid\", right_on=\"id\")\n",
    "demographic[[\"userid\", \"age\", \"gender\", \"occupation\", \"postcode\"]].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Compute similarity using Min-hash signatures\n",
    "\n",
    "<u>Description of hash functions</u>: use the following family of hash functions: $h_{a,b}(x)=(ax+b) mod R$, with a,b random integers in the interval (0,R) and R a large enough prime number that you may want to finetune in your initial experimentation. Make sure that each hash function uses different values of a,b pairs.\n",
    "\n",
    "<u>Evaluation of Min-hashing</u>: Use 50, 100, and 200 hash functions. For each value, output the pair of users that have estimated similarity at least 0.5, and report the number of false positives and false negatives (against the exact Jaccard similarity) that you obtain. For the false positives and negatives, report the averages for 5 different runs using different functions. Comment on how the number of hash functions affects the false positive and negatives figures."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create user matrices\n",
    "\n",
    "Before proceeding, we will create the \"Document\" of each user. This, in practice, is a list in which we assign the number 1 if the user has seen the movie with id i and 0 if he hasn't.\n",
    "\n",
    "* keep in mind that the movie id's start from one while python indices start from zero"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "userid\n1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n2    [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, ...\n3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n5    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\ndtype: object"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create doc\n",
    "movies = user_movies.apply(lambda x: [1 if i+1 in x else 0 for i in range(ratings_df.movieid.max())])\n",
    "movies.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We need a large value of R which will make sure that we have at least 1682 different values (distinct movies). In this case we will avoid having two values for the same row (hash conflict), while hashing the rows movie ids."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1682"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the max value of the movieid\n",
    "number_of_movies: int = ratings_df.movieid.max()\n",
    "number_of_movies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value for R is: 1693\n"
     ]
    }
   ],
   "source": [
    "# Define movie index rows\n",
    "rows: np.ndarray = np.array(range(1, len(movies[1])+1))\n",
    "\n",
    "# find optimal R which avoids hash conficts\n",
    "R: int = find_optimal_R(rows=rows, number_of_movies=number_of_movies)\n",
    "print(f\"Optimal value for R is: {R}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Detailed results will be saved in the estimated_similarities.csv file, and during iterations, only a summary for each run will be printed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "69"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define_writer\n",
    "fw: TextIO = (Path(\"files\") / f\"estimated_similarities.csv\").open(mode=\"w\",encoding=\"utf8\")\n",
    "writer = csv.writer(fw,lineterminator=\"\\n\")\n",
    "writer.writerow([\"hash_functions\",\"iteration\", \"user1\", \"user2\", \"estimated_similarity\", \"evaluation\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For 50, 100 and 200 hash functions, 5 runs will be performed. At the end of the run the average number of TP, FP and FN will be printed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hash functions: 50\n",
      "Iteration 1\n",
      "{'False Negatives': 2, 'False Positives': 79, 'True Positives': 8}\n",
      "\n",
      "\n",
      "Number of Hash functions: 50\n",
      "Iteration 2\n",
      "{'False Negatives': 3, 'False Positives': 104, 'True Positives': 7}\n",
      "\n",
      "\n",
      "Number of Hash functions: 50\n",
      "Iteration 3\n",
      "{'False Positives': 161, 'True Positives': 10}\n",
      "\n",
      "\n",
      "Number of Hash functions: 50\n",
      "Iteration 4\n",
      "{'False Negatives': 3, 'False Positives': 108, 'True Positives': 7}\n",
      "\n",
      "\n",
      "Number of Hash functions: 50\n",
      "Iteration 5\n",
      "{'False Negatives': 2, 'False Positives': 109, 'True Positives': 8}\n",
      "\n",
      "\n",
      "Average for 50: \n",
      "False Negatives - 2.0 \n",
      "False Positives - 112.2 \n",
      "True Positives - 8.0\n",
      "\n",
      "\n",
      "\n",
      "Number of Hash functions: 100\n",
      "Iteration 1\n",
      "{'False Positives': 20, 'True Positives': 10}\n",
      "\n",
      "\n",
      "Number of Hash functions: 100\n",
      "Iteration 2\n",
      "{'False Negatives': 4, 'False Positives': 21, 'True Positives': 6}\n",
      "\n",
      "\n",
      "Number of Hash functions: 100\n",
      "Iteration 3\n",
      "{'False Negatives': 2, 'False Positives': 43, 'True Positives': 8}\n",
      "\n",
      "\n",
      "Number of Hash functions: 100\n",
      "Iteration 4\n",
      "{'False Negatives': 2, 'False Positives': 25, 'True Positives': 8}\n",
      "\n",
      "\n",
      "Number of Hash functions: 100\n",
      "Iteration 5\n",
      "{'False Negatives': 2, 'False Positives': 51, 'True Positives': 8}\n",
      "\n",
      "\n",
      "Average for 100: \n",
      "False Negatives - 2.0 \n",
      "False Positives - 32.0 \n",
      "True Positives - 8.0\n",
      "\n",
      "\n",
      "\n",
      "Number of Hash functions: 200\n",
      "Iteration 1\n",
      "{'False Negatives': 1, 'False Positives': 6, 'True Positives': 9}\n",
      "\n",
      "\n",
      "Number of Hash functions: 200\n",
      "Iteration 2\n",
      "{'False Negatives': 4, 'False Positives': 3, 'True Positives': 6}\n",
      "\n",
      "\n",
      "Number of Hash functions: 200\n",
      "Iteration 3\n",
      "{'False Negatives': 3, 'False Positives': 18, 'True Positives': 7}\n",
      "\n",
      "\n",
      "Number of Hash functions: 200\n",
      "Iteration 4\n",
      "{'False Negatives': 2, 'False Positives': 11, 'True Positives': 8}\n",
      "\n",
      "\n",
      "Number of Hash functions: 200\n",
      "Iteration 5\n",
      "{'False Negatives': 1, 'False Positives': 15, 'True Positives': 9}\n",
      "\n",
      "\n",
      "Average for 200: \n",
      "False Negatives - 2.2 \n",
      "False Positives - 10.6 \n",
      "True Positives - 7.8\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in [50, 100, 200]:\n",
    "    fn, fp, tp = 0, 0, 0\n",
    "    for i in range(5):\n",
    "        print(f\"Number of Hash functions: {n}\\nIteration {i+1}\")\n",
    "\n",
    "        # create signatures\n",
    "        signature: pd.DataFrame = generate_signatures(n=n, movies=movies, R=R, iteration=i)\n",
    "\n",
    "        # compute jaccard scores\n",
    "        jaccard_scores_hash: Dict[int, list] = compute_jaccard_hash(data=signature, similar_users=similar_users)\n",
    "\n",
    "        # Evalute scores\n",
    "        approx_scores: dict = evaluate_jaccard(jaccard_scores=jaccard_scores_hash, similar_users=similar_users, n=n, iteration=i+1, writer=writer)\n",
    "\n",
    "        # save scores\n",
    "        fn += approx_scores.get(\"False Negatives\", 0)\n",
    "        fp += approx_scores.get(\"False Positives\", 0)\n",
    "        tp += approx_scores.get(\"True Positives\", 0)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # save signature with 200 hash functions\n",
    "        if n == 200:\n",
    "            f =(Path(\"files\") / f\"signature.pkl\").open('wb')\n",
    "            pkl.dump(rows, f)\n",
    "            f.close()\n",
    "\n",
    "\n",
    "    print(f\"Average for {n}: \\nFalse Negatives - {fn/5} \\nFalse Positives - {fp/5} \\nTrue Positives - {tp/5}\")\n",
    "    print(\"\\n\\n\")\n",
    "fw.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4) Locate similar users using LSH index\n",
    "\n",
    "Using a set of 200 hash functions break up the signatures into b bands with r hash functions per band (b*r=200) and implement Locality Sensitive Hashing.\n",
    "Recall that with LSH we first locate users that are similar (have the same mini-signatures) across at least one band and then assess their true similarity using their initial representations. Use the following two instances of LSH:\n",
    "* LSH instance 1: b = 25, r = 8\n",
    "* LSH instance 2: b = 40, r = 5\n",
    "\n",
    "Using each instance find the pair of users with similarity at least 0.5 and report:\n",
    "- The number of true pairs returned (true positives).\n",
    "- The number of similarity evaluations performed using the initial representations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* In order to run this part indepentently, we will load the signatures from the pickle file, in case the variable is not available."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Pairs for r = 5, iteration 0\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "\n",
      "True Positive Pairs for r = 5, iteration 1\n",
      "Pair: (600, 826) - Jaccard Score: 54.55%\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (489, 451) - Jaccard Score: 53.33%\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (554, 764) - Jaccard Score: 51.70%\n",
      "Pair: (674, 879) - Jaccard Score: 52.17%\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "Pair: (600, 197) - Jaccard Score: 50.00%\n",
      "\n",
      "True Positive Pairs for r = 5, iteration 2\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (554, 764) - Jaccard Score: 51.70%\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (826, 197) - Jaccard Score: 51.30%\n",
      "Pair: (489, 451) - Jaccard Score: 53.33%\n",
      "\n",
      "True Positive Pairs for r = 5, iteration 3\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (674, 879) - Jaccard Score: 52.17%\n",
      "Pair: (489, 451) - Jaccard Score: 53.33%\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (600, 826) - Jaccard Score: 54.55%\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "Pair: (600, 197) - Jaccard Score: 50.00%\n",
      "Pair: (800, 879) - Jaccard Score: 50.00%\n",
      "\n",
      "True Positive Pairs for r = 5, iteration 4\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (600, 197) - Jaccard Score: 50.00%\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "Pair: (800, 879) - Jaccard Score: 50.00%\n",
      "\n",
      "True Positive Pairs for r = 8, iteration 0\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (826, 197) - Jaccard Score: 51.30%\n",
      "\n",
      "True Positive Pairs for r = 8, iteration 1\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (554, 764) - Jaccard Score: 51.70%\n",
      "\n",
      "True Positive Pairs for r = 8, iteration 2\n",
      "Pair: (554, 764) - Jaccard Score: 51.70%\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "Pair: (489, 451) - Jaccard Score: 53.33%\n",
      "\n",
      "True Positive Pairs for r = 8, iteration 3\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (489, 451) - Jaccard Score: 53.33%\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "\n",
      "True Positive Pairs for r = 8, iteration 4\n",
      "Pair: (328, 788) - Jaccard Score: 67.30%\n",
      "Pair: (408, 898) - Jaccard Score: 83.87%\n",
      "Pair: (489, 587) - Jaccard Score: 62.99%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results: dict = {\"5\" : [], \"8\": []}\n",
    "\n",
    "for r in [5, 8]:\n",
    "    tp_count: int = 0\n",
    "    avg_evaluations: int = 0\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "        # find candidates\n",
    "        similar_users_band = calculate_similar_users_LSH(r=r, iteration=i)\n",
    "\n",
    "\n",
    "        print(f\"True Positive Pairs for r = {r}, iteration {i}\")\n",
    "        for pair in similar_users_band:\n",
    "\n",
    "            # find candidates\n",
    "            jaccard_scores_LSH = compute_jaccard(data=user_movies.loc[list(pair)])\n",
    "\n",
    "            # for candidates with score above 50%, find true pairs\n",
    "            if jaccard_scores_LSH:\n",
    "                if pair in similar_users:\n",
    "                    print_similar_pairs(jaccard_scores_LSH)\n",
    "                    tp_count += 1\n",
    "        print()\n",
    "\n",
    "        avg_evaluations += len(similar_users_band)\n",
    "\n",
    "    results[str(r)].append(tp_count/5)\n",
    "    results[str(r)].append(avg_evaluations/5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for r=5:\n",
      "\tAverage number of True Positives: 6.0\n",
      "\tAverage number Evaluations: 1279.4\n",
      "\n",
      "Results for r=8:\n",
      "\tAverage number of True Positives: 3.0\n",
      "\tAverage number Evaluations: 38.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r, v in results.items():\n",
    "    print(f\"Results for r={r}:\")\n",
    "    print(f\"\\tAverage number of True Positives: {v[0]}\")\n",
    "    print(f\"\\tAverage number Evaluations: {v[1]}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
